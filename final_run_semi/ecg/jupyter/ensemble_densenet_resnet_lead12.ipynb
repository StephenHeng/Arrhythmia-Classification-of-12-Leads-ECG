{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from resnet_ecg.utils import one_hot,get_batches\n",
    "from resnet_ecg.ecg_preprocess import ecg_preprocessing\n",
    "from resnet_ecg.densemodel import Net\n",
    "from resnet_ecg.ecg import resnetmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import extract_basic_features\n",
    "\n",
    "import wfdb\n",
    "import os\n",
    "import wfdb.processing as wp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from utils import find_noise_features, extract_basic_features\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import random as rn\n",
    "#from lightgbm import LGBMClassifier\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "#from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping,ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(session )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.io as sio\n",
    "train_dataset_path = os.getcwd()+\"/Train/\"\n",
    "val_dataset_path = os.getcwd()+\"/Val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = os.listdir(train_dataset_path)\n",
    "train_files.sort()\n",
    "val_files = os.listdir(val_dataset_path)\n",
    "val_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>label6</th>\n",
       "      <th>label7</th>\n",
       "      <th>label8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN0001</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN0002</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN0003</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN0004</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN0005</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File_name  label1  label2  label3  label4  label5  label6  label7  label8\n",
       "0  TRAIN0001       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "1  TRAIN0002       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "2  TRAIN0003       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "3  TRAIN0004       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "4  TRAIN0005       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"reference.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    # Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "    \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    # Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/JDWorkSpace/vyuf0458/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/JDWorkSpace/uuser/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/JDWorkSpace/vyuf0458/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model_densenet1 = load_model(\"weights_best_simple_model_10_837.hdf5\",custom_objects={'fmeasure':fmeasure,\n",
    "                                                                           'recall':recall,\n",
    "                                                                           'precision':precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_densenet2 = load_model(\"weights_best_simple_model_10_833.hdf5\",custom_objects={'fmeasure':fmeasure,\n",
    "                                                                           'recall':recall,\n",
    "                                                                           'precision':precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_seg(data_path, split = \"Train\",preprocess=False,fs=500,newFs=256,winSecond=10,winNum=10,n_index=0):\n",
    "    \"\"\" Read data \"\"\"\n",
    "\n",
    "    # Fixed params\n",
    "    #n_index = 0\n",
    "    n_class = 9\n",
    "    winSize = winSecond*fs\n",
    "    new_winSize = winSecond*newFs\n",
    "    # Paths\n",
    "    path_signals = os.path.join(data_path, split)\n",
    "\n",
    "    # Read labels and one-hot encode\n",
    "    #label_path = os.path.join(data_path, \"reference.txt\")\n",
    "    #labels = pd.read_csv(label_path, sep='\\t',header = None)\n",
    "    #labels = pd.read_csv(\"reference.csv\")\n",
    "\n",
    "    # Read time-series data\n",
    "    channel_files = os.listdir(path_signals)\n",
    "    #print(channel_files)\n",
    "    channel_files.sort()\n",
    "    n_channels = 12#len(channel_files)\n",
    "    #posix = len(split) + 5\n",
    "\n",
    "    # Initiate array\n",
    "    list_of_channels = []\n",
    "    \n",
    "    X = np.zeros((len(channel_files), new_winSize, n_channels))\n",
    "    i_ch = 0\n",
    "    \n",
    "    channel_name = ['V6', 'aVF', 'I', 'V4', 'V2', 'aVL', 'V1','II', 'aVR', 'V3', 'III', 'V5']\n",
    "    channel_mid_name = ['II','aVR','V2','V5']\n",
    "    channel_post_name = ['III','aVF','V3','V6']\n",
    "    \n",
    "    for i_ch,fil_ch in enumerate(channel_files[:]):#tqdm\n",
    "        #print(fil_ch)\n",
    "        ecg = sio.loadmat(os.path.join(path_signals,fil_ch))\n",
    "        ecg_length = ecg[\"I\"].shape[1]\n",
    "        \n",
    "        if ecg_length > fs*winNum*winSecond:\n",
    "            print(\" too long !!!\",ecg_length)\n",
    "            ecg_length = fs*winNum*winSecond\n",
    "        if ecg_length < 4500:\n",
    "            print(\" too short !!!\",ecg_length)\n",
    "            break\n",
    "        \n",
    "        slide_steps = int((ecg_length- winSize)/winSecond)\n",
    "        \n",
    "        if ecg_length <= 4500:\n",
    "            slide_steps = 0\n",
    "            \n",
    "        ecg_channels = np.zeros((new_winSize, n_channels))\n",
    "        \n",
    "        for i_n,ch_name in enumerate(channel_name):\n",
    "\n",
    "            ecg_channels[:,i_n] = signal.resample(ecg[ch_name]\n",
    "                                                  [:,n_index*slide_steps:n_index*slide_steps+winSize].T\n",
    "                                                  ,new_winSize).T\n",
    "            if preprocess:\n",
    "                data = ecg_preprocessing(ecg_channels[:,i_n].reshape(1,new_winSize), 'sym8', 8, 3, newFs)\n",
    "                ecg_channels[:,i_n] = data[0]\n",
    "            else:\n",
    "                pass\n",
    "                ecg_channels[:,i_n] = ecg_channels[:,i_n]\n",
    "                \n",
    "        X[i_ch,:,:] = ecg_channels\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecg12_seg0 = read_data_seg(os.getcwd(),n_index=0)\n",
    "ecg12_seg1 = read_data_seg(os.getcwd(),n_index=1)\n",
    "ecg12_seg2 = read_data_seg(os.getcwd(),n_index=2)\n",
    "ecg12_seg3 = read_data_seg(os.getcwd(),n_index=3)\n",
    "ecg12_seg4 = read_data_seg(os.getcwd(),n_index=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecg12_seg5 = read_data_seg(os.getcwd(),n_index=5)\n",
    "ecg12_seg6 = read_data_seg(os.getcwd(),n_index=6)\n",
    "ecg12_seg7 = read_data_seg(os.getcwd(),n_index=7)\n",
    "ecg12_seg8 = read_data_seg(os.getcwd(),n_index=8)\n",
    "ecg12_seg9 = read_data_seg(os.getcwd(),n_index=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x_seg0 = read_data_seg(os.getcwd(),split='Val',n_index=0)\n",
    "test_x_seg1 = read_data_seg(os.getcwd(),split='Val',n_index=1)\n",
    "test_x_seg2 = read_data_seg(os.getcwd(),split='Val',n_index=2)\n",
    "test_x_seg3 = read_data_seg(os.getcwd(),split='Val',n_index=3)\n",
    "test_x_seg4 = read_data_seg(os.getcwd(),split='Val',n_index=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x_seg5 = read_data_seg(os.getcwd(),split='Val',n_index=5)\n",
    "test_x_seg6 = read_data_seg(os.getcwd(),split='Val',n_index=6)\n",
    "test_x_seg7 = read_data_seg(os.getcwd(),split='Val',n_index=7)\n",
    "test_x_seg8 = read_data_seg(os.getcwd(),split='Val',n_index=8)\n",
    "test_x_seg9 = read_data_seg(os.getcwd(),split='Val',n_index=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = [test_x_seg0,test_x_seg1,test_x_seg2,test_x_seg3,test_x_seg4,\n",
    "          test_x_seg5,test_x_seg6,test_x_seg7,test_x_seg8,test_x_seg9,\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import hamming_loss\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = [ecg12_seg0[:],ecg12_seg1[:],ecg12_seg2[:],ecg12_seg3[:],\n",
    "           ecg12_seg4[:],ecg12_seg5[:],ecg12_seg6[:],ecg12_seg7[:],\n",
    "           ecg12_seg8[:],ecg12_seg9[:],\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr_y = model.predict(train_x)#X_tr\n",
    "\n",
    "threshold = np.arange(0.1,0.9,0.1)\n",
    "\n",
    "out = x_tr_y\n",
    "y_test = bin_label#y_tr\n",
    "\n",
    "acc = []\n",
    "accuracies = []\n",
    "best_threshold = np.zeros(out.shape[1])\n",
    "for i in range(out.shape[1]):\n",
    "    y_prob = np.array(out[:,i])\n",
    "    for j in threshold:\n",
    "        y_pred = [1 if prob>=j else 0 for prob in y_prob]\n",
    "        acc.append( matthews_corrcoef(y_test[:,i],y_pred))\n",
    "    acc   = np.array(acc)\n",
    "    index = np.where(acc==acc.max()) \n",
    "    accuracies.append(acc.max()) \n",
    "    best_threshold[i] = threshold[index[0][0]]\n",
    "    acc = []\n",
    "\n",
    "print(\"best_threshold: \",best_threshold)\n",
    "\n",
    "y_pred = np.array([[1 if out[i,j]>=best_threshold[j] else 0 for j in range(y_test.shape[1])] for i in range(len(y_test))])\n",
    "\n",
    "y_pred \n",
    "\n",
    "y_test\n",
    "\n",
    "#best_threshold:  [0.7 0.4 0.5 0.4 0.3 0.2 0.3 0.4 0.4]\n",
    "#0.022393162393162393\n",
    "\n",
    "hamming_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8]\n",
    "\n",
    "y_pred = [[1 if test_y[i,j]>=best_threshold[j] else 0 for j in range(test_y.shape[1])] \n",
    "          for i in range(len(test_y))]\n",
    "pred=[]\n",
    "for j in range(test_y.shape[0]):\n",
    "    pred.append([classes[i] for i in range(9) if y_pred[j][i] == 1])\n",
    "\n",
    "with open('answers116.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['File_name', 'label1', 'label2',\n",
    "                    'label3', 'label4', 'label5', 'label6', 'label7', 'label8'])\n",
    "    count = 0\n",
    "    for file_name in val_files:\n",
    "        if file_name.endswith('.mat'):\n",
    "            \n",
    "            record_name = file_name.strip('.mat')\n",
    "            answer = []\n",
    "            answer.append(record_name)\n",
    "            \n",
    "            result = pred[count]\n",
    "            \n",
    "            answer.extend(result)\n",
    "            for i in range(8-len(result)):\n",
    "                answer.append('')\n",
    "                \n",
    "            #print(answer)\n",
    "            count += 1\n",
    "            writer.writerow(answer)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
