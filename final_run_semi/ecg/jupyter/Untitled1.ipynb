{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/jdcloud'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "train_dataset_path = os.getcwd()+\"/Train/\"\n",
    "val_dataset_path = os.getcwd()+\"/Val/\"\n",
    "#record = \"TRAIN0001\"\n",
    "#ecg = sio.loadmat(dataset_path+record+'.mat')\n",
    "#ecg[\"II\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_files = os.listdir(train_dataset_path)\n",
    "train_files.sort()\n",
    "val_files = os.listdir(val_dataset_path)\n",
    "val_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import extract_basic_features\n",
    "\n",
    "import wfdb\n",
    "import os\n",
    "import wfdb.processing as wp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from utils import find_noise_features, extract_basic_features\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V6', 'aVF', 'I', 'V4', 'V2', 'aVL', 'V1', 'II', 'aVR', 'V3', 'III', 'V5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['V6', 'aVF', 'I', 'V4', 'V2', 'aVL', 'V1',  'II', 'aVR', 'V3', 'III', 'V5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature39_name = [\n",
    "    \"var\", \"skew\", \"kurtosis\", \"perdiogram_1\", \"perdiogram_2\", \"perdiogram_3\",\n",
    "    \"perdiogram_4\", \"qrs_areas_mean\", \"qrs_areas_max\", \"qrs_areas2_mean\",\n",
    "    \"qrs_areas2_max\", \"qrs_malin_mean\", \"qrs_malin_max\", \"qrs_malin2_mean\",\n",
    "    \"qrs_malin2_max\", \"n_plus_mean\", \"n_plus_max\", \"n_plus2_mean\",\n",
    "    \"n_plus2_max\", \"v40_mean\", \"v40_max\", \"v40_2_mean\", \"v40_2_max\",\n",
    "    \"freq_ratio_1\", \"freq_ratio_2\", \"freq_ratio_3\", \"freq_ratio_4\",\n",
    "    \"freq_ratio_5\", \"lorenz_plot\", \"rr_var\", \"rr_var_1\", \"rr_var_2\", \"log_rr\",\n",
    "    \"log_rr_1_abs\", \"sample_entropy_1\", \"sample_entropy_2\",\n",
    "    \"shannon_entropy_1\", \"shannon_entropy_2\", \"correlation\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature39_name_II = [i+'_II' for i in feature39_name]\n",
    "feature39_name_V3 = [i+'_V3' for i in feature39_name]\n",
    "feature39_name_V6 = [i+'_V6' for i in feature39_name]\n",
    "feature39_name_aVF = [i+'_aVF' for i in feature39_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features39_pd = pd.DataFrame(columns=feature39_name_II,index=range(len(train_files)))\n",
    "#features39_pd.head(2)\n",
    "if os.path.exists(\"./feature39/features39_II.csv\"):\n",
    "    features39_pd_II = pd.read_csv(\"./feature39/features39_II.csv\")\n",
    "else:\n",
    "    for i,record in tqdm(enumerate(train_files)):\n",
    "        feat = []\n",
    "        ecg = sio.loadmat(train_dataset_path+record)\n",
    "        feat.extend(extract_basic_features(ecg[\"II\"][0],30000)[0])\n",
    "        features39_pd.loc[i] = feat\n",
    "\n",
    "    features39_pd.to_csv(\"./feature39/features39_II.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features39_pd = pd.DataFrame(columns=feature39_name_V3,index=range(len(train_files)))\n",
    "#features39_pd.head(2)\n",
    "if os.path.exists(\"./feature39/features39_V3.csv\"):\n",
    "    features39_pd_V3 = pd.read_csv(\"./feature39/features39_V3.csv\")\n",
    "else:\n",
    "    for i,record in tqdm(enumerate(train_files)):\n",
    "        feat = []\n",
    "        ecg = sio.loadmat(train_dataset_path+record)\n",
    "        feat.extend(extract_basic_features(ecg[\"V3\"][0],30000)[0])\n",
    "        features39_pd.loc[i] = feat\n",
    "\n",
    "    features39_pd.to_csv(\"./feature39/features39_V3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features39_pd = pd.DataFrame(columns=feature39_name_aVF,index=range(len(train_files)))\n",
    "#features39_pd.head(2)\n",
    "if os.path.exists(\"./feature39/features39_aVF.csv\"):\n",
    "    features39_pd_aVF = pd.read_csv(\"./feature39/features39_aVF.csv\")\n",
    "else:\n",
    "    for i,record in tqdm(enumerate(train_files)):\n",
    "        feat = []\n",
    "        ecg = sio.loadmat(train_dataset_path+record)\n",
    "        feat.extend(extract_basic_features(ecg[\"aVF\"][0],30000)[0])\n",
    "        features39_pd.loc[i] = feat\n",
    "\n",
    "    features39_pd.to_csv(\"./feature39/features39_aVF.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_aVF</th>\n",
       "      <th>skew_aVF</th>\n",
       "      <th>kurtosis_aVF</th>\n",
       "      <th>perdiogram_1_aVF</th>\n",
       "      <th>perdiogram_2_aVF</th>\n",
       "      <th>perdiogram_3_aVF</th>\n",
       "      <th>perdiogram_4_aVF</th>\n",
       "      <th>qrs_areas_mean_aVF</th>\n",
       "      <th>qrs_areas_max_aVF</th>\n",
       "      <th>qrs_areas2_mean_aVF</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_aVF</th>\n",
       "      <th>rr_var_1_aVF</th>\n",
       "      <th>rr_var_2_aVF</th>\n",
       "      <th>log_rr_aVF</th>\n",
       "      <th>log_rr_1_abs_aVF</th>\n",
       "      <th>sample_entropy_1_aVF</th>\n",
       "      <th>sample_entropy_2_aVF</th>\n",
       "      <th>shannon_entropy_1_aVF</th>\n",
       "      <th>shannon_entropy_2_aVF</th>\n",
       "      <th>correlation_aVF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.973077</td>\n",
       "      <td>5.619959</td>\n",
       "      <td>-2650.546673</td>\n",
       "      <td>-2726.159403</td>\n",
       "      <td>-3797.366533</td>\n",
       "      <td>-4645.815144</td>\n",
       "      <td>-0.403650</td>\n",
       "      <td>0.291697</td>\n",
       "      <td>-0.370628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>5.240436</td>\n",
       "      <td>0.417410</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.014903</td>\n",
       "      <td>3.106891</td>\n",
       "      <td>3.664498</td>\n",
       "      <td>0.017238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.320714</td>\n",
       "      <td>4.101945</td>\n",
       "      <td>-2650.010695</td>\n",
       "      <td>-2729.089201</td>\n",
       "      <td>-3506.634461</td>\n",
       "      <td>-4685.315704</td>\n",
       "      <td>-0.161361</td>\n",
       "      <td>-0.022024</td>\n",
       "      <td>0.064970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>3.640313</td>\n",
       "      <td>0.307430</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.121928</td>\n",
       "      <td>2.947703</td>\n",
       "      <td>0.013937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>4.478735</td>\n",
       "      <td>27.801425</td>\n",
       "      <td>-2935.066394</td>\n",
       "      <td>-2580.475229</td>\n",
       "      <td>-3422.428275</td>\n",
       "      <td>-4410.786190</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.609383</td>\n",
       "      <td>0.748391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>3.291774</td>\n",
       "      <td>0.624371</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.947703</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.023624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>2.959382</td>\n",
       "      <td>13.857385</td>\n",
       "      <td>-2869.382688</td>\n",
       "      <td>-2510.926131</td>\n",
       "      <td>-3406.283269</td>\n",
       "      <td>-4391.724005</td>\n",
       "      <td>0.277225</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.443753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>4.931958</td>\n",
       "      <td>0.733631</td>\n",
       "      <td>4.510860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.807355</td>\n",
       "      <td>3.546594</td>\n",
       "      <td>0.010383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>4.321433</td>\n",
       "      <td>22.709594</td>\n",
       "      <td>-2899.025262</td>\n",
       "      <td>-2507.509796</td>\n",
       "      <td>-3426.970090</td>\n",
       "      <td>-4490.410194</td>\n",
       "      <td>0.779407</td>\n",
       "      <td>0.851157</td>\n",
       "      <td>0.917017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>3.639155</td>\n",
       "      <td>0.346044</td>\n",
       "      <td>3.113515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.921928</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>0.033133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_aVF  skew_aVF  kurtosis_aVF  perdiogram_1_aVF  perdiogram_2_aVF  \\\n",
       "6495   0.0002 -0.973077      5.619959      -2650.546673      -2726.159403   \n",
       "6496   0.0002  0.320714      4.101945      -2650.010695      -2729.089201   \n",
       "6497   0.0002  4.478735     27.801425      -2935.066394      -2580.475229   \n",
       "6498   0.0002  2.959382     13.857385      -2869.382688      -2510.926131   \n",
       "6499   0.0002  4.321433     22.709594      -2899.025262      -2507.509796   \n",
       "\n",
       "      perdiogram_3_aVF  perdiogram_4_aVF  qrs_areas_mean_aVF  \\\n",
       "6495      -3797.366533      -4645.815144           -0.403650   \n",
       "6496      -3506.634461      -4685.315704           -0.161361   \n",
       "6497      -3422.428275      -4410.786190            0.553006   \n",
       "6498      -3406.283269      -4391.724005            0.277225   \n",
       "6499      -3426.970090      -4490.410194            0.779407   \n",
       "\n",
       "      qrs_areas_max_aVF  qrs_areas2_mean_aVF  ...  rr_var_aVF  rr_var_1_aVF  \\\n",
       "6495           0.291697            -0.370628  ...    0.000092      0.000102   \n",
       "6496          -0.022024             0.064970  ...    0.000022      0.000051   \n",
       "6497           0.609383             0.748391  ...    0.000273      0.000467   \n",
       "6498           0.469302             0.443753  ...    0.000152      0.000203   \n",
       "6499           0.851157             0.917017  ...    0.000086      0.000110   \n",
       "\n",
       "      rr_var_2_aVF  log_rr_aVF  log_rr_1_abs_aVF  sample_entropy_1_aVF  \\\n",
       "6495      0.000157    5.240436          0.417410              1.945910   \n",
       "6496      0.000153    3.640313          0.307430              3.806662   \n",
       "6497      0.001062    3.291774          0.624371              2.890372   \n",
       "6498      0.000354    4.931958          0.733631              4.510860   \n",
       "6499      0.000194    3.639155          0.346044              3.113515   \n",
       "\n",
       "      sample_entropy_2_aVF  shannon_entropy_1_aVF  shannon_entropy_2_aVF  \\\n",
       "6495              2.014903               3.106891               3.664498   \n",
       "6496              0.000000               3.121928               2.947703   \n",
       "6497              0.000000               2.947703               3.000000   \n",
       "6498              0.000000               3.807355               3.546594   \n",
       "6499              0.000000               2.921928               3.169925   \n",
       "\n",
       "      correlation_aVF  \n",
       "6495         0.017238  \n",
       "6496         0.013937  \n",
       "6497         0.023624  \n",
       "6498         0.010383  \n",
       "6499         0.033133  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features39_pd_aVF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_V3</th>\n",
       "      <th>skew_V3</th>\n",
       "      <th>kurtosis_V3</th>\n",
       "      <th>perdiogram_1_V3</th>\n",
       "      <th>perdiogram_2_V3</th>\n",
       "      <th>perdiogram_3_V3</th>\n",
       "      <th>perdiogram_4_V3</th>\n",
       "      <th>qrs_areas_mean_V3</th>\n",
       "      <th>qrs_areas_max_V3</th>\n",
       "      <th>qrs_areas2_mean_V3</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_V3</th>\n",
       "      <th>rr_var_1_V3</th>\n",
       "      <th>rr_var_2_V3</th>\n",
       "      <th>log_rr_V3</th>\n",
       "      <th>log_rr_1_abs_V3</th>\n",
       "      <th>sample_entropy_1_V3</th>\n",
       "      <th>sample_entropy_2_V3</th>\n",
       "      <th>shannon_entropy_1_V3</th>\n",
       "      <th>shannon_entropy_2_V3</th>\n",
       "      <th>correlation_V3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.254658</td>\n",
       "      <td>10.132419</td>\n",
       "      <td>-3139.927294</td>\n",
       "      <td>-2857.684944</td>\n",
       "      <td>-3509.610393</td>\n",
       "      <td>-4455.358919</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.107293</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>4.936711</td>\n",
       "      <td>0.306514</td>\n",
       "      <td>2.901422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.093069</td>\n",
       "      <td>3.392747</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.491958</td>\n",
       "      <td>13.184237</td>\n",
       "      <td>-2805.594486</td>\n",
       "      <td>-2682.732160</td>\n",
       "      <td>-3399.717929</td>\n",
       "      <td>-4391.845184</td>\n",
       "      <td>-0.333410</td>\n",
       "      <td>-0.039578</td>\n",
       "      <td>-0.207275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>3.640321</td>\n",
       "      <td>0.300236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>0.021378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.469768</td>\n",
       "      <td>9.581992</td>\n",
       "      <td>-2776.026712</td>\n",
       "      <td>-2573.486894</td>\n",
       "      <td>-3448.171587</td>\n",
       "      <td>-4560.492242</td>\n",
       "      <td>0.036918</td>\n",
       "      <td>0.116862</td>\n",
       "      <td>0.274402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>3.291801</td>\n",
       "      <td>0.625959</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.009525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.823176</td>\n",
       "      <td>18.814163</td>\n",
       "      <td>-3002.559350</td>\n",
       "      <td>-2566.866777</td>\n",
       "      <td>-3365.073230</td>\n",
       "      <td>-4329.617643</td>\n",
       "      <td>0.483573</td>\n",
       "      <td>0.653279</td>\n",
       "      <td>0.638949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>4.932016</td>\n",
       "      <td>0.729409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.807355</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>0.005273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.112012</td>\n",
       "      <td>10.492450</td>\n",
       "      <td>-2931.015841</td>\n",
       "      <td>-2495.384526</td>\n",
       "      <td>-3401.777985</td>\n",
       "      <td>-4502.923833</td>\n",
       "      <td>-0.301827</td>\n",
       "      <td>-0.183863</td>\n",
       "      <td>-0.144460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>3.639223</td>\n",
       "      <td>0.333082</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>2.947703</td>\n",
       "      <td>0.019555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_V3   skew_V3  kurtosis_V3  perdiogram_1_V3  perdiogram_2_V3  \\\n",
       "6495  0.0002 -0.254658    10.132419     -3139.927294     -2857.684944   \n",
       "6496  0.0002 -1.491958    13.184237     -2805.594486     -2682.732160   \n",
       "6497  0.0002  0.469768     9.581992     -2776.026712     -2573.486894   \n",
       "6498  0.0002  3.823176    18.814163     -3002.559350     -2566.866777   \n",
       "6499  0.0002 -1.112012    10.492450     -2931.015841     -2495.384526   \n",
       "\n",
       "      perdiogram_3_V3  perdiogram_4_V3  qrs_areas_mean_V3  qrs_areas_max_V3  \\\n",
       "6495     -3509.610393     -4455.358919          -0.142546         -0.107293   \n",
       "6496     -3399.717929     -4391.845184          -0.333410         -0.039578   \n",
       "6497     -3448.171587     -4560.492242           0.036918          0.116862   \n",
       "6498     -3365.073230     -4329.617643           0.483573          0.653279   \n",
       "6499     -3401.777985     -4502.923833          -0.301827         -0.183863   \n",
       "\n",
       "      qrs_areas2_mean_V3  ...  rr_var_V3  rr_var_1_V3  rr_var_2_V3  log_rr_V3  \\\n",
       "6495            0.016435  ...   0.000015     0.000026     0.000076   4.936711   \n",
       "6496           -0.207275  ...   0.000021     0.000051     0.000156   3.640321   \n",
       "6497            0.274402  ...   0.000271     0.000460     0.001034   3.291801   \n",
       "6498            0.638949  ...   0.000151     0.000198     0.000341   4.932016   \n",
       "6499           -0.144460  ...   0.000082     0.000101     0.000174   3.639223   \n",
       "\n",
       "      log_rr_1_abs_V3  sample_entropy_1_V3  sample_entropy_2_V3  \\\n",
       "6495         0.306514             2.901422                  0.0   \n",
       "6496         0.300236             0.000000                  0.0   \n",
       "6497         0.625959             2.890372                  0.0   \n",
       "6498         0.729409             0.000000                  0.0   \n",
       "6499         0.333082             2.708050                  0.0   \n",
       "\n",
       "      shannon_entropy_1_V3  shannon_entropy_2_V3  correlation_V3  \n",
       "6495              3.093069              3.392747        0.001619  \n",
       "6496              3.321928              3.169925        0.021378  \n",
       "6497              3.169925              3.000000        0.009525  \n",
       "6498              3.807355              3.700440        0.005273  \n",
       "6499              3.321928              2.947703        0.019555  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features39_pd_V3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_II</th>\n",
       "      <th>skew_II</th>\n",
       "      <th>kurtosis_II</th>\n",
       "      <th>perdiogram_1_II</th>\n",
       "      <th>perdiogram_2_II</th>\n",
       "      <th>perdiogram_3_II</th>\n",
       "      <th>perdiogram_4_II</th>\n",
       "      <th>qrs_areas_mean_II</th>\n",
       "      <th>qrs_areas_max_II</th>\n",
       "      <th>qrs_areas2_mean_II</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_II</th>\n",
       "      <th>rr_var_1_II</th>\n",
       "      <th>rr_var_2_II</th>\n",
       "      <th>log_rr_II</th>\n",
       "      <th>log_rr_1_abs_II</th>\n",
       "      <th>sample_entropy_1_II</th>\n",
       "      <th>sample_entropy_2_II</th>\n",
       "      <th>shannon_entropy_1_II</th>\n",
       "      <th>shannon_entropy_2_II</th>\n",
       "      <th>correlation_II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.841733</td>\n",
       "      <td>1.038107</td>\n",
       "      <td>-2669.878220</td>\n",
       "      <td>-2771.567454</td>\n",
       "      <td>-3810.314383</td>\n",
       "      <td>-4793.906284</td>\n",
       "      <td>-0.196164</td>\n",
       "      <td>0.078146</td>\n",
       "      <td>-0.032934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>4.936672</td>\n",
       "      <td>0.291623</td>\n",
       "      <td>2.901422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.093069</td>\n",
       "      <td>3.546594</td>\n",
       "      <td>0.016704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.519052</td>\n",
       "      <td>4.918307</td>\n",
       "      <td>-2685.042392</td>\n",
       "      <td>-2772.809633</td>\n",
       "      <td>-3488.640617</td>\n",
       "      <td>-4599.295090</td>\n",
       "      <td>-0.135883</td>\n",
       "      <td>-0.085005</td>\n",
       "      <td>0.096052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>3.640329</td>\n",
       "      <td>0.303798</td>\n",
       "      <td>3.113515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921928</td>\n",
       "      <td>2.947703</td>\n",
       "      <td>0.013599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.864339</td>\n",
       "      <td>22.254192</td>\n",
       "      <td>-2888.383063</td>\n",
       "      <td>-2552.276433</td>\n",
       "      <td>-3438.568042</td>\n",
       "      <td>-4487.089356</td>\n",
       "      <td>0.576914</td>\n",
       "      <td>0.632430</td>\n",
       "      <td>0.785903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>3.291834</td>\n",
       "      <td>0.620898</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.628166</td>\n",
       "      <td>16.663626</td>\n",
       "      <td>-2909.116812</td>\n",
       "      <td>-2470.863495</td>\n",
       "      <td>-3406.564221</td>\n",
       "      <td>-4413.050057</td>\n",
       "      <td>0.509271</td>\n",
       "      <td>0.647335</td>\n",
       "      <td>0.646033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>4.932390</td>\n",
       "      <td>0.702343</td>\n",
       "      <td>2.901422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.807355</td>\n",
       "      <td>3.392747</td>\n",
       "      <td>0.007635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.663893</td>\n",
       "      <td>17.212268</td>\n",
       "      <td>-2886.312087</td>\n",
       "      <td>-2515.476059</td>\n",
       "      <td>-3434.087598</td>\n",
       "      <td>-4546.008119</td>\n",
       "      <td>0.725843</td>\n",
       "      <td>0.782350</td>\n",
       "      <td>0.872075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>3.639105</td>\n",
       "      <td>0.343690</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921928</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>0.026671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_II   skew_II  kurtosis_II  perdiogram_1_II  perdiogram_2_II  \\\n",
       "6495  0.0002  0.841733     1.038107     -2669.878220     -2771.567454   \n",
       "6496  0.0002  0.519052     4.918307     -2685.042392     -2772.809633   \n",
       "6497  0.0002  3.864339    22.254192     -2888.383063     -2552.276433   \n",
       "6498  0.0002  3.628166    16.663626     -2909.116812     -2470.863495   \n",
       "6499  0.0002  3.663893    17.212268     -2886.312087     -2515.476059   \n",
       "\n",
       "      perdiogram_3_II  perdiogram_4_II  qrs_areas_mean_II  qrs_areas_max_II  \\\n",
       "6495     -3810.314383     -4793.906284          -0.196164          0.078146   \n",
       "6496     -3488.640617     -4599.295090          -0.135883         -0.085005   \n",
       "6497     -3438.568042     -4487.089356           0.576914          0.632430   \n",
       "6498     -3406.564221     -4413.050057           0.509271          0.647335   \n",
       "6499     -3434.087598     -4546.008119           0.725843          0.782350   \n",
       "\n",
       "      qrs_areas2_mean_II  ...  rr_var_II  rr_var_1_II  rr_var_2_II  log_rr_II  \\\n",
       "6495           -0.032934  ...   0.000016     0.000029     0.000076   4.936672   \n",
       "6496            0.096052  ...   0.000021     0.000052     0.000160   3.640329   \n",
       "6497            0.785903  ...   0.000269     0.000458     0.001032   3.291834   \n",
       "6498            0.646033  ...   0.000140     0.000185     0.000324   4.932390   \n",
       "6499            0.872075  ...   0.000088     0.000114     0.000206   3.639105   \n",
       "\n",
       "      log_rr_1_abs_II  sample_entropy_1_II  sample_entropy_2_II  \\\n",
       "6495         0.291623             2.901422                  0.0   \n",
       "6496         0.303798             3.113515                  0.0   \n",
       "6497         0.620898             2.484907                  0.0   \n",
       "6498         0.702343             2.901422                  0.0   \n",
       "6499         0.343690             2.708050                  0.0   \n",
       "\n",
       "      shannon_entropy_1_II  shannon_entropy_2_II  correlation_II  \n",
       "6495              3.093069              3.546594        0.016704  \n",
       "6496              2.921928              2.947703        0.013599  \n",
       "6497              3.169925              3.000000        0.023461  \n",
       "6498              3.807355              3.392747        0.007635  \n",
       "6499              2.921928              3.169925        0.026671  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features39_pd_II.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>label6</th>\n",
       "      <th>label7</th>\n",
       "      <th>label8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN0001</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN0002</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN0003</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN0004</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN0005</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File_name  label1  label2  label3  label4  label5  label6  label7  label8\n",
       "0  TRAIN0001       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "1  TRAIN0002       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "2  TRAIN0003       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "3  TRAIN0004       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "4  TRAIN0005       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"reference.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test finished!\n"
     ]
    }
   ],
   "source": [
    "#!/bin/python\n",
    "from ctypes import  *\n",
    "import os\n",
    "\n",
    "class StructPointer(Structure):  \n",
    "    _fields_ = [(\"RR_mean\", c_double),(\"RR_min\", c_double),(\"RR_max\", c_double),(\"HR_median\", c_double),\n",
    "    (\"AFEv\", c_int), (\"IrrEv\", c_int),(\"CV\", c_double), (\"MAD\",c_double), (\"CosEn\", c_double),(\"Radius\", c_double),\n",
    "    (\"CV_deltaRR\", c_double)]  \n",
    "\t\n",
    "hr=[240,200,256,260]  #,248,238,250,239,243,270\n",
    "carrary = (c_int * len(hr))(*hr)\n",
    "fs=256\n",
    "mylib = cdll.LoadLibrary(\"featcaculate.so\")\n",
    "mylib.AFDet.restype = POINTER(StructPointer) \n",
    "c_result = mylib.AFDet(carrary,len(hr),fs,1)\n",
    "\n",
    "# print(c_result.contents.AFEv)\n",
    "# print(c_result.contents.CV)\n",
    "print(\"test finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/jdcloud'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09927874910213115"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_result.contents.CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params2={\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':819,\n",
    " 'max_depth':8,\n",
    " 'num_leaves':115,\n",
    " 'min_child_weight':0,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'min_child_samples':21,\n",
    " 'objective':'multiclass',\n",
    " 'reg_alpha':0.15,\n",
    " 'reg_lambda' : 0.01,\n",
    " 'num_class': 9,\n",
    " 'n_jobs':4,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([features39_pd_II,features39_pd_V3,features39_pd_aVF],axis=1)#features315_pd#\n",
    "feature_name = feature39_name_II+feature39_name_V3+feature39_name_aVF#feature39_name\n",
    "train_labels = labels['label1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = LabelEncoder().fit_transform(train_labels)\n",
    "#label_encoder_y = LabelEncoder().(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_y(y,num_class=9):\n",
    "    bin_label = np.zeros((y.shape[0],num_class))\n",
    "    for i in range(y.shape[0]):\n",
    "        label_nona = labels.loc[y.index.tolist()[i]].dropna()\n",
    "        for j in range(1,label_nona.shape[0]):\n",
    "            bin_label[i,int(label_nona[j])]=1\n",
    "    return bin_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_labels = preprocess_y(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_eatimators=500,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneVsRestClassifier(xgb.XGBClassifier(learning_rate=0.005,n_eatimators=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold :  1\n",
      "... time passed: 29.0sec , fold F1 : 0.5603\n",
      "fold :  2\n",
      "... time passed: 29.2sec , fold F1 : 0.5650\n",
      "fold :  3\n",
      "... time passed: 29.1sec , fold F1 : 0.5613\n",
      "fold :  4\n",
      "... time passed: 29.1sec , fold F1 : 0.5342\n",
      "fold :  5\n",
      "... time passed: 29.4sec , fold F1 : 0.5690\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "n_classes = 9\n",
    "kfold = KFold(n_folds,shuffle=True,random_state=123)\n",
    "\n",
    "#kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=123)\n",
    "kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "blend_train = np.zeros((train_df.shape[0],n_classes))\n",
    "blend_test = np.zeros((val_df.shape[0],n_folds,n_classes))\n",
    "\n",
    "for i,(train_ind,val_ind) in enumerate(kf):\n",
    "    t = time.time()\n",
    "    print(\"fold : \",i+1)\n",
    "    X = train_df[feature_name].astype('float32')\n",
    "    X_train = X.iloc[train_ind]\n",
    "    y_train = bin_labels[train_ind]\n",
    "    \n",
    "    X_val = X.iloc[val_ind]\n",
    "    y_val = bin_labels[val_ind]\n",
    "    \n",
    "    X_test = val_df[feature_name].astype('float32')\n",
    "    \n",
    "    clf = OneVsRestClassifier(xgb.XGBClassifier(learning_rate=0.005,n_eatimators=500))\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    y_p_v = clf.predict_proba(X_val)\n",
    "    y_p_test = clf.predict_proba(X_test)\n",
    "    \n",
    "    blend_train[val_ind,:] = y_p_v\n",
    "    blend_test[:,i,:] = y_p_test\n",
    "    \n",
    "    f1 = f1_score(y_val,1*y_p_v>0.4,average='macro')\n",
    "    print(\"... time passed: {0:.1f}sec , fold F1 : {1:.4f}\".format(time.time()-t,f1))\n",
    "    \n",
    "f1 = f1_score(bin_labels,1*blend_train>0.4,average='macro')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "... time passed: 2915.9sec , fold F1 : 0.6483\n",
      "fold:  1  training\n",
      "... time passed: 2967.4sec , fold F1 : 0.6617\n",
      "fold:  2  training\n",
      "... time passed: 3020.2sec , fold F1 : 0.6531\n",
      "fold:  3  training\n",
      "... time passed: 3068.4sec , fold F1 : 0.6409\n",
      "fold:  4  training\n",
      "... time passed: 3117.1sec , fold F1 : 0.6216\n",
      "fold f1 score is 0.6454172267221155\n"
     ]
    }
   ],
   "source": [
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_params={\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':819,\n",
    " 'max_depth':8,\n",
    " 'num_leaves':115,\n",
    " 'min_child_weight':0,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'min_child_samples':21,\n",
    " 'objective':'binary',#'multiclass',\n",
    " 'reg_alpha':0.15,\n",
    " 'reg_lambda' : 0.01,\n",
    " 'num_class': 1,\n",
    " 'n_jobs':4,\n",
    "  'verbosity':2,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}\n",
    "\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 5\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data_df = train_df[feature_name].astype('float32') #feature_name  columns\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data_df\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_data_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "\n",
    "        X = train_df[feature_name].astype('float32')\n",
    "        X_train = X.iloc[train_fold]\n",
    "        y_train = bin_labels[train_fold]\n",
    "\n",
    "        X_val = X.iloc[validate]\n",
    "        y_val = bin_labels[validate]\n",
    "\n",
    "        X_test = val_df[feature_name].astype('float32')\n",
    "        #print(X_validate)\n",
    "        #break\n",
    "        #dtrain = lgb.Dataset(X_train, label_train)\n",
    "        #dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        bst = OneVsRestClassifier(lgb.LGBMClassifier(**lgb_params))\n",
    "        #, dtrain, num_boost_round=819, valid_sets=dvalid, verbose_eval=200,early_stopping_rounds=500)\n",
    "        bst.fit(X_train, y_train)\n",
    "        \n",
    "        y_p_v = bst.predict_proba(X_val)\n",
    "        y_p_test = bst.predict_proba(X_test)\n",
    "\n",
    "        blend_train[validate,:] = y_p_v\n",
    "        blend_test[:,i,:] = y_p_test\n",
    "\n",
    "        f1 = f1_score(y_val,1*y_p_v>0.4,average='macro')\n",
    "        print(\"... time passed: {0:.1f}sec , fold F1 : {1:.4f}\".format(time.time()-t,f1))\n",
    "    \n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "fold_f1_error = f1_score(bin_labels,1*blend_train>0.4,average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "#F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_labels.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_p_tst = blend_test.mean(axis=1)#>0.4\n",
    "\n",
    "classes = [0,1,2,3,4,5,6,7,8]\n",
    "thred = 0.4 #0.15\n",
    "test_y = y_p_tst\n",
    "y_pred = [[1 if test_y[i,j] >= thred else 0 for j in range(test_y.shape[1])] \n",
    "          for i in range(len(test_y))]\n",
    "pred=[]\n",
    "for j in range(test_y.shape[0]):\n",
    "    pred.append([classes[i] for i in range(9) if y_pred[j][i] == 1])\n",
    "\n",
    "with open('answers1.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['File_name', 'label1', 'label2',\n",
    "                    'label3', 'label4', 'label5', 'label6', 'label7', 'label8'])\n",
    "    count = 0\n",
    "    for file_name in val_files:\n",
    "        if file_name.endswith('.mat'):\n",
    "            \n",
    "            record_name = file_name.strip('.mat')\n",
    "            answer = []\n",
    "            answer.append(record_name)\n",
    "            \n",
    "            result = pred[count]\n",
    "            \n",
    "            answer.extend(result)\n",
    "            for i in range(8-len(result)):\n",
    "                answer.append('')\n",
    "                \n",
    "            #print(answer)\n",
    "            count += 1\n",
    "            writer.writerow(answer)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.95781\n",
      "[400]\tvalid_0's multi_logloss: 0.790339\n",
      "[600]\tvalid_0's multi_logloss: 0.732317\n",
      "[800]\tvalid_0's multi_logloss: 0.714109\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[817]\tvalid_0's multi_logloss: 0.713529\n",
      "fold:  1  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 1.00614\n",
      "[400]\tvalid_0's multi_logloss: 0.840589\n",
      "[600]\tvalid_0's multi_logloss: 0.787958\n",
      "[800]\tvalid_0's multi_logloss: 0.772766\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[816]\tvalid_0's multi_logloss: 0.772532\n",
      "fold:  2  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 1.01114\n",
      "[400]\tvalid_0's multi_logloss: 0.867016\n",
      "[600]\tvalid_0's multi_logloss: 0.822438\n",
      "[800]\tvalid_0's multi_logloss: 0.813291\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[810]\tvalid_0's multi_logloss: 0.813036\n",
      "fold:  3  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.980984\n",
      "[400]\tvalid_0's multi_logloss: 0.821969\n",
      "[600]\tvalid_0's multi_logloss: 0.783469\n",
      "[800]\tvalid_0's multi_logloss: 0.77543\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[791]\tvalid_0's multi_logloss: 0.775094\n",
      "fold:  4  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.981946\n",
      "[400]\tvalid_0's multi_logloss: 0.831734\n",
      "[600]\tvalid_0's multi_logloss: 0.795717\n",
      "[800]\tvalid_0's multi_logloss: 0.791443\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[725]\tvalid_0's multi_logloss: 0.790703\n",
      "fold:  5  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 1.00037\n",
      "[400]\tvalid_0's multi_logloss: 0.856139\n",
      "[600]\tvalid_0's multi_logloss: 0.821182\n",
      "[800]\tvalid_0's multi_logloss: 0.818037\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[716]\tvalid_0's multi_logloss: 0.816233\n",
      "fold:  6  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 1.01675\n",
      "[400]\tvalid_0's multi_logloss: 0.878572\n",
      "[600]\tvalid_0's multi_logloss: 0.839428\n",
      "[800]\tvalid_0's multi_logloss: 0.833711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[729]\tvalid_0's multi_logloss: 0.832908\n",
      "fold:  7  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.976416\n",
      "[400]\tvalid_0's multi_logloss: 0.831923\n",
      "[600]\tvalid_0's multi_logloss: 0.802307\n",
      "[800]\tvalid_0's multi_logloss: 0.800229\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[680]\tvalid_0's multi_logloss: 0.798028\n",
      "fold:  8  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.990728\n",
      "[400]\tvalid_0's multi_logloss: 0.840921\n",
      "[600]\tvalid_0's multi_logloss: 0.801758\n",
      "[800]\tvalid_0's multi_logloss: 0.794741\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[787]\tvalid_0's multi_logloss: 0.794341\n",
      "fold:  9  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.997157\n",
      "[400]\tvalid_0's multi_logloss: 0.841803\n",
      "[600]\tvalid_0's multi_logloss: 0.792406\n",
      "[800]\tvalid_0's multi_logloss: 0.778705\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[816]\tvalid_0's multi_logloss: 0.778307\n",
      "fold f1 score is 0.6364096591623809\n"
     ]
    }
   ],
   "source": [
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 10\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data_df = train_df[feature_name].astype('float32') #feature_name  columns\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data_df\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_data_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \\\n",
    "        train_label[train_fold], train_label[validate]\n",
    "        #print(X_validate)\n",
    "        #break\n",
    "        dtrain = lgb.Dataset(X_train, label_train)\n",
    "        dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        bst = lgb.train(lgb_params2, dtrain, num_boost_round=819, valid_sets=dvalid, verbose_eval=200,early_stopping_rounds=500)\n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "        oof[validate] = np.argmax(k_pred,axis=1)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = count + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "oof = list(map(int, oof))\n",
    "fold_f1_error = f1_score(train_labels, oof, average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "#F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_labels.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:07, 68.12it/s]\n"
     ]
    }
   ],
   "source": [
    "val_features39_II = pd.DataFrame(columns=feature39_name_II,index=range(len(val_files)))\n",
    "for i,record in tqdm(enumerate(val_files)):\n",
    "    feat = []\n",
    "    ecg = sio.loadmat(val_dataset_path+record)\n",
    "    feat.extend(extract_basic_features(ecg[\"II\"][0],30000)[0])\n",
    "    val_features39_II.loc[i] = feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:07, 69.94it/s]\n"
     ]
    }
   ],
   "source": [
    "val_features39_V3 = pd.DataFrame(columns=feature39_name_V3,index=range(len(val_files)))\n",
    "for i,record in tqdm(enumerate(val_files)):\n",
    "    feat = []\n",
    "    ecg = sio.loadmat(val_dataset_path+record)\n",
    "    feat.extend(extract_basic_features(ecg[\"V3\"][0],30000)[0])\n",
    "    val_features39_V3.loc[i] = feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:07, 68.08it/s]\n"
     ]
    }
   ],
   "source": [
    "val_features39_aVF = pd.DataFrame(columns=feature39_name_aVF,index=range(len(val_files)))\n",
    "for i,record in tqdm(enumerate(val_files)):\n",
    "    feat = []\n",
    "    ecg = sio.loadmat(val_dataset_path+record)\n",
    "    feat.extend(extract_basic_features(ecg[\"aVF\"][0],30000)[0])\n",
    "    val_features39_aVF.loc[i] = feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_df = pd.concat([val_features39_II,val_features39_V3,val_features39_aVF],axis=1)#features315_pd#\n",
    "feature_name = feature39_name_II+feature39_name_V3+feature39_name_aVF#feature39_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dfeatures = train_df[feature_name].values\n",
    "x_tr_y = bst.predict(train_dfeatures)\n",
    "\n",
    "#x_tr_y = model.predict(train_x)#X_tr\n",
    "\n",
    "threshold = np.arange(0.1,0.9,0.1)\n",
    "\n",
    "out = x_tr_y\n",
    "y_test = bin_label#y_tr\n",
    "\n",
    "acc = []\n",
    "accuracies = []\n",
    "best_threshold = np.zeros(out.shape[1])\n",
    "for i in range(out.shape[1]):\n",
    "    y_prob = np.array(out[:,i])\n",
    "    for j in threshold:\n",
    "        y_pred = [1 if prob>=j else 0 for prob in y_prob]\n",
    "        #acc.append( matthews_corrcoef(y_test[:,i],y_pred))\n",
    "        acc.append(f1_score(y_test[:,i],y_pred,average='macro'))\n",
    "    acc   = np.array(acc)\n",
    "    index = np.where(acc==acc.max()) \n",
    "    accuracies.append(acc.max()) \n",
    "    best_threshold[i] = threshold[index[0][0]]\n",
    "    acc = []\n",
    "    \n",
    "print(\"best_threshold: \",best_threshold)\n",
    "\n",
    "y_pred = np.array([[1 if out[i,j]>=best_threshold[j] else 0 for j in range(y_test.shape[1])] for i in range(len(y_test))])\n",
    "\n",
    "y_pred \n",
    "\n",
    "y_test\n",
    "\n",
    "#best_threshold:  [0.7 0.4 0.5 0.4 0.3 0.2 0.3 0.4 0.4]\n",
    "#0.022393162393162393\n",
    "\n",
    "#best_threshold:  [0.7 0.4 0.5 0.4 0.4 0.2 0.4 0.4 0.5]\n",
    "#0.022615384615384617\n",
    "\n",
    "hamming_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dfeatures = val_df[feature_name].values\n",
    "kpred = bst.predict(dfeatures)\n",
    "\n",
    "pred = []\n",
    "thred = 0.15 #0.15\n",
    "for i in range(kpred.shape[0]):\n",
    "    pred.append( list(np.hstack(np.argwhere(kpred[i]>thred))))\n",
    "    \n",
    "with open('answers.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['File_name', 'label1', 'label2',\n",
    "                    'label3', 'label4', 'label5', 'label6', 'label7', 'label8'])\n",
    "    count = 0\n",
    "    for file_name in val_files:\n",
    "        if file_name.endswith('.mat'):\n",
    "            \n",
    "            record_name = file_name.strip('.mat')\n",
    "            answer = []\n",
    "            answer.append(record_name)\n",
    "            \n",
    "            result = pred[count]\n",
    "            \n",
    "            answer.extend(result)\n",
    "            for i in range(8-len(result)):\n",
    "                answer.append('')\n",
    "                \n",
    "            #print(answer)\n",
    "            count += 1\n",
    "            writer.writerow(answer)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First 315 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features_st import entropy,pyeeg\n",
    "from features_st.features.features_submit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate Features object\n",
    "#file_name = \"TRAIN0001\"\n",
    "def generate_features315(dataset_path,file_name):\n",
    "    ecg_features = FeaturesSubmit(\n",
    "        file_path=os.path.join(dataset_path, file_name+'.mat'),\n",
    "        file_name=file_name,\n",
    "        fs=500,\n",
    "        feature_groups=[\n",
    "            'full_waveform_statistics',\n",
    "            'heart_rate_variability_statistics',\n",
    "            'template_statistics'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate ECG features\n",
    "    ecg_features.calculate_features(\n",
    "        filter_bandwidth=[3, 45], show=False,\n",
    "        normalize=True, polarity_check=True,\n",
    "        template_before=0.25, template_after=0.4\n",
    "    )\n",
    "\n",
    "    # Get features DataFrame\n",
    "    features = ecg_features.get_features()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"features315_II.csv\"):\n",
    "    features315_pd = pd.read_csv(\"features315_II.csv\")\n",
    "else:\n",
    "    features315_pd = generate_features315(train_dataset_path,\"TRAIN0001\")\n",
    "    for file_name in tqdm(train_files[1:]):\n",
    "        df_temp = generate_features315(train_dataset_path,file_name.strip('.mat'))\n",
    "        features315_pd = pd.concat([features315_pd,df_temp])\n",
    "    features315_pd.to_csv(\"features315_II.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features315_name = set(features315_pd.columns.values) - set(['File_name'])\n",
    "len(features315_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "      <th>label6</th>\n",
       "      <th>label7</th>\n",
       "      <th>label8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN0001</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN0002</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN0003</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN0004</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN0005</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File_name  label1  label2  label3  label4  label5  label6  label7  label8\n",
       "0  TRAIN0001       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "1  TRAIN0002       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "2  TRAIN0003       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "3  TRAIN0004       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN\n",
       "4  TRAIN0005       8     NaN     NaN     NaN     NaN     NaN     NaN     NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"reference.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_labels = labels.copy()\n",
    "ex_features315_pd = features315_pd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(labels.shape[0])[:]:\n",
    "    label_nona = labels.loc[i].dropna()\n",
    "    if label_nona.shape[0]>2:\n",
    "        for j in range(1,label_nona.shape[0]-1):\n",
    "            #print(label_nona['File_name'])\n",
    "            #print(label_nona['label'+str(j+1)])\n",
    "            label_row = [label_nona['File_name'],label_nona['label'+str(j+1)],'','','','','','','']\n",
    "            ex_labels.loc[ex_labels.shape[0]]=label_row\n",
    "            ex_features315_pd.loc[ex_labels.shape[0]] = ex_features315_pd.iloc[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_labels.to_csv(\"ex_labels.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_features315_pd.to_csv(\"ex_features315_II.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1953\n",
       "8    1547\n",
       "3     714\n",
       "6     571\n",
       "5     520\n",
       "2     449\n",
       "1     430\n",
       "7     205\n",
       "4     111\n",
       "Name: label1, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"label1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum1_label=0\n",
    "sum2_label=0\n",
    "sum3_label=0\n",
    "sum4_label=0\n",
    "sum5_label=0\n",
    "sum6_label=0\n",
    "sum7_label=0\n",
    "bin_label = np.zeros((6500,9))\n",
    "for i in range(labels.shape[0]):\n",
    "    label_nona = labels.loc[i].dropna()\n",
    "    if label_nona.shape[0] == 2:\n",
    "        sum1_label+=1\n",
    "    if label_nona.shape[0] == 3:\n",
    "        sum2_label+=1\n",
    "    if label_nona.shape[0] == 4:\n",
    "        sum3_label+=1\n",
    "    if label_nona.shape[0] == 5:\n",
    "        sum4_label+=1\n",
    "    if label_nona.shape[0] == 6:\n",
    "        sum5_label+=1\n",
    "    if label_nona.shape[0] == 7:\n",
    "        sum6_label+=1\n",
    "    if label_nona.shape[0] == 8:\n",
    "        sum7_label+=1\n",
    "    for j in range(1,label_nona.shape[0]):\n",
    "        bin_label[i,int(label_nona[j])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum6_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7703"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum1_label + sum2_label*2 + sum3_label*3 + sum4_label*4 + sum5_label*5 + sum6_label*6 + sum7_label*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params2={\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':819,\n",
    " 'max_depth':8,\n",
    " 'num_leaves':115,\n",
    " 'min_child_weight':0,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'min_child_samples':21,\n",
    " 'objective':'multiclass',\n",
    " 'reg_alpha':0.15,\n",
    " 'reg_lambda' : 0.01,\n",
    " 'num_class': 9,\n",
    " 'n_jobs':4,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = features315_pd#ex_features315_pd#features315_pd#features39_pd\n",
    "feature_name = ['t_wave_eng',\n",
    " 's_wave_amp',\n",
    " 'p_wave_eng',\n",
    " 'q_wave_amp',\n",
    " 't_wave_corr_coeff_std',\n",
    " 't_wave_amp',\n",
    " 'pt_time',\n",
    " 'p_wave_time',\n",
    " 'rri_skew',\n",
    " 'p_wave_amp',\n",
    " 'p_wave_corr_coeff_std',\n",
    " 'rri_multiscale_entropy',\n",
    " 'rpeak_multiscale_entropy',\n",
    " 'pq_time',\n",
    " 't_wave_sample_entropy_median',\n",
    " 'swt_a_1_med_power_ratio',\n",
    " 'diff_rri_multiscale_entropy',\n",
    " 'full_waveform_median',\n",
    " 't_wave_corr_coeff_median',\n",
    " 'p_wave_permutation_entropy_std',\n",
    " 'diff2_rri_multiscale_entropy',\n",
    " 't_wave_higuchi_fractal_median',\n",
    " 'diff_rri_skew',\n",
    " 'template_swt_a_4_low_power_ratio',\n",
    " 't_wave_permutation_entropy_std',\n",
    " 'diff_rri_mean',\n",
    " 'full_waveform_mean',\n",
    " 't_wave_approximate_entropy_median',\n",
    " 'rri_p3_pearson_p_value',\n",
    " 'p_wave_higuchi_fractal_median',\n",
    " 'template_swt_d_1_med_power_ratio',\n",
    " 't_wave_time',\n",
    " 's_wave_time',\n",
    " 'rri_min',\n",
    " 't_wave_hurst_exponent_std',\n",
    " 'full_waveform_skew',\n",
    " 'swt_a_1_higuchi_fractal',\n",
    " 'heart_rate_multiscale_entropy',\n",
    " 'p_wave_multiscale_entropy_std',\n",
    " 'diff_rri_fisher_info',\n",
    " 'p_wave_corr_coeff_median',\n",
    " 'pt_time_std',\n",
    " 'full_waveform_min',\n",
    " 'rri_very_high_frequency_power',\n",
    " 'qrs_corr_coeff_std',\n",
    " 'qt_time',\n",
    " 't_wave_approximate_entropy_std',\n",
    " 'template_swt_a_1_low_power_ratio',\n",
    " 'rri_kurtosis',\n",
    " 'p_wave_sample_entropy_median',\n",
    " 'full_waveform_max',\n",
    " 'diff2_rri_svd_entropy',\n",
    " 'template_swt_d_2_med_power_ratio',\n",
    " 't_wave_sample_entropy_std',\n",
    " 't_wave_higuchi_fractal_std',\n",
    " 'qrs_energy_pearson_p_value',\n",
    " 'p_wave_amp_std',\n",
    " 'swt_d_1_med_power_ratio',\n",
    " 'p_wave_approximate_entropy_std',\n",
    " 'rpeaks_bad',\n",
    " 't_wave_multiscale_permutation_entropy_median',\n",
    " 'qsi_pearson_coeff',\n",
    " 'template_corr_coeff_std',\n",
    " 'st_time',\n",
    " 'template_swt_a_1_med_power_ratio',\n",
    " 'swt_a_1_low_power_ratio',\n",
    " 'q_wave_amp_std',\n",
    " 'p_wave_time_std',\n",
    " 'full_waveform_std',\n",
    " 'rpeak_kurtosis',\n",
    " 'swt_a_1_high_power_ratio',\n",
    " 'rri_cluster_ssd_3',\n",
    " 'template_swt_a_1_high_power_ratio',\n",
    " 'diff2_rri_max',\n",
    " 'heart_rate_skew',\n",
    " 't_wave_amp_std',\n",
    " 'full_waveform_kurtosis',\n",
    " 'diff_rri_svd_entropy',\n",
    " 'swt_d_3_high_power_ratio',\n",
    " 'diff2_rri_min',\n",
    " 'heart_rate_kurtosis',\n",
    " 'swt_d_4_higuchi_fractal',\n",
    " 'pq_time_std',\n",
    " 'rri_p3_pearson_coeff',\n",
    " 'p_wave_higuchi_fractal_std',\n",
    " 'diff2_rri_mean',\n",
    " 'template_swt_d_3_high_power_ratio',\n",
    " 'p_wave_approximate_entropy_median',\n",
    " 'fragmentation_ials',\n",
    " 'diff2_rri_morbidity',\n",
    " 'rri_p2_pearson_p_value',\n",
    " 'p_wave_hurst_exponent_std',\n",
    " 't_wave_hurst_exponent_median',\n",
    " 'diff2_rri_kurtosis',\n",
    " 'template_swt_d_1_low_power_ratio',\n",
    " 'diff2_rri_fisher_info',\n",
    " 'diff_rri_kurtosis',\n",
    " 'rpeak_skew',\n",
    " 'rri_spectral_entropy',\n",
    " 'qrs_energy_std'][:120]#\n",
    "feature_name = features315_name#feature39_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6500"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = labels[\"label1\"].values#labels[\"label1\"].values  #bin_label\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 315)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.809684\n",
      "[400]\tvalid_0's multi_logloss: 0.655225\n"
     ]
    }
   ],
   "source": [
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 10\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data_df = train_df[feature_name].astype('float32') #feature_name  columns\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data_df\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_data_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \\\n",
    "        train_label[train_fold], train_label[validate]\n",
    "        #print(X_validate)\n",
    "        #break\n",
    "        dtrain = lgb.Dataset(X_train, label_train)\n",
    "        dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        bst = lgb.train(lgb_params2, dtrain, num_boost_round=819, valid_sets=dvalid, verbose_eval=200,early_stopping_rounds=500)\n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "        oof[validate] = np.argmax(k_pred,axis=1)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = count + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "oof = list(map(int, oof))\n",
    "fold_f1_error = f1_score(train_labels, oof, average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "#F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_labels.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t_wave_eng',\n",
       " 'pt_time',\n",
       " 'p_wave_time',\n",
       " 'p_wave_eng',\n",
       " 's_wave_amp',\n",
       " 't_wave_amp',\n",
       " 'rri_skew',\n",
       " 'p_wave_corr_coeff_median',\n",
       " 't_wave_higuchi_fractal_median',\n",
       " 't_wave_sample_entropy_median',\n",
       " 'p_wave_amp',\n",
       " 'rri_multiscale_entropy',\n",
       " 't_wave_corr_coeff_std',\n",
       " 'full_waveform_median',\n",
       " 'q_wave_amp',\n",
       " 'p_wave_corr_coeff_std',\n",
       " 't_wave_time',\n",
       " 'swt_a_1_med_power_ratio',\n",
       " 't_wave_corr_coeff_median',\n",
       " 'template_swt_a_4_low_power_ratio',\n",
       " 'full_waveform_skew',\n",
       " 't_wave_approximate_entropy_median',\n",
       " 'st_time',\n",
       " 'qt_time',\n",
       " 'pq_time',\n",
       " 'template_swt_d_1_med_power_ratio',\n",
       " 'rri_cluster_ssd_3',\n",
       " 'rri_kurtosis',\n",
       " 's_wave_time',\n",
       " 'full_waveform_min',\n",
       " 'p_wave_higuchi_fractal_median',\n",
       " 'rpeaks_bad',\n",
       " 'rpeak_multiscale_entropy',\n",
       " 'diff_rri_skew',\n",
       " 'qrs_corr_coeff_std',\n",
       " 'diff_rri_multiscale_entropy',\n",
       " 'rri_min',\n",
       " 'diff_rri_mean',\n",
       " 't_wave_permutation_entropy_std',\n",
       " 'swt_d_1_med_power_ratio',\n",
       " 'full_waveform_max',\n",
       " 'pt_time_std',\n",
       " 'template_swt_a_1_low_power_ratio',\n",
       " 'full_waveform_kurtosis',\n",
       " 'heart_rate_multiscale_entropy',\n",
       " 'p_wave_permutation_entropy_std',\n",
       " 'p_wave_amp_std',\n",
       " 't_wave_hurst_exponent_std',\n",
       " 'template_swt_d_2_med_power_ratio',\n",
       " 't_wave_hurst_exponent_median',\n",
       " 'swt_a_1_higuchi_fractal',\n",
       " 'diff_rri_fisher_info',\n",
       " 'diff2_rri_multiscale_entropy',\n",
       " 't_wave_svd_entropy_median',\n",
       " 'full_waveform_mean',\n",
       " 'swt_a_1_low_power_ratio',\n",
       " 'p_wave_multiscale_entropy_std',\n",
       " 't_wave_multiscale_permutation_entropy_median',\n",
       " 't_wave_higuchi_fractal_std',\n",
       " 'qsi_pearson_p_value',\n",
       " 'diff2_rri_svd_entropy',\n",
       " 'diff2_rri_fisher_info',\n",
       " 'fragmentation_ials',\n",
       " 'p_wave_sample_entropy_median',\n",
       " 'diff2_rri_morbidity',\n",
       " 'qrs_energy_std',\n",
       " 'rri_max',\n",
       " 'swt_d_2_med_power_ratio',\n",
       " 'swt_d_2_higuchi_fractal',\n",
       " 'rri_p3_pearson_p_value',\n",
       " 't_wave_fisher_info_median',\n",
       " 'diff_rri_max',\n",
       " 'p_wave_approximate_entropy_median',\n",
       " 'pq_time_std',\n",
       " 'template_swt_d_3_low_power_ratio',\n",
       " 't_wave_sample_entropy_std',\n",
       " 't_wave_amp_std',\n",
       " 'rri_p3_pearson_coeff',\n",
       " 'rri_very_high_frequency_power',\n",
       " 'template_swt_a_1_med_power_ratio',\n",
       " 't_wave_fisher_info_std',\n",
       " 'qsi_pearson_coeff',\n",
       " 'rpeak_kurtosis',\n",
       " 'qs_time_std',\n",
       " 'swt_a_4_low_power_ratio',\n",
       " 'diff2_rri_min',\n",
       " 's_wave_amp_std',\n",
       " 'template_swt_d_4_low_power_ratio',\n",
       " 'p_wave_time_std',\n",
       " 'swt_d_1_higuchi_fractal',\n",
       " 'template_swt_d_1_low_power_ratio',\n",
       " 'p_wave_approximate_entropy_std',\n",
       " 'swt_d_4_higuchi_fractal',\n",
       " 'heart_rate_std',\n",
       " 'rri_p2_pearson_p_value',\n",
       " 'full_waveform_std',\n",
       " 'swt_a_1_high_power_ratio',\n",
       " 'rpeak_hurst_exponent',\n",
       " 'rpeak_median',\n",
       " 'q_wave_amp_std']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold f1 score is 0.7022919519907358\n"
     ]
    }
   ],
   "source": [
    "oof = list(map(int, oof))\n",
    "fold_f1_error = f1_score(train_labels, oof, average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fdf544cffd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.save_model(\"lightgbm_05141_temp315.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bst = lgb.Booster(model_file='lightgbm_05141_temp315.bin')  #lgb.bin  lightgbm_0327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"val_features315_II.csv\"):\n",
    "    pass\n",
    "else:\n",
    "    val_features315_pd = generate_features315(val_dataset_path,\"VAL001\")\n",
    "    for file_name in tqdm(val_files[1:]):\n",
    "        df_temp = generate_features315(val_dataset_path,file_name.strip('.mat'))\n",
    "        val_features315_pd = pd.concat([val_features315_pd,df_temp])\n",
    "    val_features315_pd.to_csv(\"val_features315_II.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dfeatures = val_features315_pd[feature_name].values\n",
    "kpred = bst.predict(dfeatures)\n",
    "\n",
    "pred = []\n",
    "for i in range(kpred.shape[0]):\n",
    "    pred.append( list(np.hstack(np.argwhere(kpred[i]>0.15))))\n",
    "    \n",
    "with open('answers.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['File_name', 'label1', 'label2',\n",
    "                    'label3', 'label4', 'label5', 'label6', 'label7', 'label8'])\n",
    "    count = 0\n",
    "    for file_name in val_files:\n",
    "        if file_name.endswith('.mat'):\n",
    "            \n",
    "            record_name = file_name.strip('.mat')\n",
    "            answer = []\n",
    "            answer.append(record_name)\n",
    "            \n",
    "            result = pred[count]\n",
    "            \n",
    "            answer.extend(result)\n",
    "            for i in range(8-len(result)):\n",
    "                answer.append('')\n",
    "                \n",
    "            #print(answer)\n",
    "            count += 1\n",
    "            writer.writerow(answer)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:09, 52.68it/s]\n"
     ]
    }
   ],
   "source": [
    "val_features39_pd = pd.DataFrame(columns=feature39_name,index=range(len(val_files)))\n",
    "for i,record in tqdm(enumerate(val_files)):\n",
    "    feat = []\n",
    "    ecg = sio.loadmat(val_dataset_path+record)\n",
    "    feat.extend(extract_basic_features(ecg[\"II\"][0],30000)[0])\n",
    "    val_features39_pd.loc[i] = feat\n",
    "    \n",
    "val_features39_pd.to_csv(\"val_features39.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>perdiogram_1</th>\n",
       "      <th>perdiogram_2</th>\n",
       "      <th>perdiogram_3</th>\n",
       "      <th>perdiogram_4</th>\n",
       "      <th>qrs_areas_mean</th>\n",
       "      <th>qrs_areas_max</th>\n",
       "      <th>qrs_areas2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>6.66667e-05</td>\n",
       "      <td>4.30897</td>\n",
       "      <td>24.2626</td>\n",
       "      <td>-9299.66</td>\n",
       "      <td>-8125.87</td>\n",
       "      <td>-11318.8</td>\n",
       "      <td>-14838.5</td>\n",
       "      <td>0.43602</td>\n",
       "      <td>0.722651</td>\n",
       "      <td>0.471016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00179353</td>\n",
       "      <td>0.00472905</td>\n",
       "      <td>0.0146254</td>\n",
       "      <td>9.49078</td>\n",
       "      <td>3.87286</td>\n",
       "      <td>1.62161</td>\n",
       "      <td>1.39666</td>\n",
       "      <td>4.8125</td>\n",
       "      <td>4.69613</td>\n",
       "      <td>0.00856784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.000133333</td>\n",
       "      <td>4.16013</td>\n",
       "      <td>20.413</td>\n",
       "      <td>-4555.15</td>\n",
       "      <td>-3908.04</td>\n",
       "      <td>-5267.6</td>\n",
       "      <td>-7132.83</td>\n",
       "      <td>0.625227</td>\n",
       "      <td>0.656808</td>\n",
       "      <td>0.709537</td>\n",
       "      <td>...</td>\n",
       "      <td>7.18617e-05</td>\n",
       "      <td>1.62732e-05</td>\n",
       "      <td>2.65265e-05</td>\n",
       "      <td>6.12745</td>\n",
       "      <td>0.327509</td>\n",
       "      <td>2.951</td>\n",
       "      <td>0</td>\n",
       "      <td>3.79465</td>\n",
       "      <td>3.57247</td>\n",
       "      <td>0.0198841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.88521</td>\n",
       "      <td>12.6546</td>\n",
       "      <td>-2614.96</td>\n",
       "      <td>-2569.6</td>\n",
       "      <td>-4061.58</td>\n",
       "      <td>-5287.63</td>\n",
       "      <td>0.186569</td>\n",
       "      <td>2.72928</td>\n",
       "      <td>0.177976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00938753</td>\n",
       "      <td>0.0221122</td>\n",
       "      <td>0.0698939</td>\n",
       "      <td>5.11229</td>\n",
       "      <td>2.99427</td>\n",
       "      <td>2.84158</td>\n",
       "      <td>1.25276</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.90689</td>\n",
       "      <td>0.0212713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.64245</td>\n",
       "      <td>16.1741</td>\n",
       "      <td>-3055.34</td>\n",
       "      <td>-2523.26</td>\n",
       "      <td>-3398.77</td>\n",
       "      <td>-4542.8</td>\n",
       "      <td>0.675001</td>\n",
       "      <td>0.706521</td>\n",
       "      <td>0.792839</td>\n",
       "      <td>...</td>\n",
       "      <td>8.2744e-05</td>\n",
       "      <td>3.00286e-05</td>\n",
       "      <td>8.33071e-05</td>\n",
       "      <td>4.62154</td>\n",
       "      <td>0.315956</td>\n",
       "      <td>2.74727</td>\n",
       "      <td>1.38629</td>\n",
       "      <td>3.54659</td>\n",
       "      <td>3.58496</td>\n",
       "      <td>0.00334011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.000133333</td>\n",
       "      <td>2.58085</td>\n",
       "      <td>10.8808</td>\n",
       "      <td>-4383.81</td>\n",
       "      <td>-4012.28</td>\n",
       "      <td>-5184.31</td>\n",
       "      <td>-7209.27</td>\n",
       "      <td>0.430938</td>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.571314</td>\n",
       "      <td>...</td>\n",
       "      <td>5.08705e-05</td>\n",
       "      <td>8.5478e-05</td>\n",
       "      <td>0.000133537</td>\n",
       "      <td>6.41416</td>\n",
       "      <td>0.702254</td>\n",
       "      <td>2.94444</td>\n",
       "      <td>2.19722</td>\n",
       "      <td>3.93214</td>\n",
       "      <td>3.9477</td>\n",
       "      <td>0.00822882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             var     skew kurtosis perdiogram_1 perdiogram_2 perdiogram_3  \\\n",
       "495  6.66667e-05  4.30897  24.2626     -9299.66     -8125.87     -11318.8   \n",
       "496  0.000133333  4.16013   20.413     -4555.15     -3908.04      -5267.6   \n",
       "497       0.0002  1.88521  12.6546     -2614.96      -2569.6     -4061.58   \n",
       "498       0.0002  3.64245  16.1741     -3055.34     -2523.26     -3398.77   \n",
       "499  0.000133333  2.58085  10.8808     -4383.81     -4012.28     -5184.31   \n",
       "\n",
       "    perdiogram_4 qrs_areas_mean qrs_areas_max qrs_areas2_mean  ...  \\\n",
       "495     -14838.5        0.43602      0.722651        0.471016  ...   \n",
       "496     -7132.83       0.625227      0.656808        0.709537  ...   \n",
       "497     -5287.63       0.186569       2.72928        0.177976  ...   \n",
       "498      -4542.8       0.675001      0.706521        0.792839  ...   \n",
       "499     -7209.27       0.430938      0.504038        0.571314  ...   \n",
       "\n",
       "          rr_var     rr_var_1     rr_var_2   log_rr log_rr_1_abs  \\\n",
       "495   0.00179353   0.00472905    0.0146254  9.49078      3.87286   \n",
       "496  7.18617e-05  1.62732e-05  2.65265e-05  6.12745     0.327509   \n",
       "497   0.00938753    0.0221122    0.0698939  5.11229      2.99427   \n",
       "498   8.2744e-05  3.00286e-05  8.33071e-05  4.62154     0.315956   \n",
       "499  5.08705e-05   8.5478e-05  0.000133537  6.41416     0.702254   \n",
       "\n",
       "    sample_entropy_1 sample_entropy_2 shannon_entropy_1 shannon_entropy_2  \\\n",
       "495          1.62161          1.39666            4.8125           4.69613   \n",
       "496            2.951                0           3.79465           3.57247   \n",
       "497          2.84158          1.25276              3.75           3.90689   \n",
       "498          2.74727          1.38629           3.54659           3.58496   \n",
       "499          2.94444          2.19722           3.93214            3.9477   \n",
       "\n",
       "    correlation  \n",
       "495  0.00856784  \n",
       "496   0.0198841  \n",
       "497   0.0212713  \n",
       "498  0.00334011  \n",
       "499  0.00822882  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features39_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfeatures = val_features39_pd[feature39_name].values\n",
    "kpred = bst.predict(dfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(kpred.shape[0]):\n",
    "    pred.append( list(np.hstack(np.argwhere(kpred[i]>0.15))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['File_name',\n",
       " 'label1',\n",
       " 'label2',\n",
       " 'label3',\n",
       " 'label4',\n",
       " 'label5',\n",
       " 'label6',\n",
       " 'label7',\n",
       " 'label8']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "random.randint(0,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('answers.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['File_name', 'label1', 'label2',\n",
    "                    'label3', 'label4', 'label5', 'label6', 'label7', 'label8'])\n",
    "    count = 0\n",
    "    for file_name in val_files:\n",
    "        if file_name.endswith('.mat'):\n",
    "            \n",
    "            record_name = file_name.strip('.mat')\n",
    "            answer = []\n",
    "            answer.append(record_name)\n",
    "            \n",
    "            result = pred[count]\n",
    "            \n",
    "            answer.extend(result)\n",
    "            for i in range(8-len(result)):\n",
    "                answer.append('')\n",
    "                \n",
    "            #print(answer)\n",
    "            count += 1\n",
    "            writer.writerow(answer)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ecg12_data=[]\n",
    "for k,v in ecg.items():\n",
    "    if k in [\"__header__\",\"__globals__\",\"__version__\"]:\n",
    "        continue\n",
    "    elif k in [\"sex\",\"age\"]:\n",
    "        continue\n",
    "    else:\n",
    "        ecg12_data.append(v[0])\n",
    "ecg = np.array(ecg12_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
