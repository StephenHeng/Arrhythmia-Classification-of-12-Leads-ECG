{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb.processing as wp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from utils import find_noise_features, extract_basic_features\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "path = \"F:\\\\ECG数据集\\\\www.physionet.org\\\\physiobank\\\\database\\\\afdb\\\\\"\n",
    "record_name = \"04048\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cinc_f1_score(ref, ans, verbose=True, details=False):\n",
    "    assert (ref.shape[0] == ans.shape[0])\n",
    "\n",
    "    AA = np.zeros((4, 4))\n",
    "\n",
    "    for n in range(ref.shape[0]):\n",
    "        rec = ref[n]\n",
    "\n",
    "        this_answer = ans[n]\n",
    "\n",
    "        if rec == 0:\n",
    "            if this_answer == 0:\n",
    "                AA[0, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[0, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[0, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[0, 3] += 1\n",
    "\n",
    "        elif rec == 1:\n",
    "            if this_answer == 0:\n",
    "                AA[1, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[1, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[1, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[1, 3] += 1\n",
    "\n",
    "        elif rec == 2:\n",
    "            if this_answer == 0:\n",
    "                AA[2, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[2, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[2, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[2, 3] += 1\n",
    "\n",
    "        elif rec == 3:\n",
    "            if this_answer == 0:\n",
    "                AA[3, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[3, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[3, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[3, 3] += 1\n",
    "\n",
    "    F1n = 2 * AA[0, 0] / (sum(AA[0, :]) + sum(AA[:, 0]))\n",
    "    F1a = 2 * AA[1, 1] / (sum(AA[1, :]) + sum(AA[:, 1]))\n",
    "    F1o = 2 * AA[2, 2] / (sum(AA[2, :]) + sum(AA[:, 2]))\n",
    "    F1p = 2 * AA[3, 3] / (sum(AA[3, :]) + sum(AA[:, 3]))\n",
    "    F1 = (F1n + F1a + F1o) / 3\n",
    "    if details:\n",
    "        print(AA)\n",
    "    if verbose:\n",
    "        print('F1 measure for Normal rhythm: ' '%1.4f' % F1n)\n",
    "        print('F1 measure for AF rhythm: ' '%1.4f' % F1a)\n",
    "        print('F1 measure for Other rhythm: ' '%1.4f' % F1o)\n",
    "        print('F1 measure for Noisy recordings: ' '%1.4f' % F1p)\n",
    "        print('Final F1 measure: ' '%1.4f' % F1)\n",
    "\n",
    "    return F1n,F1a,F1o,F1p,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature38_name = ['CV','rmssd','QRS_Width_std','MAD','AFEv','IrrEv','OriginCount','PACEv','R_amp_std','RR_mean',\n",
    "           'RR_min','HR_median','RR_max','CV_deltaRR','Pf_1','Pf_2','pf_RR_1','pf_RR_2','pf_RR_3','se', \n",
    "           'nn50', 'percentage_nn50', 'arrhyth_ind', 'res_kstest','COSEn', 'Radius','similar_ind_QRS','similar_ind_Ramp',\n",
    "           'r_high_similarbeats','stepping', 'E','MOBILITY','COMPLEXITY','R_amp_CV', 'QRS_width_mean','sk_RR','kurt_RR','RR_range']\n",
    "feature16_name=[]\n",
    "for i in [6,5,26,25,22,30,24,36,20,7,32,1,33,12,21,29]:\n",
    "    feature16_name.append(feature38_name[i-1])\n",
    "feature39_name = [\n",
    "    \"var\", \"skew\", \"kurtosis\", \"perdiogram_1\", \"perdiogram_2\", \"perdiogram_3\",\n",
    "    \"perdiogram_4\", \"qrs_areas_mean\", \"qrs_areas_max\", \"qrs_areas2_mean\",\n",
    "    \"qrs_areas2_max\", \"qrs_malin_mean\", \"qrs_malin_max\", \"qrs_malin2_mean\",\n",
    "    \"qrs_malin2_max\", \"n_plus_mean\", \"n_plus_max\", \"n_plus2_mean\",\n",
    "    \"n_plus2_max\", \"v40_mean\", \"v40_max\", \"v40_2_mean\", \"v40_2_max\",\n",
    "    \"freq_ratio_1\", \"freq_ratio_2\", \"freq_ratio_3\", \"freq_ratio_4\",\n",
    "    \"freq_ratio_5\", \"lorenz_plot\", \"rr_var\", \"rr_var_1\", \"rr_var_2\", \"log_rr\",\n",
    "    \"log_rr_1_abs\", \"sample_entropy_1\", \"sample_entropy_2\",\n",
    "    \"shannon_entropy_1\", \"shannon_entropy_2\", \"correlation\"\n",
    "]\n",
    "def generate_feature188():\n",
    "    a=\"Features_SD_1\"\n",
    "    feature_name = []\n",
    "    for i in range(1,69,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a=\"Features_RB_1\"\n",
    "    for i in range(1,16,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a=\"Features_ADC_1\"\n",
    "    for i in range(1,22,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a='Features_embcsoa_1'\n",
    "    for i in range(1,9,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a=\"Features_CP_1\"\n",
    "    for i in range(1,28,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a='features_temp_1'\n",
    "    for i in range(1,20,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a='features_temp_rs_1'\n",
    "    for i in range(1,31,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "    return feature_name\n",
    "feature188_name = generate_feature188()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"F:\\\\ECG\\\\ecg\\\\training2017\\\\\"\n",
    "f_list = os.listdir(path)\n",
    "file_list = []\n",
    "for i in f_list:\n",
    "    # os.path.splitext():分离文件名与扩展名\n",
    "    if os.path.splitext(i)[1] == '.mat':\n",
    "        file_list.append(i.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>perdiogram_1</th>\n",
       "      <th>perdiogram_2</th>\n",
       "      <th>perdiogram_3</th>\n",
       "      <th>perdiogram_4</th>\n",
       "      <th>qrs_areas_mean</th>\n",
       "      <th>qrs_areas_max</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.909595</td>\n",
       "      <td>11.207767</td>\n",
       "      <td>-5022.949108</td>\n",
       "      <td>-4897.418491</td>\n",
       "      <td>-6417.626901</td>\n",
       "      <td>-8600.342510</td>\n",
       "      <td>0.348011</td>\n",
       "      <td>0.602488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11.201408</td>\n",
       "      <td>0.781425</td>\n",
       "      <td>3.782768</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.504121</td>\n",
       "      <td>4.499598</td>\n",
       "      <td>0.006479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.935605</td>\n",
       "      <td>15.180122</td>\n",
       "      <td>-4976.180846</td>\n",
       "      <td>-4776.655937</td>\n",
       "      <td>-6577.618563</td>\n",
       "      <td>-8395.064863</td>\n",
       "      <td>0.295944</td>\n",
       "      <td>0.919263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>9.144809</td>\n",
       "      <td>2.459695</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>1.592631</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.694019</td>\n",
       "      <td>0.117561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-1.580090</td>\n",
       "      <td>4.994374</td>\n",
       "      <td>-10358.327470</td>\n",
       "      <td>-10455.589720</td>\n",
       "      <td>-14087.272830</td>\n",
       "      <td>-18263.731720</td>\n",
       "      <td>-0.091824</td>\n",
       "      <td>0.200487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>19.644293</td>\n",
       "      <td>2.044110</td>\n",
       "      <td>2.211211</td>\n",
       "      <td>1.800493</td>\n",
       "      <td>5.167088</td>\n",
       "      <td>5.119668</td>\n",
       "      <td>0.025986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>3.551206</td>\n",
       "      <td>14.768413</td>\n",
       "      <td>-4898.854941</td>\n",
       "      <td>-4707.588663</td>\n",
       "      <td>-6478.057380</td>\n",
       "      <td>-8517.461309</td>\n",
       "      <td>0.415471</td>\n",
       "      <td>0.506781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>9.152490</td>\n",
       "      <td>3.104567</td>\n",
       "      <td>2.984304</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.789015</td>\n",
       "      <td>0.038117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00005</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.303823</td>\n",
       "      <td>8.327276</td>\n",
       "      <td>-10835.293760</td>\n",
       "      <td>-10181.270340</td>\n",
       "      <td>-13613.273700</td>\n",
       "      <td>-17518.596880</td>\n",
       "      <td>0.119709</td>\n",
       "      <td>0.540239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>22.598280</td>\n",
       "      <td>10.004504</td>\n",
       "      <td>2.332943</td>\n",
       "      <td>1.735189</td>\n",
       "      <td>6.079932</td>\n",
       "      <td>6.396046</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       var      skew   kurtosis  perdiogram_1  perdiogram_2  \\\n",
       "0  A00001  0.000111  2.909595  11.207767  -5022.949108  -4897.418491   \n",
       "1  A00002  0.000111  2.935605  15.180122  -4976.180846  -4776.655937   \n",
       "2  A00003  0.000056 -1.580090   4.994374 -10358.327470 -10455.589720   \n",
       "3  A00004  0.000111  3.551206  14.768413  -4898.854941  -4707.588663   \n",
       "4  A00005  0.000056  2.303823   8.327276 -10835.293760 -10181.270340   \n",
       "\n",
       "   perdiogram_3  perdiogram_4  qrs_areas_mean  qrs_areas_max     ...       \\\n",
       "0  -6417.626901  -8600.342510        0.348011       0.602488     ...        \n",
       "1  -6577.618563  -8395.064863        0.295944       0.919263     ...        \n",
       "2 -14087.272830 -18263.731720       -0.091824       0.200487     ...        \n",
       "3  -6478.057380  -8517.461309        0.415471       0.506781     ...        \n",
       "4 -13613.273700 -17518.596880        0.119709       0.540239     ...        \n",
       "\n",
       "     rr_var  rr_var_1  rr_var_2     log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  0.000049  0.000022  0.000044  11.201408      0.781425          3.782768   \n",
       "1  0.001101  0.002392  0.008281   9.144809      2.459695          1.916463   \n",
       "2  0.000146  0.000197  0.000517  19.644293      2.044110          2.211211   \n",
       "3  0.001151  0.001939  0.005273   9.152490      3.104567          2.984304   \n",
       "4  0.001371  0.001967  0.004816  22.598280     10.004504          2.332943   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  \n",
       "0          2.772589           4.504121           4.499598     0.006479  \n",
       "1          1.592631           4.640224           4.694019     0.117561  \n",
       "2          1.800493           5.167088           5.119668     0.025986  \n",
       "3          2.890372           4.640224           4.789015     0.038117  \n",
       "4          1.735189           6.079932           6.396046     0.026922  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取39个特征数据\n",
    "if os.path.isfile(\"cinc_feat.csv\"):\n",
    "    features39_pd = pd.read_csv(\"cinc_feat.csv\")\n",
    "features39_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>Features_SD_10</th>\n",
       "      <th>...</th>\n",
       "      <th>features_temp_rs_22</th>\n",
       "      <th>features_temp_rs_23</th>\n",
       "      <th>features_temp_rs_24</th>\n",
       "      <th>features_temp_rs_25</th>\n",
       "      <th>features_temp_rs_26</th>\n",
       "      <th>features_temp_rs_27</th>\n",
       "      <th>features_temp_rs_28</th>\n",
       "      <th>features_temp_rs_29</th>\n",
       "      <th>features_temp_rs_30</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.298329</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  Features_SD_5  \\\n",
       "0          -11.0           11.0            0.0            0.0            0.0   \n",
       "1            9.0            7.0           16.0            0.0            0.0   \n",
       "2          -26.0           31.0            5.0            0.0            0.0   \n",
       "3           26.0            0.0           26.0            0.0            1.0   \n",
       "4           57.0           10.0           75.0            4.0            9.0   \n",
       "\n",
       "   Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  Features_SD_10  \\\n",
       "0            0.0       0.044264       0.031529       0.039185        0.013482   \n",
       "1            4.0       0.325171       0.296396       0.298329        0.171309   \n",
       "2            3.0       0.093895       0.088135       0.064279        0.056015   \n",
       "3            5.0       0.195561       0.251051       0.318723        0.107943   \n",
       "4           15.0       0.412665       0.503457       0.537868        0.263645   \n",
       "\n",
       "    ...    features_temp_rs_22  features_temp_rs_23  features_temp_rs_24  \\\n",
       "0   ...                    0.0                  0.0                  0.0   \n",
       "1   ...                    0.0                  0.0                  0.0   \n",
       "2   ...                    0.0                  0.0                  0.0   \n",
       "3   ...                    0.0                  0.0                  0.0   \n",
       "4   ...                    0.0                  0.0                  0.0   \n",
       "\n",
       "   features_temp_rs_25  features_temp_rs_26  features_temp_rs_27  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   features_temp_rs_28  features_temp_rs_29  features_temp_rs_30      id  \n",
       "0                  0.0                  0.0                  0.0  A00001  \n",
       "1                  0.0                  0.0                  0.0  A00002  \n",
       "2                  0.0                  0.0                  0.0  A00003  \n",
       "3                  0.0                  0.0                  0.0  A00004  \n",
       "4                  0.0                  0.0                  0.0  A00005  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取188个特征数据\n",
    "path = \"F:\\\\ECG\\\\ecg\\\\training2017\\\\\"\n",
    "if os.path.isfile(\"cinc_feat188.csv\"):\n",
    "    features188_pd = pd.read_csv(\"cinc_feat188.csv\")\n",
    "else:\n",
    "    data = np.loadtxt(path+\"TH902_features_188.txt\")\n",
    "    features188_pd = pd.DataFrame(data,columns=feature188_name,index=file_list)\n",
    "     \n",
    "    features188_pd['id']=file_list\n",
    "    col = feature188_name.copy()\n",
    "    col.insert(0,'id')\n",
    "    #features15_pd = features15_pd.reindex(columns=col)\n",
    "    features188_pd.to_csv(\"cinc_feat188.csv\",index=False)\n",
    "features188_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>QRS_Width_std</th>\n",
       "      <th>MAD</th>\n",
       "      <th>AFEv</th>\n",
       "      <th>IrrEv</th>\n",
       "      <th>OriginCount</th>\n",
       "      <th>PACEv</th>\n",
       "      <th>R_amp_std</th>\n",
       "      <th>RR_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>stepping</th>\n",
       "      <th>E</th>\n",
       "      <th>MOBILITY</th>\n",
       "      <th>COMPLEXITY</th>\n",
       "      <th>R_amp_CV</th>\n",
       "      <th>QRS_width_mean</th>\n",
       "      <th>sk_RR</th>\n",
       "      <th>kurt_RR</th>\n",
       "      <th>RR_range</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.11</td>\n",
       "      <td>A00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.89</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.13</td>\n",
       "      <td>A00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.28</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>11.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>A00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.62</td>\n",
       "      <td>A00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>58.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>28.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>A00005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CV  rmssd  QRS_Width_std   MAD  AFEv  IrrEv  OriginCount  PACEv  \\\n",
       "0  0.04  0.00            0.00  0.03  -6.0    0.0          6.0    0.0   \n",
       "1  0.04  0.00            0.00  0.03  -6.0    0.0          6.0    0.0   \n",
       "2  0.10  0.01            0.01  0.04 -14.0    8.0         22.0    0.0   \n",
       "3  0.19  0.06            0.00  0.15  26.0   26.0          0.0    0.0   \n",
       "4  0.41  0.07            0.01  0.18  58.0   76.0          8.0    5.0   \n",
       "\n",
       "   R_amp_std  RR_mean   ...    stepping      E  MOBILITY  COMPLEXITY  \\\n",
       "0       0.09     0.76   ...        0.04  11.90      0.16        9.03   \n",
       "1       0.07     1.03   ...        0.04  -0.95      0.24        5.89   \n",
       "2       0.12     0.74   ...        0.11  21.17      0.20        8.28   \n",
       "3       0.11     0.95   ...        0.32   0.12      0.30        5.23   \n",
       "4       0.16     0.54   ...        0.53  28.54      0.48        3.29   \n",
       "\n",
       "   R_amp_CV  QRS_width_mean  sk_RR  kurt_RR  RR_range      id  \n",
       "0      0.11            0.07   0.12     1.80      0.11  A00001  \n",
       "1      0.10            0.07  -0.41     2.62      0.13  A00002  \n",
       "2     -0.26            0.07   0.18    11.10      0.61  A00003  \n",
       "3      0.09            0.07   0.48     2.05      0.62  A00004  \n",
       "4      0.17            0.06   1.18     3.02      0.78  A00005  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./wclfeature/\"\n",
    "features38_pd = pd.read_csv(path+\"cinc_feat.csv\",header=None)\n",
    "features38_pd.drop([0,39],axis=1,inplace=True)\n",
    "features38_pd.columns = feature38_name\n",
    "features38_pd['id']=file_list\n",
    "features38_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>Features_SD_10</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11.201408</td>\n",
       "      <td>0.781425</td>\n",
       "      <td>3.782768</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.504121</td>\n",
       "      <td>4.499598</td>\n",
       "      <td>0.006479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.298329</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>9.144809</td>\n",
       "      <td>2.459695</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>1.592631</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.694019</td>\n",
       "      <td>0.117561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>19.644293</td>\n",
       "      <td>2.044110</td>\n",
       "      <td>2.211211</td>\n",
       "      <td>1.800493</td>\n",
       "      <td>5.167088</td>\n",
       "      <td>5.119668</td>\n",
       "      <td>0.025986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>9.152490</td>\n",
       "      <td>3.104567</td>\n",
       "      <td>2.984304</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.789015</td>\n",
       "      <td>0.038117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>22.598280</td>\n",
       "      <td>10.004504</td>\n",
       "      <td>2.332943</td>\n",
       "      <td>1.735189</td>\n",
       "      <td>6.079932</td>\n",
       "      <td>6.396046</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  Features_SD_5  \\\n",
       "0          -11.0           11.0            0.0            0.0            0.0   \n",
       "1            9.0            7.0           16.0            0.0            0.0   \n",
       "2          -26.0           31.0            5.0            0.0            0.0   \n",
       "3           26.0            0.0           26.0            0.0            1.0   \n",
       "4           57.0           10.0           75.0            4.0            9.0   \n",
       "\n",
       "   Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  Features_SD_10  \\\n",
       "0            0.0       0.044264       0.031529       0.039185        0.013482   \n",
       "1            4.0       0.325171       0.296396       0.298329        0.171309   \n",
       "2            3.0       0.093895       0.088135       0.064279        0.056015   \n",
       "3            5.0       0.195561       0.251051       0.318723        0.107943   \n",
       "4           15.0       0.412665       0.503457       0.537868        0.263645   \n",
       "\n",
       "      ...         rr_var  rr_var_1  rr_var_2     log_rr  log_rr_1_abs  \\\n",
       "0     ...       0.000049  0.000022  0.000044  11.201408      0.781425   \n",
       "1     ...       0.001101  0.002392  0.008281   9.144809      2.459695   \n",
       "2     ...       0.000146  0.000197  0.000517  19.644293      2.044110   \n",
       "3     ...       0.001151  0.001939  0.005273   9.152490      3.104567   \n",
       "4     ...       0.001371  0.001967  0.004816  22.598280     10.004504   \n",
       "\n",
       "   sample_entropy_1  sample_entropy_2  shannon_entropy_1  shannon_entropy_2  \\\n",
       "0          3.782768          2.772589           4.504121           4.499598   \n",
       "1          1.916463          1.592631           4.640224           4.694019   \n",
       "2          2.211211          1.800493           5.167088           5.119668   \n",
       "3          2.984304          2.890372           4.640224           4.789015   \n",
       "4          2.332943          1.735189           6.079932           6.396046   \n",
       "\n",
       "   correlation  \n",
       "0     0.006479  \n",
       "1     0.117561  \n",
       "2     0.025986  \n",
       "3     0.038117  \n",
       "4     0.026922  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#组合全部特征\n",
    "train_data = pd.merge(features188_pd,features38_pd,on='id')\n",
    "train_data = pd.merge(train_data,features39_pd,on='id')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00005</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID label\n",
       "0  A00001     N\n",
       "1  A00002     N\n",
       "2  A00003     N\n",
       "3  A00004     A\n",
       "4  A00005     A"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取标签\n",
    "path = \"F:\\\\ECG\\\\ecg\\\\training2017\\\\\"\n",
    "target = pd.read_csv(os.path.join(path,\"REFERENCE-v3.csv\"),header=None,index_col=False)\n",
    "target.columns=[\"ID\",\"label\"]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>Features_SD_10</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11.201408</td>\n",
       "      <td>0.781425</td>\n",
       "      <td>3.782768</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.504121</td>\n",
       "      <td>4.499598</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.298329</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>9.144809</td>\n",
       "      <td>2.459695</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>1.592631</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.694019</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>19.644293</td>\n",
       "      <td>2.044110</td>\n",
       "      <td>2.211211</td>\n",
       "      <td>1.800493</td>\n",
       "      <td>5.167088</td>\n",
       "      <td>5.119668</td>\n",
       "      <td>0.025986</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>9.152490</td>\n",
       "      <td>3.104567</td>\n",
       "      <td>2.984304</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.789015</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>22.598280</td>\n",
       "      <td>10.004504</td>\n",
       "      <td>2.332943</td>\n",
       "      <td>1.735189</td>\n",
       "      <td>6.079932</td>\n",
       "      <td>6.396046</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  Features_SD_5  \\\n",
       "0          -11.0           11.0            0.0            0.0            0.0   \n",
       "1            9.0            7.0           16.0            0.0            0.0   \n",
       "2          -26.0           31.0            5.0            0.0            0.0   \n",
       "3           26.0            0.0           26.0            0.0            1.0   \n",
       "4           57.0           10.0           75.0            4.0            9.0   \n",
       "\n",
       "   Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  Features_SD_10  \\\n",
       "0            0.0       0.044264       0.031529       0.039185        0.013482   \n",
       "1            4.0       0.325171       0.296396       0.298329        0.171309   \n",
       "2            3.0       0.093895       0.088135       0.064279        0.056015   \n",
       "3            5.0       0.195561       0.251051       0.318723        0.107943   \n",
       "4           15.0       0.412665       0.503457       0.537868        0.263645   \n",
       "\n",
       "   ...    rr_var_1  rr_var_2     log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  ...    0.000022  0.000044  11.201408      0.781425          3.782768   \n",
       "1  ...    0.002392  0.008281   9.144809      2.459695          1.916463   \n",
       "2  ...    0.000197  0.000517  19.644293      2.044110          2.211211   \n",
       "3  ...    0.001939  0.005273   9.152490      3.104567          2.984304   \n",
       "4  ...    0.001967  0.004816  22.598280     10.004504          2.332943   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  label  \n",
       "0          2.772589           4.504121           4.499598     0.006479      N  \n",
       "1          1.592631           4.640224           4.694019     0.117561      N  \n",
       "2          1.800493           5.167088           5.119668     0.025986      N  \n",
       "3          2.890372           4.640224           4.789015     0.038117      A  \n",
       "4          1.735189           6.079932           6.396046     0.026922      A  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"] = np.array(target[\"label\"])#target[\"label\"]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fe451cdf98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFXCAYAAAC/aQfJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4g7AADGEHcAAIwh7gAAGPO/pnyuEOJI8n8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(train_data[train_data['E'].notnull()].reset_index()[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-11.00000000</td>\n",
       "      <td>11.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.04426400</td>\n",
       "      <td>0.03152900</td>\n",
       "      <td>0.03918500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00002230</td>\n",
       "      <td>0.00004430</td>\n",
       "      <td>11.20140801</td>\n",
       "      <td>0.78142460</td>\n",
       "      <td>3.78276817</td>\n",
       "      <td>2.77258872</td>\n",
       "      <td>4.50412060</td>\n",
       "      <td>4.49959762</td>\n",
       "      <td>0.00647882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.00000000</td>\n",
       "      <td>7.00000000</td>\n",
       "      <td>16.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>4.00000000</td>\n",
       "      <td>0.32517100</td>\n",
       "      <td>0.29639600</td>\n",
       "      <td>0.29832900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00239223</td>\n",
       "      <td>0.00828122</td>\n",
       "      <td>9.14480873</td>\n",
       "      <td>2.45969485</td>\n",
       "      <td>1.91646295</td>\n",
       "      <td>1.59263079</td>\n",
       "      <td>4.64022393</td>\n",
       "      <td>4.69401936</td>\n",
       "      <td>0.11756109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-26.00000000</td>\n",
       "      <td>31.00000000</td>\n",
       "      <td>5.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>3.00000000</td>\n",
       "      <td>0.09389500</td>\n",
       "      <td>0.08813500</td>\n",
       "      <td>0.06427900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00019736</td>\n",
       "      <td>0.00051699</td>\n",
       "      <td>19.64429350</td>\n",
       "      <td>2.04411026</td>\n",
       "      <td>2.21121082</td>\n",
       "      <td>1.80049315</td>\n",
       "      <td>5.16708805</td>\n",
       "      <td>5.11966798</td>\n",
       "      <td>0.02598626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>26.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>5.00000000</td>\n",
       "      <td>0.19556100</td>\n",
       "      <td>0.25105100</td>\n",
       "      <td>0.31872300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00193868</td>\n",
       "      <td>0.00527312</td>\n",
       "      <td>9.15248984</td>\n",
       "      <td>3.10456705</td>\n",
       "      <td>2.98430358</td>\n",
       "      <td>2.89037176</td>\n",
       "      <td>4.64022393</td>\n",
       "      <td>4.78901548</td>\n",
       "      <td>0.03811713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57.00000000</td>\n",
       "      <td>10.00000000</td>\n",
       "      <td>75.00000000</td>\n",
       "      <td>4.00000000</td>\n",
       "      <td>9.00000000</td>\n",
       "      <td>15.00000000</td>\n",
       "      <td>0.41266500</td>\n",
       "      <td>0.50345700</td>\n",
       "      <td>0.53786800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00196747</td>\n",
       "      <td>0.00481638</td>\n",
       "      <td>22.59828023</td>\n",
       "      <td>10.00450437</td>\n",
       "      <td>2.33294272</td>\n",
       "      <td>1.73518912</td>\n",
       "      <td>6.07993157</td>\n",
       "      <td>6.39604595</td>\n",
       "      <td>0.02692229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  \\\n",
       "0      0   -11.00000000    11.00000000     0.00000000     0.00000000   \n",
       "1      1     9.00000000     7.00000000    16.00000000     0.00000000   \n",
       "2      2   -26.00000000    31.00000000     5.00000000     0.00000000   \n",
       "3      3    26.00000000     0.00000000    26.00000000     0.00000000   \n",
       "4      4    57.00000000    10.00000000    75.00000000     4.00000000   \n",
       "\n",
       "   Features_SD_5  Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  \\\n",
       "0     0.00000000     0.00000000     0.04426400     0.03152900     0.03918500   \n",
       "1     0.00000000     4.00000000     0.32517100     0.29639600     0.29832900   \n",
       "2     0.00000000     3.00000000     0.09389500     0.08813500     0.06427900   \n",
       "3     1.00000000     5.00000000     0.19556100     0.25105100     0.31872300   \n",
       "4     9.00000000    15.00000000     0.41266500     0.50345700     0.53786800   \n",
       "\n",
       "   ...     rr_var_1   rr_var_2      log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  ...   0.00002230 0.00004430 11.20140801    0.78142460        3.78276817   \n",
       "1  ...   0.00239223 0.00828122  9.14480873    2.45969485        1.91646295   \n",
       "2  ...   0.00019736 0.00051699 19.64429350    2.04411026        2.21121082   \n",
       "3  ...   0.00193868 0.00527312  9.15248984    3.10456705        2.98430358   \n",
       "4  ...   0.00196747 0.00481638 22.59828023   10.00450437        2.33294272   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  label  \n",
       "0        2.77258872         4.50412060         4.49959762   0.00647882      0  \n",
       "1        1.59263079         4.64022393         4.69401936   0.11756109      0  \n",
       "2        1.80049315         5.16708805         5.11966798   0.02598626      0  \n",
       "3        2.89037176         4.64022393         4.78901548   0.03811713      1  \n",
       "4        1.73518912         6.07993157         6.39604595   0.02692229      1  \n",
       "\n",
       "[5 rows x 268 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_data[train_data['E'].notnull()].reset_index()\n",
    "\n",
    "train_labels = train_df['label']\n",
    "map_dict = {\"N\":0,\"A\":1,\"O\":0,\"~\":0}\n",
    "train_labels = train_labels.map(map_dict)\n",
    "train_df[\"label\"] = train_labels.values#target[\"label\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7770\n",
       "1     758\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name = ['sk_RR',\n",
    " 'Features_SD_55',\n",
    " 'features_temp_11',\n",
    " 'pf_RR_1',\n",
    " 'Features_SD_22',\n",
    " 'Features_SD_48',\n",
    " 'Features_embcsoa_8',\n",
    " 'qrs_malin2_max',\n",
    " 'Features_ADC_9',\n",
    " 'Features_SD_16',\n",
    " 'sample_entropy_2',\n",
    " 'n_plus_mean',\n",
    " 'RR_min',\n",
    " 'Features_SD_47',\n",
    " 'Features_SD_13',\n",
    " 'CV_deltaRR',\n",
    " 'Features_CP_15',\n",
    " 'sample_entropy_1',\n",
    " 'features_temp_2',\n",
    " 'AFEv',\n",
    " 'se',\n",
    " 'r_high_similarbeats',\n",
    " 'qrs_malin_max',\n",
    " 'v40_mean',\n",
    " 'Features_SD_64',\n",
    " 'Features_CP_18',\n",
    " 'rr_var_2',\n",
    " 'Features_ADC_6',\n",
    " 'features_temp_rs_13',\n",
    " 'qrs_malin_mean',\n",
    " 'features_temp_rs_15',\n",
    " 'Features_RB_6',\n",
    " 'lorenz_plot',\n",
    " 'qrs_malin2_mean',\n",
    " 'Features_SD_57',\n",
    " 'Features_SD_14',\n",
    " 'Features_CP_17',\n",
    " 'Features_RB_4',\n",
    " 'features_temp_rs_7',\n",
    " 'Features_SD_52',\n",
    " 'Features_CP_12',\n",
    " 'Features_SD_33',\n",
    " 'Features_ADC_2',\n",
    " 'Features_SD_44',\n",
    " 'features_temp_rs_2',\n",
    " 'Features_SD_1',\n",
    " 'Features_SD_58',\n",
    " 'features_temp_rs_8',\n",
    " 'features_temp_rs_17',\n",
    " 'Features_SD_41',\n",
    " 'Features_CP_4',\n",
    " 'R_amp_CV',\n",
    " 'Features_RB_11',\n",
    " 'Features_SD_37',\n",
    " 'Radius',\n",
    " 'Features_SD_46',\n",
    " 'Features_ADC_13',\n",
    " 'Features_CP_8',\n",
    " 'Features_CP_22',\n",
    " 'Features_SD_60',\n",
    " 'IrrEv',\n",
    " 'features_temp_12',\n",
    " 'Features_RB_10',\n",
    " 'kurt_RR',\n",
    " 'Features_SD_28',\n",
    " 'Features_SD_59',\n",
    " 'Features_CP_7',\n",
    " 'perdiogram_1',\n",
    " 'features_temp_rs_16',\n",
    " 'Features_SD_35',\n",
    " 'Features_SD_51',\n",
    " 'v40_2_mean',\n",
    " 'Features_CP_26',\n",
    " 'Features_ADC_10',\n",
    " 'Features_RB_13',\n",
    " 'Features_SD_45',\n",
    " 'Features_CP_25',\n",
    " 'COSEn',\n",
    " 'Features_SD_43',\n",
    " 'Features_RB_9',\n",
    " 'Features_SD_42',\n",
    " 'Features_SD_38',\n",
    " 'Features_RB_8',\n",
    " 'Features_ADC_3',\n",
    " 'n_plus2_mean',\n",
    " 'features_temp_rs_1',\n",
    " 'Features_SD_39',\n",
    " 'Features_RB_14',\n",
    " 'Features_CP_14',\n",
    " 'Features_CP_19',\n",
    " 'Features_CP_16',\n",
    " 'Features_SD_36',\n",
    " 'Features_RB_12',\n",
    " 'RR_max',\n",
    " 'Features_SD_56',\n",
    " 'Features_CP_20',\n",
    " 'Features_SD_62',\n",
    " 'features_temp_3',\n",
    " 'features_temp_rs_10',\n",
    " 'HR_median'][:20]\n",
    "\n",
    "len(feature_name)#43：0.8132 0.8232    48：0.8143 -0.8260  51 0.8088-0.8233\n",
    "#feature_name = feature39_name+feature38_name+feature188_name[:175]\n",
    "#feature_name = feature16_name\n",
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#二分类前100特征排名\n",
    "feature_name =['AFEv',\n",
    " 'sk_RR',\n",
    " 'Features_SD_16',\n",
    " 'Features_ADC_9',\n",
    " 'features_temp_2',\n",
    " 'IrrEv',\n",
    " 'Radius',\n",
    " 'Features_SD_44',\n",
    " 'Features_ADC_3',\n",
    " 'Features_ADC_6',\n",
    " 'Features_ADC_2',\n",
    " 'Features_SD_48',\n",
    " 'Features_ADC_11',\n",
    " 'Features_SD_1',\n",
    " 'sample_entropy_1',\n",
    " 'Features_CP_8',\n",
    " 'n_plus_mean',\n",
    " 'CV_deltaRR',\n",
    " 'Features_ADC_7',\n",
    " 'qrs_malin2_mean',\n",
    " 'Features_CP_18',\n",
    " 'Features_CP_20',\n",
    " 'v40_2_mean',\n",
    " 'Features_CP_19',\n",
    " 'Features_SD_46',\n",
    " 'Features_ADC_13',\n",
    " 'Features_SD_60',\n",
    " 'Features_RB_13',\n",
    " 'R_amp_std',\n",
    " 'features_temp_11',\n",
    " 'Features_SD_43',\n",
    " 'sample_entropy_2',\n",
    " 'RR_min',\n",
    " 'COSEn',\n",
    " 'features_temp_3',\n",
    " 'Features_CP_22',\n",
    " 'se',\n",
    " 'Features_SD_51',\n",
    " 'Features_SD_55',\n",
    " 'Features_CP_16',\n",
    " 'Features_SD_56',\n",
    " 'Features_SD_52',\n",
    " 'Features_SD_45',\n",
    " 'features_temp_rs_1',\n",
    " 'percentage_nn50',\n",
    " 'HR_median',\n",
    " 'shannon_entropy_1',\n",
    " 'qrs_areas_mean',\n",
    " 'pf_RR_1',\n",
    " 'Features_RB_14',\n",
    " 'Features_SD_3',\n",
    " 'n_plus2_mean',\n",
    " 'correlation',\n",
    " 'Features_SD_6',\n",
    " 'perdiogram_4',\n",
    " 'RR_max',\n",
    " 'Features_CP_12',\n",
    " 'Features_RB_11',\n",
    " 'Features_SD_62',\n",
    " 'Features_RB_9',\n",
    " 'lorenz_plot',\n",
    " 'Features_SD_47',\n",
    " 'features_temp_rs_7',\n",
    " 'Features_CP_25',\n",
    " 'Features_SD_61',\n",
    " 'CV',\n",
    " 'features_temp_1',\n",
    " 'Features_ADC_21',\n",
    " 'features_temp_12',\n",
    " 'Features_CP_17',\n",
    " 'features_temp_rs_2',\n",
    " 'Features_RB_12',\n",
    " 'Features_SD_53',\n",
    " 'qrs_malin2_max',\n",
    " 'Features_CP_1',\n",
    " 'stepping',\n",
    " 'Features_SD_17',\n",
    " 'kurt_RR',\n",
    " 'qrs_areas2_max',\n",
    " 'Features_CP_4',\n",
    " 'Features_SD_64',\n",
    " 'Features_SD_31',\n",
    " 'features_temp_rs_16',\n",
    " 'Features_ADC_10',\n",
    " 'skew',\n",
    " 'features_temp_rs_12',\n",
    " 'Features_SD_30',\n",
    " 'log_rr',\n",
    " 'Features_SD_9',\n",
    " 'Features_CP_15',\n",
    " 'Features_embcsoa_8',\n",
    " 'Features_CP_7',\n",
    " 'Features_CP_9',\n",
    " 'Features_ADC_4',\n",
    " 'r_high_similarbeats',\n",
    " 'Features_SD_22',\n",
    " 'v40_mean',\n",
    " 'log_rr_1_abs',\n",
    " 'Features_SD_35',\n",
    " 'Features_CP_27'][:35]\n",
    "\n",
    "len(feature_name)#43：0.8132 0.8232    48：0.8143 -0.8260  51 0.8088-0.8233\n",
    "#feature_name = feature39_name+feature38_name+feature188_name[:175]\n",
    "#feature_name = feature16_name\n",
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_name = list(set(feature_name + feature16_name))\n",
    "#feature_name = feature16_name\n",
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "#4分类参数\n",
    "''' \n",
    "lgb_params2={\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':819,\n",
    " 'max_depth':8,\n",
    " 'num_leaves':115,\n",
    " 'min_child_weight':0,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'min_child_samples':21,\n",
    " 'objective':'binary',\n",
    " 'reg_alpha':0.15,\n",
    " 'reg_lambda' : 0.01,\n",
    " 'num_class': 1,\n",
    " 'n_jobs':4,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}\n",
    "'''\n",
    "'''\n",
    "#2分类参数\n",
    "lgb_params2={\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':68,\n",
    " 'max_depth':7,\n",
    " 'num_leaves':50,\n",
    " 'min_child_weight':0.0005,\n",
    " 'subsample':0.9,\n",
    " 'colsample_bytree':0.9,\n",
    " 'min_child_samples':19,\n",
    " 'objective':'binary',\n",
    " 'reg_alpha':0.5,\n",
    " 'reg_lambda' : 0.03,\n",
    " 'num_class': 1,\n",
    " 'n_jobs':4,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}\n",
    "\n",
    "''' \n",
    "lgb_params2={\n",
    "'boosting_type': 'gbdt',\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':661,\n",
    " 'max_depth':57,\n",
    " 'num_leaves':31,\n",
    " 'min_child_weight':1,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'min_child_samples':20,\n",
    " 'objective':'binary',\n",
    " 'reg_alpha':0.0,\n",
    " 'reg_lambda' : 0.0,\n",
    " 'num_class': 1,\n",
    " 'n_jobs':4,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8528, 35)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[feature_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFEv</th>\n",
       "      <th>sk_RR</th>\n",
       "      <th>Features_SD_16</th>\n",
       "      <th>Features_ADC_9</th>\n",
       "      <th>features_temp_2</th>\n",
       "      <th>IrrEv</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Features_SD_44</th>\n",
       "      <th>Features_ADC_3</th>\n",
       "      <th>Features_ADC_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Features_ADC_13</th>\n",
       "      <th>Features_SD_60</th>\n",
       "      <th>Features_RB_13</th>\n",
       "      <th>R_amp_std</th>\n",
       "      <th>features_temp_11</th>\n",
       "      <th>Features_SD_43</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>RR_min</th>\n",
       "      <th>COSEn</th>\n",
       "      <th>features_temp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-10.28517824</td>\n",
       "      <td>-0.07349672</td>\n",
       "      <td>-0.23100243</td>\n",
       "      <td>48.20966229</td>\n",
       "      <td>3.02754163</td>\n",
       "      <td>5.65114916</td>\n",
       "      <td>0.07543856</td>\n",
       "      <td>0.79373406</td>\n",
       "      <td>0.78735572</td>\n",
       "      <td>25.65668077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99790527</td>\n",
       "      <td>105.31045583</td>\n",
       "      <td>0.01536705</td>\n",
       "      <td>0.12275446</td>\n",
       "      <td>0.81335131</td>\n",
       "      <td>0.31750798</td>\n",
       "      <td>1.66509864</td>\n",
       "      <td>0.69828330</td>\n",
       "      <td>-2.72186914</td>\n",
       "      <td>15.73579350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.86614086</td>\n",
       "      <td>1.17191924</td>\n",
       "      <td>1.77479181</td>\n",
       "      <td>277.29111509</td>\n",
       "      <td>12.81983459</td>\n",
       "      <td>10.96315764</td>\n",
       "      <td>0.15229096</td>\n",
       "      <td>0.20426497</td>\n",
       "      <td>0.20992105</td>\n",
       "      <td>18.65590535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15405400</td>\n",
       "      <td>15.70420119</td>\n",
       "      <td>0.12423597</td>\n",
       "      <td>0.09784041</td>\n",
       "      <td>0.50542953</td>\n",
       "      <td>0.24366958</td>\n",
       "      <td>0.94230839</td>\n",
       "      <td>0.22092895</td>\n",
       "      <td>2.02116118</td>\n",
       "      <td>35.20638570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-148.00000000</td>\n",
       "      <td>-8.76000000</td>\n",
       "      <td>-7.76915100</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-0.74046600</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-2.02800000</td>\n",
       "      <td>-0.74460800</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-10.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-23.00000000</td>\n",
       "      <td>-0.49000000</td>\n",
       "      <td>-0.93508450</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.72600000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.71794900</td>\n",
       "      <td>0.70833300</td>\n",
       "      <td>13.19705225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97752800</td>\n",
       "      <td>96.64641725</td>\n",
       "      <td>-0.05184300</td>\n",
       "      <td>0.07000000</td>\n",
       "      <td>0.46475000</td>\n",
       "      <td>0.15187075</td>\n",
       "      <td>1.00318793</td>\n",
       "      <td>0.56000000</td>\n",
       "      <td>-3.04000000</td>\n",
       "      <td>0.58375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-0.09247050</td>\n",
       "      <td>3.00000000</td>\n",
       "      <td>1.36500000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.03000000</td>\n",
       "      <td>0.86486500</td>\n",
       "      <td>0.86111100</td>\n",
       "      <td>21.97807100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>102.37347250</td>\n",
       "      <td>0.03097650</td>\n",
       "      <td>0.10000000</td>\n",
       "      <td>0.78700000</td>\n",
       "      <td>0.26542150</td>\n",
       "      <td>1.73460105</td>\n",
       "      <td>0.72000000</td>\n",
       "      <td>-2.44000000</td>\n",
       "      <td>1.12800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.43000000</td>\n",
       "      <td>0.54354900</td>\n",
       "      <td>12.00000000</td>\n",
       "      <td>1.89700000</td>\n",
       "      <td>6.00000000</td>\n",
       "      <td>0.05000000</td>\n",
       "      <td>0.94285700</td>\n",
       "      <td>0.94117600</td>\n",
       "      <td>32.63371575</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02041750</td>\n",
       "      <td>110.24451775</td>\n",
       "      <td>0.09505650</td>\n",
       "      <td>0.15000000</td>\n",
       "      <td>1.15000000</td>\n",
       "      <td>0.41825350</td>\n",
       "      <td>2.35137526</td>\n",
       "      <td>0.84000000</td>\n",
       "      <td>-1.79000000</td>\n",
       "      <td>1.87200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.00000000</td>\n",
       "      <td>8.55000000</td>\n",
       "      <td>12.21772200</td>\n",
       "      <td>17137.00000000</td>\n",
       "      <td>100.00000000</td>\n",
       "      <td>108.00000000</td>\n",
       "      <td>1.76000000</td>\n",
       "      <td>0.99159700</td>\n",
       "      <td>0.99152500</td>\n",
       "      <td>169.70562700</td>\n",
       "      <td>...</td>\n",
       "      <td>5.56521700</td>\n",
       "      <td>303.88370400</td>\n",
       "      <td>0.75169400</td>\n",
       "      <td>1.56000000</td>\n",
       "      <td>3.51300000</td>\n",
       "      <td>2.66190300</td>\n",
       "      <td>4.61512052</td>\n",
       "      <td>1.77000000</td>\n",
       "      <td>1.16000000</td>\n",
       "      <td>100.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AFEv         sk_RR  Features_SD_16  Features_ADC_9  \\\n",
       "count 8528.00000000 8528.00000000   8528.00000000   8528.00000000   \n",
       "mean   -10.28517824   -0.07349672     -0.23100243     48.20966229   \n",
       "std     21.86614086    1.17191924      1.77479181    277.29111509   \n",
       "min   -148.00000000   -8.76000000     -7.76915100      0.00000000   \n",
       "25%    -23.00000000   -0.49000000     -0.93508450      1.00000000   \n",
       "50%     -9.00000000    0.00000000     -0.09247050      3.00000000   \n",
       "75%      0.00000000    0.43000000      0.54354900     12.00000000   \n",
       "max    104.00000000    8.55000000     12.21772200  17137.00000000   \n",
       "\n",
       "       features_temp_2         IrrEv        Radius  Features_SD_44  \\\n",
       "count    8528.00000000 8528.00000000 8528.00000000   8528.00000000   \n",
       "mean        3.02754163    5.65114916    0.07543856      0.79373406   \n",
       "std        12.81983459   10.96315764    0.15229096      0.20426497   \n",
       "min         0.00000000    0.00000000    0.00000000      0.00000000   \n",
       "25%         0.72600000    0.00000000    0.01000000      0.71794900   \n",
       "50%         1.36500000    1.00000000    0.03000000      0.86486500   \n",
       "75%         1.89700000    6.00000000    0.05000000      0.94285700   \n",
       "max       100.00000000  108.00000000    1.76000000      0.99159700   \n",
       "\n",
       "       Features_ADC_3  Features_ADC_6       ...         Features_ADC_13  \\\n",
       "count   8528.00000000   8528.00000000       ...           8528.00000000   \n",
       "mean       0.78735572     25.65668077       ...              0.99790527   \n",
       "std        0.20992105     18.65590535       ...              0.15405400   \n",
       "min        0.00000000      0.00000000       ...              0.00000000   \n",
       "25%        0.70833300     13.19705225       ...              0.97752800   \n",
       "50%        0.86111100     21.97807100       ...              1.00000000   \n",
       "75%        0.94117600     32.63371575       ...              1.02041750   \n",
       "max        0.99152500    169.70562700       ...              5.56521700   \n",
       "\n",
       "       Features_SD_60  Features_RB_13     R_amp_std  features_temp_11  \\\n",
       "count   8528.00000000   8528.00000000 8528.00000000     8528.00000000   \n",
       "mean     105.31045583      0.01536705    0.12275446        0.81335131   \n",
       "std       15.70420119      0.12423597    0.09784041        0.50542953   \n",
       "min        0.00000000     -0.74046600    0.00000000       -2.02800000   \n",
       "25%       96.64641725     -0.05184300    0.07000000        0.46475000   \n",
       "50%      102.37347250      0.03097650    0.10000000        0.78700000   \n",
       "75%      110.24451775      0.09505650    0.15000000        1.15000000   \n",
       "max      303.88370400      0.75169400    1.56000000        3.51300000   \n",
       "\n",
       "       Features_SD_43  sample_entropy_2        RR_min         COSEn  \\\n",
       "count   8528.00000000     8528.00000000 8528.00000000 8528.00000000   \n",
       "mean       0.31750798        1.66509864    0.69828330   -2.72186914   \n",
       "std        0.24366958        0.94230839    0.22092895    2.02116118   \n",
       "min       -0.74460800        0.00000000    0.00000000  -10.00000000   \n",
       "25%        0.15187075        1.00318793    0.56000000   -3.04000000   \n",
       "50%        0.26542150        1.73460105    0.72000000   -2.44000000   \n",
       "75%        0.41825350        2.35137526    0.84000000   -1.79000000   \n",
       "max        2.66190300        4.61512052    1.77000000    1.16000000   \n",
       "\n",
       "       features_temp_3  \n",
       "count    8528.00000000  \n",
       "mean       15.73579350  \n",
       "std        35.20638570  \n",
       "min         0.00000000  \n",
       "25%         0.58375000  \n",
       "50%         1.12800000  \n",
       "75%         1.87200000  \n",
       "max       100.00000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[feature_name].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-14a8b70d34d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7770\n",
       "1     758\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.141884\n",
      "[400]\tvalid_0's binary_logloss: 0.0950333\n",
      "[600]\tvalid_0's binary_logloss: 0.0926157\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[539]\tvalid_0's binary_logloss: 0.0918878\n",
      "fold:  1  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.140408\n",
      "[400]\tvalid_0's binary_logloss: 0.0901931\n",
      "[600]\tvalid_0's binary_logloss: 0.0858467\n",
      "[800]\tvalid_0's binary_logloss: 0.0884807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[553]\tvalid_0's binary_logloss: 0.0854446\n",
      "fold:  2  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.144524\n",
      "[400]\tvalid_0's binary_logloss: 0.0967919\n",
      "[600]\tvalid_0's binary_logloss: 0.0958722\n",
      "[800]\tvalid_0's binary_logloss: 0.0999617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[557]\tvalid_0's binary_logloss: 0.095408\n",
      "fold:  3  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.152469\n",
      "[400]\tvalid_0's binary_logloss: 0.101822\n",
      "[600]\tvalid_0's binary_logloss: 0.0990789\n",
      "[800]\tvalid_0's binary_logloss: 0.10187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[541]\tvalid_0's binary_logloss: 0.0985386\n",
      "fold:  4  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.140077\n",
      "[400]\tvalid_0's binary_logloss: 0.0893257\n",
      "[600]\tvalid_0's binary_logloss: 0.0837806\n",
      "[800]\tvalid_0's binary_logloss: 0.086256\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[617]\tvalid_0's binary_logloss: 0.0836303\n",
      "fold:  5  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.144608\n",
      "[400]\tvalid_0's binary_logloss: 0.0961631\n",
      "[600]\tvalid_0's binary_logloss: 0.0921764\n",
      "[800]\tvalid_0's binary_logloss: 0.0951527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[553]\tvalid_0's binary_logloss: 0.0918558\n",
      "fold:  6  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.149481\n",
      "[400]\tvalid_0's binary_logloss: 0.10121\n",
      "[600]\tvalid_0's binary_logloss: 0.0961344\n",
      "[800]\tvalid_0's binary_logloss: 0.101176\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[533]\tvalid_0's binary_logloss: 0.0959723\n",
      "fold:  7  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.14269\n",
      "[400]\tvalid_0's binary_logloss: 0.0939647\n",
      "[600]\tvalid_0's binary_logloss: 0.0911254\n",
      "[800]\tvalid_0's binary_logloss: 0.0960454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[537]\tvalid_0's binary_logloss: 0.0906862\n",
      "fold:  8  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.134166\n",
      "[400]\tvalid_0's binary_logloss: 0.0792988\n",
      "[600]\tvalid_0's binary_logloss: 0.073901\n",
      "[800]\tvalid_0's binary_logloss: 0.0769246\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[577]\tvalid_0's binary_logloss: 0.0736723\n",
      "fold:  9  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.129593\n",
      "[400]\tvalid_0's binary_logloss: 0.0758549\n",
      "[600]\tvalid_0's binary_logloss: 0.0688789\n",
      "[800]\tvalid_0's binary_logloss: 0.0699219\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[626]\tvalid_0's binary_logloss: 0.0687199\n",
      "fold f1 score is 0.8969219421945847\n",
      "fold acc score is 0.9679878048780488\n",
      "F1 measure for Normal rhythm: 0.9825\n",
      "F1 measure for AF rhythm: 0.8113\n",
      "F1 measure for Other rhythm: nan\n",
      "F1 measure for Noisy recordings: nan\n",
      "Final F1 measure: nan\n"
     ]
    }
   ],
   "source": [
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 10\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data_df = train_df[feature_name].astype('float64') #feature_name  columns\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data_df\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_data_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \\\n",
    "        train_label[train_fold], train_label[validate]\n",
    "        #print(X_validate)\n",
    "        #break\n",
    "        dtrain = lgb.Dataset(X_train, label_train)\n",
    "        dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        bst = lgb.train(lgb_params2, dtrain, num_boost_round=819, valid_sets=dvalid, verbose_eval=200,early_stopping_rounds=500)\n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "        #print(k_pred)\n",
    "        oof[validate] = [round(i) for i in k_pred]#np.argmax(k_pred,axis=1)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = count + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "oof = list(map(int, oof))\n",
    "fold_f1_error = f1_score(train_labels.values, oof, average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "fold_acc_error = accuracy_score(train_labels.values, oof)\n",
    "print('fold acc score is {0}'.format(fold_acc_error))\n",
    "\n",
    "F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_labels.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model(\"lightgbm_0510_groupfeat_2_35_tiaocan.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "def display_confusion_matrix(y_pred,y_true):\n",
    "    # Creates a confusion matrix\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "    # Transform to df for easier plotting\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = ['N','A'],#['N','A','O','~'], \n",
    "                         columns = ['N','A'])\n",
    "\n",
    "    plt.figure(figsize=(16,10))\n",
    "    sns.heatmap(cm_df, annot=True,annot_kws={'size':25,'weight':'bold', 'color':'r'},fmt=\"d\")#,cmap=\"RdBu\"\n",
    "    plt.title('Xgboost \\nAccuracy:{0:.3f}'.format(accuracy_score(y_pred,y_true)))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAALICAYAAAApGmi2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEpRRAAAAABKUUQAAAAASvn/r672SKUa6A4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_confusion_matrix(oof,train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_importances(model_name,feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(12, 16))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('{0} Features (avg over folds)'.format(model_name))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAR4CAYAAAAblHcQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNI9PSTUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:200].index.tolist()\n",
    "top_fea = display_importances(\"lightgbm\",feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Features_CP_19',\n",
       " 'sk_RR',\n",
       " 'Features_SD_16',\n",
       " 'AFEv',\n",
       " 'n_plus_mean',\n",
       " 'Features_ADC_9',\n",
       " 'R_amp_std',\n",
       " 'Features_CP_20',\n",
       " 'RR_min',\n",
       " 'Features_ADC_11',\n",
       " 'IrrEv',\n",
       " 'Features_CP_18',\n",
       " 'sample_entropy_1',\n",
       " 'v40_2_mean',\n",
       " 'features_temp_11',\n",
       " 'Features_SD_46',\n",
       " 'CV_deltaRR',\n",
       " 'Features_ADC_13',\n",
       " 'Features_SD_48',\n",
       " 'Features_SD_43',\n",
       " 'Features_SD_1',\n",
       " 'features_temp_2',\n",
       " 'Features_ADC_6',\n",
       " 'Features_CP_8',\n",
       " 'Features_SD_60',\n",
       " 'Features_RB_13',\n",
       " 'Features_SD_44',\n",
       " 'Radius',\n",
       " 'qrs_malin2_mean',\n",
       " 'Features_ADC_2',\n",
       " 'Features_ADC_3',\n",
       " 'Features_ADC_7',\n",
       " 'sample_entropy_2',\n",
       " 'features_temp_3',\n",
       " 'COSEn']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Predict_afdb(object):\n",
    "    def __init__(self, path,data_id,preprocess,feature39_name,feature188_name,select_feature_name):\n",
    "        super(Predict_afdb,self).__init__()\n",
    "        self.feature39_name = feature39_name\n",
    "        self.feature188_name = feature188_name\n",
    "        self.select_feature_name = select_feature_name\n",
    "        self.preprocess = preprocess\n",
    "        self.features39_id = []\n",
    "        self.labels = []\n",
    "        self.path = path\n",
    "        self.data_id = data_id\n",
    "        self.test_data = 0\n",
    "        self.pred_labels = []\n",
    "    def _get_id_labels(self):\n",
    "        with open(os.path.join(self.path,self.data_id+'_features39_id.txt')) as f:\n",
    "            temp = f.read().splitlines()#[-2909:]\n",
    "            self.features39_id = [x.split(\" \")[0] for x in temp]\n",
    "            self.labels = [x.split(\" \")[-1] for x in temp]\n",
    "    def _get_merge_features(self):\n",
    "        self._get_id_labels()\n",
    "        #print(self.features39_id)\n",
    "        \n",
    "        #读取39个特征\n",
    "        ''' \n",
    "        test_features39_pd = pd.read_csv(os.path.join(self.path,self.data_id+'_feat39.csv'))\n",
    "        test_features39_pd.dropna(inplace=True)\n",
    "        self.labels = test_features39_pd[\"label\"].values.tolist()\n",
    "        self.features39_id =  test_features39_pd[\"ID\"].values.tolist()\n",
    "        test_features39_pd.drop([\"ID\",\"label\"],axis=1,inplace=True)\n",
    "        test_features39_pd[\"id\"] = self.features39_id\n",
    "        #features39_pd.columns = feature39_name\n",
    "        #features38_pd['id']=file_list\n",
    "        '''\n",
    "        features39 = np.loadtxt(os.path.join(self.path,self.data_id+'_features39.txt'))#[-2909:]\n",
    "        test_features39_pd = pd.DataFrame(data=features39,columns=self.feature39_name)\n",
    "        test_features39_pd[\"id\"] = self.features39_id\n",
    "        #print(test_features39_pd.shape)\n",
    "        \n",
    "        #读取188个特征\n",
    "        if self.preprocess == False:\n",
    "            features188 = np.loadtxt(os.path.join(os.path.join(self.path,data_id),\"TH902_features_188_test.txt\"))\n",
    "        else:\n",
    "            features188 = np.loadtxt(os.path.join(os.path.join(self.path,\"results\",data_id),\"afdb_188features_lead1.txt\"))\n",
    "        features188_pd = pd.DataFrame(features188,columns=self.feature188_name)\n",
    "        features188_pd['id']=self.features39_id\n",
    "        #print(features188_pd.shape)\n",
    "        \n",
    "        \n",
    "        #读取38个特征\n",
    "        wclfeat_test_path = \"./wclfeature/afdb_test/\"\n",
    "        features38_pd = pd.read_csv(wclfeat_test_path+data_id+\"_feat_id.csv\")#,header=None\n",
    "        #features38_pd.drop(38,axis=1,inplace=True)\n",
    "        #features38_pd.columns = feature38_name+[\"label\"]   \n",
    "        #features38_pd['id']=self.features39_id\n",
    "        #features38_pd.to_csv(wclfeat_test_path+data_id+\"_feat_id.csv\",index=False)\n",
    "        #print(features38_pd.shape)\n",
    "        \n",
    "        test_data_all = pd.merge(test_features39_pd,features188_pd,on='id')\n",
    "        test_data_all = pd.merge(test_data_all,features38_pd,on='id')\n",
    "        self.test_data = test_data_all[self.select_feature_name] #feature39_name feature_name\n",
    "        \n",
    "        self.labels = test_data_all[\"label\"]\n",
    "        #test_data_all.to_csv(\"test.csv\")\n",
    "        #print(test_data_all[[\"id\",\"RR_range\"]])\n",
    "        #print(\"test_data shape: \",self.test_data.shape)\n",
    "    def _predict(self):\n",
    "        self._get_merge_features()\n",
    "        results = []\n",
    "        num_N=0\n",
    "        num_A=0\n",
    "        num_O=0\n",
    "        num_ = 0\n",
    "        result=0\n",
    "        for i in range(self.test_data.shape[0]):\n",
    "            dfeatures = self.test_data.iloc[i].astype('float64')\n",
    "            prediction_prob = bst.predict(dfeatures)\n",
    "            prediction = round(prediction_prob[0])#[round(prediction_prob) for i in prediction_prob] #np.argmax(prediction_prob)\n",
    "            self.pred_labels.append(prediction)\n",
    "\n",
    "            if prediction == 0:\n",
    "                num_N += 1\n",
    "                pred_label = \"N\"\n",
    "                result =self.features39_id[i] + '   N\\n'\n",
    "            elif prediction == 1:\n",
    "                num_A += 1\n",
    "                pred_label = \"AFIB\"\n",
    "                result = self.features39_id[i]+'   A\\n'\n",
    "            elif prediction == 2:\n",
    "                num_O += 1\n",
    "                pred_label = \"O\"\n",
    "                result =self.features39_id[i] + '   O\\n'\n",
    "            elif prediction == 3:\n",
    "                num_ += 1\n",
    "                pred_label = \"~\"\n",
    "                result = self.features39_id[i]+'   ~\\n'\n",
    "\n",
    "            results.append(result)\n",
    "            #pred_labels.append(pred_label)\n",
    "            #print(test_data_all.iloc[i].loc['id'])\n",
    "            #print(\"********* result :************ \", result)\n",
    "        print(\"\\n************************\\n\")\n",
    "        print(\"data_id =  \" ,self.data_id)\n",
    "        print(\"num_N = %d  :\" % num_N)\n",
    "        print(\"num_A = %d  :\" % num_A)\n",
    "        print(\"num_O = %d  :\" % num_O)\n",
    "        print(\"num_  = %d  :\" % num_ )\n",
    "        \n",
    "        return results\n",
    "    def _perf_measure(self,y_actual, y_hat):\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "\n",
    "        for i in range(len(y_hat)): \n",
    "            if y_actual[i]==y_hat[i]==1:\n",
    "                TP += 1\n",
    "            if y_hat[i]==1 and y_actual[i]!=1:\n",
    "                FP += 1\n",
    "            if y_actual[i]!=1 and y_actual[i]!=1:\n",
    "                TN += 1\n",
    "            if y_hat[i]!=1 and y_actual[i]==1:\n",
    "                FN += 1\n",
    "        #TP, FP, TN, FN = perf_measure(train_labels.values,pred_labels)\n",
    "\n",
    "        print(\"TP, FP, TN, FN == \",TP, FP, TN, FN)\n",
    "\n",
    "        SE = TP / (TP + FN+ 0.00001)\n",
    "        print(\"召回率或灵敏度 SE = TP / (TP + FN) == \",SE)\n",
    "\n",
    "        SP = TN / (TN + FP+0.00001)\n",
    "        print(\"特异性 SP = TN / (TN + FP) == \",SP)\n",
    "\n",
    "        PPV = TP / (TP + FP+ 0.00001)\n",
    "        print(\"阳性预测值 PPV = TP / (TP + FP) == \",PPV)\n",
    "        \n",
    "        Recall       = TP / (TP + FN + 0.00001)\n",
    "        Precision    = TP / (TP + FP + 0.00001)\n",
    "        Specificity  = TN / (TN + FP + 0.00001); # 1-FPR\n",
    "        Acc          = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "        print(\"Recall :\",Recall)\n",
    "        print(\"Precision :\",Precision)\n",
    "        print(\"Specificity :\",Specificity)\n",
    "        print(\"Acc :\",Acc)\n",
    "\n",
    "        return TP, FP, TN, FN,SE, SP, PPV, Acc\n",
    "    def display_confusion_matrix(self):\n",
    "        results = self._predict()\n",
    "        # Creates a confusion matrix\n",
    "        map_dict = {\"N\":0,\"AFIB\":1,\"AFL\":1,\"O\":0,\"~\":0,\"J\":0}#AFIB\n",
    "        train_labels = pd.Series(self.labels)#.map(map_dict)\n",
    "        \n",
    "        columns = pd.Series(self.labels).value_counts().index.values\n",
    "        print(\"true_labels : \\n\",train_labels.value_counts())\n",
    "        y_true = train_labels.values\n",
    "        y_pred = self.pred_labels\n",
    "        \n",
    "        cm = confusion_matrix(y_true,y_pred)\n",
    "        if cm.shape == (2,2):\n",
    "            cm_df = pd.DataFrame(cm,\n",
    "                                     index = ['A','O'], \n",
    "                                     columns = ['A','O'])\n",
    "        else:\n",
    "            # Transform to df for easier plotting\n",
    "            try:\n",
    "                cm_df = pd.DataFrame(cm,\n",
    "                                 index = ['N','A','O','~'], \n",
    "                                 columns = ['N','A','O','~'])\n",
    "            except ValueError:\n",
    "                cm_df = pd.DataFrame(cm,\n",
    "                                 index = ['N','A','O'], \n",
    "                                 columns = ['N','A','O'])\n",
    "        ''' \n",
    "        plt.figure(figsize=(16,10))\n",
    "        sns.heatmap(cm_df, annot=True,annot_kws={'size':25,'weight':'bold', 'color':'r'},fmt=\"d\")#,cmap=\"RdBu\"\n",
    "        plt.title('Xgboost \\nAccuracy:{0:.3f}'.format(accuracy_score(y_pred,y_true)))\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        '''\n",
    "        TP, FP, TN, FN,SE, SP, PPV, Acc = self._perf_measure(y_true,y_pred)\n",
    "        \n",
    "        return self.data_id,self.test_data.shape[0],TP, FP, TN, FN,SE, SP, PPV, Acc#,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bst = lgb.Booster(model_file='lightgbm_0510_groupfeat_2_35_tiaocan.bin')  #lgb.bin  lightgbm_0327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_feature_name = feature_name\n",
    "len(select_feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************\n",
      "\n",
      "data_id =   04015\n",
      "num_N = 1203  :\n",
      "num_A = 26  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1221\n",
      "1       8\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  8 18 1221 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999987500015626\n",
      "特异性 SP = TN / (TN + FP) ==  0.98547214700991\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.30769218934915793\n",
      "Recall : 0.9999987500015626\n",
      "Precision : 0.30769218934915793\n",
      "Specificity : 0.98547214700991\n",
      "Acc : 0.9855653568564555\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04043\n",
      "num_N = 977  :\n",
      "num_A = 277  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    978\n",
      "1    276\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  260 17 978 16\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9420289513757627\n",
      "特异性 SP = TN / (TN + FP) ==  0.9829145629857833\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9386281249592735\n",
      "Recall : 0.9420289513757627\n",
      "Precision : 0.9386281249592735\n",
      "Specificity : 0.9829145629857833\n",
      "Acc : 0.9740361919748229\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04048\n",
      "num_N = 1162  :\n",
      "num_A = 67  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1216\n",
      "1      13\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  13 54 1216 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999992307698226\n",
      "特异性 SP = TN / (TN + FP) ==  0.9574803074214149\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.19402982178659375\n",
      "Recall : 0.9999992307698226\n",
      "Precision : 0.19402982178659375\n",
      "Specificity : 0.9574803074214149\n",
      "Acc : 0.9579111457521434\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04126\n",
      "num_N = 1181  :\n",
      "num_A = 49  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1182\n",
      "1      48\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  48 1 1182 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.99999979166671\n",
      "特异性 SP = TN / (TN + FP) ==  0.999154683016444\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9795916368180332\n",
      "Recall : 0.99999979166671\n",
      "Precision : 0.9795916368180332\n",
      "Specificity : 0.999154683016444\n",
      "Acc : 0.9991876523151909\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04746\n",
      "num_N = 587  :\n",
      "num_A = 641  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    652\n",
      "0    576\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  641 0 576 11\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9831288192771653\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999826388892\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999843993762\n",
      "Recall : 0.9831288192771653\n",
      "Precision : 0.9999999843993762\n",
      "Specificity : 0.9999999826388892\n",
      "Acc : 0.991042345276873\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04908\n",
      "num_N = 1119  :\n",
      "num_A = 114  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1128\n",
      "1     105\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  105 9 1128 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999999047619138\n",
      "特异性 SP = TN / (TN + FP) ==  0.9920844239922214\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9210525507848639\n",
      "Recall : 0.9999999047619138\n",
      "Precision : 0.9210525507848639\n",
      "Specificity : 0.9920844239922214\n",
      "Acc : 0.9927536231884058\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04936\n",
      "num_N = 504  :\n",
      "num_A = 735  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    893\n",
      "0    346\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  708 27 346 185\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.792833137818218\n",
      "特异性 SP = TN / (TN + FP) ==  0.9276139161497611\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9632652930167988\n",
      "Recall : 0.792833137818218\n",
      "Precision : 0.9632652930167988\n",
      "Specificity : 0.9276139161497611\n",
      "Acc : 0.8325434439178515\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   05091\n",
      "num_N = 1226  :\n",
      "num_A = 3  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1225\n",
      "1       4\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  3 0 1225 1\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.7499981250046875\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999918367348\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999966666777778\n",
      "Recall : 0.7499981250046875\n",
      "Precision : 0.9999966666777778\n",
      "Specificity : 0.9999999918367348\n",
      "Acc : 0.9991863303498779\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   05121\n",
      "num_N = 585  :\n",
      "num_A = 651  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    778\n",
      "0    458\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  643 8 458 135\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.8264781384771448\n",
      "特异性 SP = TN / (TN + FP) ==  0.9828325969349229\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9877111983454502\n",
      "Recall : 0.8264781384771448\n",
      "Precision : 0.9877111983454502\n",
      "Specificity : 0.9828325969349229\n",
      "Acc : 0.885048231511254\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   05261\n",
      "num_N = 1214  :\n",
      "num_A = 18  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1214\n",
      "1      18\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  18 0 1214 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999994444447531\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999917627678\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999994444447531\n",
      "Recall : 0.9999994444447531\n",
      "Precision : 0.9999994444447531\n",
      "Specificity : 0.9999999917627678\n",
      "Acc : 1.0\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   06426\n",
      "num_N = 123  :\n",
      "num_A = 1112  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    1175\n",
      "0      60\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  1104 8 60 71\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.939574460088728\n",
      "特异性 SP = TN / (TN + FP) ==  0.8823528114187041\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9928057464675742\n",
      "Recall : 0.939574460088728\n",
      "Precision : 0.9928057464675742\n",
      "Specificity : 0.8823528114187041\n",
      "Acc : 0.9364440868865648\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   06453\n",
      "num_N = 1104  :\n",
      "num_A = 7  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1098\n",
      "1      13\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  7 0 1098 6\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.5384611242606736\n",
      "特异性 SP = TN / (TN + FP) ==  0.999999990892532\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999985714306123\n",
      "Recall : 0.5384611242606736\n",
      "Precision : 0.9999985714306123\n",
      "Specificity : 0.999999990892532\n",
      "Acc : 0.9945994599459946\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   06995\n",
      "num_N = 784  :\n",
      "num_A = 445  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    649\n",
      "1    580\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  443 2 649 137\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.7637930902794295\n",
      "特异性 SP = TN / (TN + FP) ==  0.9969277880656254\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9955055956066159\n",
      "Recall : 0.7637930902794295\n",
      "Precision : 0.9955055956066159\n",
      "Specificity : 0.9969277880656254\n",
      "Acc : 0.8870836718115354\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07162\n",
      "num_N = 171  :\n",
      "num_A = 1056  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    1227\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  1056 0 0 171\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.8606356898073702\n",
      "特异性 SP = TN / (TN + FP) ==  0.0\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999905303032\n",
      "Recall : 0.8606356898073702\n",
      "Precision : 0.9999999905303032\n",
      "Specificity : 0.0\n",
      "Acc : 0.8606356968215159\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07859\n",
      "num_N = 123  :\n",
      "num_A = 1104  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    1227\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  1104 0 0 123\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.8997554938895233\n",
      "特异性 SP = TN / (TN + FP) ==  0.0\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999909420291\n",
      "Recall : 0.8997554938895233\n",
      "Precision : 0.9999999909420291\n",
      "Specificity : 0.0\n",
      "Acc : 0.8997555012224939\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07879\n",
      "num_N = 489  :\n",
      "num_A = 739  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    740\n",
      "0    488\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  739 0 488 1\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9986486351533969\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999795081972\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999864682005\n",
      "Recall : 0.9986486351533969\n",
      "Precision : 0.9999999864682005\n",
      "Specificity : 0.9999999795081972\n",
      "Acc : 0.999185667752443\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07910\n",
      "num_N = 1030  :\n",
      "num_A = 198  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1032\n",
      "1     196\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  195 3 1032 1\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9948979084235761\n",
      "特异性 SP = TN / (TN + FP) ==  0.997101439641532\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9848484351086649\n",
      "Recall : 0.9948979084235761\n",
      "Precision : 0.9848484351086649\n",
      "Specificity : 0.997101439641532\n",
      "Acc : 0.9967506092607636\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08215\n",
      "num_N = 558  :\n",
      "num_A = 671  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    990\n",
      "0    239\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  671 0 239 319\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.6777777709315377\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999581589976\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999850968706\n",
      "Recall : 0.6777777709315377\n",
      "Precision : 0.9999999850968706\n",
      "Specificity : 0.9999999581589976\n",
      "Acc : 0.7404393816110659\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08219\n",
      "num_N = 982  :\n",
      "num_A = 262  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    969\n",
      "1    275\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  260 2 969 15\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9454545110743815\n",
      "特异性 SP = TN / (TN + FP) ==  0.997940257487742\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9923663743371613\n",
      "Recall : 0.9454545110743815\n",
      "Precision : 0.9923663743371613\n",
      "Specificity : 0.997940257487742\n",
      "Acc : 0.9863563402889246\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08378\n",
      "num_N = 993  :\n",
      "num_A = 238  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    973\n",
      "1    258\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  238 0 973 20\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9224805843999775\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999897225078\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999579831951\n",
      "Recall : 0.9224805843999775\n",
      "Precision : 0.9999999579831951\n",
      "Specificity : 0.9999999897225078\n",
      "Acc : 0.983753046303818\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08405\n",
      "num_N = 518  :\n",
      "num_A = 711  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    887\n",
      "0    342\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  711 0 342 176\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.8015783449652949\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999707602348\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999859353026\n",
      "Recall : 0.8015783449652949\n",
      "Precision : 0.9999999859353026\n",
      "Specificity : 0.9999999707602348\n",
      "Acc : 0.8567941415785191\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08434\n",
      "num_N = 1180  :\n",
      "num_A = 49  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1180\n",
      "1      49\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  49 0 1180 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999997959184089\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999915254238\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999997959184089\n",
      "Recall : 0.9999997959184089\n",
      "Precision : 0.9999997959184089\n",
      "Specificity : 0.9999999915254238\n",
      "Acc : 1.0\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08455\n",
      "num_N = 395  :\n",
      "num_A = 834  :\n",
      "num_O = 0  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    850\n",
      "0    379\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  834 0 379 16\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9811764590449829\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999736147764\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999880095926\n",
      "Recall : 0.9811764590449829\n",
      "Precision : 0.9999999880095926\n",
      "Specificity : 0.9999999736147764\n",
      "Acc : 0.9869812855980472\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=[\"ID\",\"samples\",\"TP\", \"FP\", \"TN\", \"FN\",\"SE\",\"SP\",\"PPV\",\"ACC\"])\n",
    "\n",
    "data_id_lists = ['04015', '04043', '04048', '04126', '04746', '04908', '04936', '05091', '05121', '05261', '06426', '06453', '06995',\n",
    "                 '07162', '07859', '07879', '07910', '08215', '08219', '08378', '08405', '08434', '08455']\n",
    "\n",
    "#data_id_lists = [\"04048\"]\n",
    "path = \"./AFdb_TEST0/\"\n",
    "for data_id in data_id_lists:\n",
    "    predict_afdb = Predict_afdb(path,data_id,True,feature39_name,feature188_name,select_feature_name)\n",
    "    ID,num,TP, FP, TN, FN,SE, SP, PPV, Acc = predict_afdb.display_confusion_matrix()\n",
    "    result.loc[result.shape[0]] = ID,num,TP, FP, TN, FN,SE, SP, PPV, Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"lead0_result_0510_2_35_tiaocan_1.csv\",index=False)#lead0_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def report_metrics(y_true,y_predict): \n",
    "    print('准确率:', metrics.accuracy_score(y_true, y_predict)) #预测准确率输出\n",
    "\n",
    "    print('宏平均精确率:',metrics.precision_score(y_true,y_predict,average='macro')) #预测宏平均精确率输出\n",
    "    print('微平均精确率:', metrics.precision_score(y_true, y_predict, average='micro')) #预测微平均精确率输出\n",
    "    print('加权平均精确率:', metrics.precision_score(y_true, y_predict, average='weighted')) #预测加权平均精确率输出\n",
    "\n",
    "    print('宏平均召回率:',metrics.recall_score(y_true,y_predict,average='macro'))#预测宏平均召回率输出\n",
    "    print('微平均召回率:',metrics.recall_score(y_true,y_predict,average='micro'))#预测微平均召回率输出\n",
    "    print('加权平均召回率:',metrics.recall_score(y_true,y_predict,average='micro'))#预测加权平均召回率输出\n",
    "\n",
    "    print('宏平均F1-score:',metrics.f1_score(y_true,y_predict,labels=[0,1,2,3],average='macro'))#预测宏平均f1-score输出\n",
    "    print('微平均F1-score:',metrics.f1_score(y_true,y_predict,labels=[0,1,2,3],average='micro'))#预测微平均f1-score输出\n",
    "    print('加权平均F1-score:',metrics.f1_score(y_true,y_predict,labels=[0,1,2,3],average='weighted'))#预测加权平均f1-score输出\n",
    "\n",
    "    print('混淆矩阵输出:\\n',metrics.confusion_matrix(y_true,y_predict,labels=[0,1,2,3]))#混淆矩阵输出\n",
    "    print('分类报告:\\n', metrics.classification_report(y_true, y_predict,labels=[0,1,2,3]))#分类报告输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "#构建xgb模型并进行交叉验证，该模型可以验证更新后的模型好坏\n",
    "#定义modelfit函数，根据一定的学习率得到最优迭代次数\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_params()\n",
    "        xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[\"label\"].values,silent=True)\n",
    "        #xgb.DMatrix(dtrain[predictors].values, label=dtrain[\"label\"].values)\n",
    "        cvresult = lgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            early_stopping_rounds=early_stopping_rounds, verbose_eval=20)\n",
    "        alg.set_params(n_estimators=len(cvresult[\"binary_logloss-stdv\"]))\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['label'],eval_metric='binary_logloss')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print(\"estimators num : {0}\".format(len(cvresult[\"binary_logloss-stdv\"])))\n",
    "    #print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['label'].values, dtrain_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['label'], dtrain_predprob))\n",
    "    cinc_f1_score(dtrain['label'].values, dtrain_predictions)\n",
    "    report_metrics(dtrain['label'].values, dtrain_predictions)\n",
    "    \n",
    "    return alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_importances(model_name,feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('{0} Features (avg over folds)'.format(model_name))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "[20]\tcv_agg's binary_logloss: 0.544625 + 0.000725219\n",
      "[40]\tcv_agg's binary_logloss: 0.439171 + 0.00120886\n",
      "[60]\tcv_agg's binary_logloss: 0.361374 + 0.0017404\n",
      "[80]\tcv_agg's binary_logloss: 0.302598 + 0.00209915\n",
      "[100]\tcv_agg's binary_logloss: 0.257395 + 0.00249468\n",
      "[120]\tcv_agg's binary_logloss: 0.222334 + 0.00289383\n",
      "[140]\tcv_agg's binary_logloss: 0.194788 + 0.00329546\n",
      "[160]\tcv_agg's binary_logloss: 0.172917 + 0.00367798\n",
      "[180]\tcv_agg's binary_logloss: 0.1555 + 0.00410069\n",
      "[200]\tcv_agg's binary_logloss: 0.141597 + 0.00444269\n",
      "[220]\tcv_agg's binary_logloss: 0.130563 + 0.00485692\n",
      "[240]\tcv_agg's binary_logloss: 0.121674 + 0.00511973\n",
      "[260]\tcv_agg's binary_logloss: 0.114499 + 0.00531821\n",
      "[280]\tcv_agg's binary_logloss: 0.108696 + 0.00564801\n",
      "[300]\tcv_agg's binary_logloss: 0.104027 + 0.00584034\n",
      "[320]\tcv_agg's binary_logloss: 0.100183 + 0.00598948\n",
      "[340]\tcv_agg's binary_logloss: 0.097173 + 0.00617237\n",
      "[360]\tcv_agg's binary_logloss: 0.0947468 + 0.00635087\n",
      "[380]\tcv_agg's binary_logloss: 0.0928256 + 0.00651094\n",
      "[400]\tcv_agg's binary_logloss: 0.0913361 + 0.00677887\n",
      "[420]\tcv_agg's binary_logloss: 0.090119 + 0.0069395\n",
      "[440]\tcv_agg's binary_logloss: 0.0891481 + 0.00714322\n",
      "[460]\tcv_agg's binary_logloss: 0.0884044 + 0.00734924\n",
      "[480]\tcv_agg's binary_logloss: 0.0878971 + 0.00752438\n",
      "[500]\tcv_agg's binary_logloss: 0.0873831 + 0.00759964\n",
      "[520]\tcv_agg's binary_logloss: 0.0870235 + 0.00769324\n",
      "[540]\tcv_agg's binary_logloss: 0.086739 + 0.00778192\n",
      "[560]\tcv_agg's binary_logloss: 0.0865272 + 0.00787228\n",
      "[580]\tcv_agg's binary_logloss: 0.0863806 + 0.00791038\n",
      "[600]\tcv_agg's binary_logloss: 0.086305 + 0.00791846\n",
      "[620]\tcv_agg's binary_logloss: 0.0862421 + 0.0080436\n",
      "[640]\tcv_agg's binary_logloss: 0.0862071 + 0.00811363\n",
      "[660]\tcv_agg's binary_logloss: 0.0861398 + 0.0081798\n",
      "[680]\tcv_agg's binary_logloss: 0.0861596 + 0.00815424\n",
      "[700]\tcv_agg's binary_logloss: 0.0861924 + 0.00824718\n",
      "\n",
      "Model Report\n",
      "estimators num : 661\n",
      "F1 measure for Normal rhythm: 0.9950\n",
      "F1 measure for AF rhythm: 0.9481\n",
      "F1 measure for Other rhythm: nan\n",
      "F1 measure for Noisy recordings: nan\n",
      "Final F1 measure: nan\n",
      "准确率: 0.9908536585365854\n",
      "宏平均精确率: 0.9749907499467734\n",
      "微平均精确率: 0.9908536585365854\n",
      "加权平均精确率: 0.9907995496954604\n",
      "宏平均召回率: 0.9681930705677407\n",
      "微平均召回率: 0.9908536585365854\n",
      "加权平均召回率: 0.9908536585365854\n",
      "宏平均F1-score: 0.4857807164433937\n",
      "微平均F1-score: 0.9908536585365854\n",
      "加权平均F1-score: 0.9908206991533568\n",
      "混淆矩阵输出:\n",
      " [[7737   33    0    0]\n",
      " [  45  713    0    0]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]]\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "           1       0.96      0.94      0.95       758\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8528\n",
      "   macro avg       0.49      0.48      0.49      8528\n",
      "weighted avg       0.99      0.99      0.99      8528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors = feature_name\n",
    "print(len(feature_name))\n",
    "lgb1 = LGBMClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='binary',\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "model = modelfit(lgb1, train_df, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 5,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 1,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 661,\n",
       " 'n_jobs': 4,\n",
       " 'num_class': 1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'binary',\n",
       " 'random_state': 27,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 1}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'num_leaves': 50}, 0.9685741088180112)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "### 我们可以创建lgb的sklearn模型，使用上面选择的(学习率，评估器数目)\n",
    "\n",
    "lgb1 = LGBMClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=62,\n",
    " max_depth=5,\n",
    " num_leaves=50,\n",
    " min_child_weight=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='binary',\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "params_test1={\n",
    "    'max_depth': range(3,8,2),\n",
    "    'num_leaves':range(50, 170, 30)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator=lgb1, param_grid=params_test1, scoring='f1_micro', cv=5, verbose=1, n_jobs=4)\n",
    "gsearch1.fit(train_df[predictors],train_df[\"label\"])\n",
    "#gsearch1.grid_scores_, \n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'num_leaves': 30}, 0.9685741088180112)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_test2={\n",
    "    'max_depth': [2,3,4,5],\n",
    "    'num_leaves':[30,40,50,60,70]\n",
    "}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator=lgb1, param_grid=params_test2, scoring='f1_micro', cv=5, verbose=1, n_jobs=4)\n",
    "gsearch2.fit(train_df[predictors],train_df[\"label\"])\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  32 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-4)]: Done  50 out of  50 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'min_child_samples': 20, 'min_child_weight': 0.001}, 0.9685741088180112)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb3 = LGBMClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=62,\n",
    " max_depth=3,\n",
    " num_leaves=30,\n",
    " min_child_weight=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='binary',\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "params_test3={\n",
    "    'min_child_samples': [18, 19, 20, 21, 22],\n",
    "    'min_child_weight':[0.001, 0.002]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator=lgb3, param_grid=params_test3, scoring='f1_micro', cv=5, verbose=1, n_jobs=-4)\n",
    "gsearch3.fit(train_df[predictors],train_df[\"label\"])\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  30 out of  30 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'min_child_samples': 19, 'min_child_weight': 0.0005}, 0.9681050656660413)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb3 = LGBMClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=62,\n",
    " max_depth=3,\n",
    " num_leaves=30,\n",
    " min_child_weight=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='binary',\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "params_test3={\n",
    "    'min_child_samples': [17,18, 19],\n",
    "    'min_child_weight':[0.0005,0.001]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator=lgb3, param_grid=params_test3, scoring='f1_micro', cv=5, verbose=1, n_jobs=-4)\n",
    "gsearch3.fit(train_df[predictors],train_df[\"label\"])\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend LokyBackend with 9 concurrent workers.\n",
      "[Parallel(n_jobs=-4)]: Done  32 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-4)]: Done  80 out of  80 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.7, 'subsample': 0.9}, 0.9684568480300187)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb4 = LGBMClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=62,\n",
    " max_depth=3,\n",
    " num_leaves=30,\n",
    " min_child_weight=0.0005,\n",
    " min_child_samples=19,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='binary',\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "\n",
    "params_test4={\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9,1],\n",
    "    'subsample': [0.7, 0.8, 0.9,1]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator=lgb4, param_grid=params_test4, scoring='f1_micro', cv=5, verbose=1, n_jobs=-4)\n",
    "gsearch4.fit(train_df[predictors],train_df[\"label\"])\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=4)]: Done 245 out of 245 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 0.08, 'reg_lambda': 0.001}, 0.9689258911819888)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lgb5 = LGBMClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=62,\n",
    " max_depth=3,\n",
    " num_leaves=30,\n",
    " min_child_weight=0.0005,\n",
    " min_child_samples=19,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.7,\n",
    " objective='binary',\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "params_test5={\n",
    "    'reg_alpha': [0, 0.001, 0.01, 0.03, 0.08, 0.3, 0.5],\n",
    "    'reg_lambda': [0, 0.001, 0.01, 0.03, 0.08, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator=lgb5, param_grid=params_test5, scoring='f1_micro', cv=5, verbose=1, n_jobs=4)\n",
    "gsearch5.fit(train_df[predictors],train_df[\"label\"])\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's binary_logloss: 0.546949 + 0.000667261\n",
      "[40]\tcv_agg's binary_logloss: 0.442923 + 0.00108852\n",
      "[60]\tcv_agg's binary_logloss: 0.366032 + 0.00161094\n",
      "\n",
      "Model Report\n",
      "estimators num : 62\n",
      "F1 measure for Normal rhythm: 0.9824\n",
      "F1 measure for AF rhythm: 0.8043\n",
      "F1 measure for Other rhythm: nan\n",
      "F1 measure for Noisy recordings: nan\n",
      "Final F1 measure: nan\n",
      "准确率: 0.9676360225140713\n",
      "宏平均精确率: 0.9226905065322312\n",
      "微平均精确率: 0.9676360225140713\n",
      "加权平均精确率: 0.966317023429333\n",
      "宏平均召回率: 0.8685407986199543\n",
      "微平均召回率: 0.9676360225140713\n",
      "加权平均召回率: 0.9676360225140713\n",
      "宏平均F1-score: 0.4466537569251607\n",
      "微平均F1-score: 0.9676360225140713\n",
      "加权平均F1-score: 0.9665291354786179\n",
      "混淆矩阵输出:\n",
      " [[7685   85    0    0]\n",
      " [ 191  567    0    0]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]]\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7770\n",
      "           1       0.87      0.75      0.80       758\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8528\n",
      "   macro avg       0.46      0.43      0.45      8528\n",
      "weighted avg       0.97      0.97      0.97      8528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb1 = LGBMClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=62,\n",
    " max_depth=3,\n",
    " num_leaves=30,\n",
    " min_child_weight=0.0005,\n",
    " min_child_samples=19,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.7,\n",
    " objective='binary',\n",
    " reg_alpha=0.08,\n",
    " reg_lambda = 0.001,\n",
    " num_class= 1,\n",
    " n_jobs=4,\n",
    " #class_weight =\"1\",\n",
    " random_state =27)\n",
    "\n",
    "model = modelfit(lgb1, train_df, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
