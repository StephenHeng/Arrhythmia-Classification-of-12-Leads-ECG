{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb.processing as wp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from utils import find_noise_features, extract_basic_features\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "path = \"F:\\\\ECG数据集\\\\www.physionet.org\\\\physiobank\\\\database\\\\afdb\\\\\"\n",
    "record_name = \"04048\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cinc_f1_score(ref, ans, verbose=True, details=False):\n",
    "    assert (ref.shape[0] == ans.shape[0])\n",
    "\n",
    "    AA = np.zeros((4, 4))\n",
    "\n",
    "    for n in range(ref.shape[0]):\n",
    "        rec = ref[n]\n",
    "\n",
    "        this_answer = ans[n]\n",
    "\n",
    "        if rec == 0:\n",
    "            if this_answer == 0:\n",
    "                AA[0, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[0, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[0, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[0, 3] += 1\n",
    "\n",
    "        elif rec == 1:\n",
    "            if this_answer == 0:\n",
    "                AA[1, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[1, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[1, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[1, 3] += 1\n",
    "\n",
    "        elif rec == 2:\n",
    "            if this_answer == 0:\n",
    "                AA[2, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[2, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[2, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[2, 3] += 1\n",
    "\n",
    "        elif rec == 3:\n",
    "            if this_answer == 0:\n",
    "                AA[3, 0] += 1\n",
    "            elif this_answer == 1:\n",
    "                AA[3, 1] += 1\n",
    "            elif this_answer == 2:\n",
    "                AA[3, 2] += 1\n",
    "            elif this_answer == 3:\n",
    "                AA[3, 3] += 1\n",
    "\n",
    "    F1n = 2 * AA[0, 0] / (sum(AA[0, :]) + sum(AA[:, 0]))\n",
    "    F1a = 2 * AA[1, 1] / (sum(AA[1, :]) + sum(AA[:, 1]))\n",
    "    F1o = 2 * AA[2, 2] / (sum(AA[2, :]) + sum(AA[:, 2]))\n",
    "    F1p = 2 * AA[3, 3] / (sum(AA[3, :]) + sum(AA[:, 3]))\n",
    "    F1 = (F1n + F1a + F1o) / 3\n",
    "    if details:\n",
    "        print(AA)\n",
    "    if verbose:\n",
    "        print('F1 measure for Normal rhythm: ' '%1.4f' % F1n)\n",
    "        print('F1 measure for AF rhythm: ' '%1.4f' % F1a)\n",
    "        print('F1 measure for Other rhythm: ' '%1.4f' % F1o)\n",
    "        print('F1 measure for Noisy recordings: ' '%1.4f' % F1p)\n",
    "        print('Final F1 measure: ' '%1.4f' % F1)\n",
    "\n",
    "    return F1n,F1a,F1o,F1p,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "def getFileName(base_path):\n",
    "    f_list = os.listdir(base_path)\n",
    "    file_temp = []\n",
    "    # print f_list\n",
    "    for i in f_list:\n",
    "        if os.path.isdir(os.path.join(base_path,i)):\n",
    "            files = os.listdir(os.path.join(base_path,i))\n",
    "            for file in files:\n",
    "                # os.path.splitext():分离文件名与扩展名\n",
    "                if os.path.splitext(file)[1] == '.txt':\n",
    "                    print(file)\n",
    "                    file_path = os.path.join(base_path,i)+\"\\\\\"+file\n",
    "                    print(file_path)\n",
    "                    newfile_path = os.path.join(base_path,\"results\",i)+\"\\\\\"+\"afdb_188features_lead1.txt\"\n",
    "                    print(newfile_path)\n",
    "                    if not os.path.exists(os.path.join(base_path,\"results\",i)):   \n",
    "                        os.makedirs(os.path.join(base_path,\"results\",i))\n",
    "                        \n",
    "                    shutil.copyfile(file_path,newfile_path)\n",
    "                    \n",
    "                    print(file)#file_temp.append(i.split(\".\")[0])\n",
    "    return file_temp\n",
    "#getFileName(\"F:\\\\ECG\\\\2017挑战赛ECG论文\\\\dawid-smolen-206\\\\AFdb_TEST1\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature38_name = ['CV','rmssd','QRS_Width_std','MAD','AFEv','IrrEv','OriginCount','PACEv','R_amp_std','RR_mean',\n",
    "           'RR_min','HR_median','RR_max','CV_deltaRR','Pf_1','Pf_2','pf_RR_1','pf_RR_2','pf_RR_3','se', \n",
    "           'nn50', 'percentage_nn50', 'arrhyth_ind', 'res_kstest','COSEn', 'Radius','similar_ind_QRS','similar_ind_Ramp',\n",
    "           'r_high_similarbeats','stepping', 'E','MOBILITY','COMPLEXITY','R_amp_CV', 'QRS_width_mean','sk_RR','kurt_RR','RR_range']\n",
    "feature16_name=[]\n",
    "for i in [6,5,26,25,22,30,24,36,20,7,32,1,33,12,21,29]:\n",
    "    feature16_name.append(feature38_name[i-1])\n",
    "feature39_name = [\n",
    "    \"var\", \"skew\", \"kurtosis\", \"perdiogram_1\", \"perdiogram_2\", \"perdiogram_3\",\n",
    "    \"perdiogram_4\", \"qrs_areas_mean\", \"qrs_areas_max\", \"qrs_areas2_mean\",\n",
    "    \"qrs_areas2_max\", \"qrs_malin_mean\", \"qrs_malin_max\", \"qrs_malin2_mean\",\n",
    "    \"qrs_malin2_max\", \"n_plus_mean\", \"n_plus_max\", \"n_plus2_mean\",\n",
    "    \"n_plus2_max\", \"v40_mean\", \"v40_max\", \"v40_2_mean\", \"v40_2_max\",\n",
    "    \"freq_ratio_1\", \"freq_ratio_2\", \"freq_ratio_3\", \"freq_ratio_4\",\n",
    "    \"freq_ratio_5\", \"lorenz_plot\", \"rr_var\", \"rr_var_1\", \"rr_var_2\", \"log_rr\",\n",
    "    \"log_rr_1_abs\", \"sample_entropy_1\", \"sample_entropy_2\",\n",
    "    \"shannon_entropy_1\", \"shannon_entropy_2\", \"correlation\"\n",
    "]\n",
    "def generate_feature188():\n",
    "    a=\"Features_SD_1\"\n",
    "    feature_name = []\n",
    "    feature_sd_name = []\n",
    "    for i in range(1,69,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        feature_sd_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a=\"Features_RB_1\"\n",
    "    for i in range(1,16,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a=\"Features_ADC_1\"\n",
    "    feature_adc_name = []\n",
    "    for i in range(1,22,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        feature_adc_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a='Features_embcsoa_1'\n",
    "    for i in range(1,9,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a=\"Features_CP_1\"\n",
    "    for i in range(1,28,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a='features_temp_1'\n",
    "    for i in range(1,20,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "\n",
    "    a='features_temp_rs_1'\n",
    "    for i in range(1,31,1):\n",
    "        b=a.replace(str(i),str(i+1))\n",
    "        feature_name.append(a)\n",
    "        a=b\n",
    "    return feature_name,feature_sd_name,feature_adc_name\n",
    "feature188_name,feature_sd_name,feature_adc_name= generate_feature188()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"F:\\\\ECG\\\\ecg\\\\training2017\\\\\"\n",
    "f_list = os.listdir(path)\n",
    "file_list = []\n",
    "for i in f_list:\n",
    "    # os.path.splitext():分离文件名与扩展名\n",
    "    if os.path.splitext(i)[1] == '.mat':\n",
    "        file_list.append(i.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>perdiogram_1</th>\n",
       "      <th>perdiogram_2</th>\n",
       "      <th>perdiogram_3</th>\n",
       "      <th>perdiogram_4</th>\n",
       "      <th>qrs_areas_mean</th>\n",
       "      <th>qrs_areas_max</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.909595</td>\n",
       "      <td>11.207767</td>\n",
       "      <td>-5022.949108</td>\n",
       "      <td>-4897.418491</td>\n",
       "      <td>-6417.626901</td>\n",
       "      <td>-8600.342510</td>\n",
       "      <td>0.348011</td>\n",
       "      <td>0.602488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11.201408</td>\n",
       "      <td>0.781425</td>\n",
       "      <td>3.782768</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.504121</td>\n",
       "      <td>4.499598</td>\n",
       "      <td>0.006479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.935605</td>\n",
       "      <td>15.180122</td>\n",
       "      <td>-4976.180846</td>\n",
       "      <td>-4776.655937</td>\n",
       "      <td>-6577.618563</td>\n",
       "      <td>-8395.064863</td>\n",
       "      <td>0.295944</td>\n",
       "      <td>0.919263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>9.144809</td>\n",
       "      <td>2.459695</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>1.592631</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.694019</td>\n",
       "      <td>0.117561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-1.580090</td>\n",
       "      <td>4.994374</td>\n",
       "      <td>-10358.327470</td>\n",
       "      <td>-10455.589720</td>\n",
       "      <td>-14087.272830</td>\n",
       "      <td>-18263.731720</td>\n",
       "      <td>-0.091824</td>\n",
       "      <td>0.200487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>19.644293</td>\n",
       "      <td>2.044110</td>\n",
       "      <td>2.211211</td>\n",
       "      <td>1.800493</td>\n",
       "      <td>5.167088</td>\n",
       "      <td>5.119668</td>\n",
       "      <td>0.025986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>3.551206</td>\n",
       "      <td>14.768413</td>\n",
       "      <td>-4898.854941</td>\n",
       "      <td>-4707.588663</td>\n",
       "      <td>-6478.057380</td>\n",
       "      <td>-8517.461309</td>\n",
       "      <td>0.415471</td>\n",
       "      <td>0.506781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>9.152490</td>\n",
       "      <td>3.104567</td>\n",
       "      <td>2.984304</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.789015</td>\n",
       "      <td>0.038117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00005</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.303823</td>\n",
       "      <td>8.327276</td>\n",
       "      <td>-10835.293760</td>\n",
       "      <td>-10181.270340</td>\n",
       "      <td>-13613.273700</td>\n",
       "      <td>-17518.596880</td>\n",
       "      <td>0.119709</td>\n",
       "      <td>0.540239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>22.598280</td>\n",
       "      <td>10.004504</td>\n",
       "      <td>2.332943</td>\n",
       "      <td>1.735189</td>\n",
       "      <td>6.079932</td>\n",
       "      <td>6.396046</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       var      skew   kurtosis  perdiogram_1  perdiogram_2  \\\n",
       "0  A00001  0.000111  2.909595  11.207767  -5022.949108  -4897.418491   \n",
       "1  A00002  0.000111  2.935605  15.180122  -4976.180846  -4776.655937   \n",
       "2  A00003  0.000056 -1.580090   4.994374 -10358.327470 -10455.589720   \n",
       "3  A00004  0.000111  3.551206  14.768413  -4898.854941  -4707.588663   \n",
       "4  A00005  0.000056  2.303823   8.327276 -10835.293760 -10181.270340   \n",
       "\n",
       "   perdiogram_3  perdiogram_4  qrs_areas_mean  qrs_areas_max     ...       \\\n",
       "0  -6417.626901  -8600.342510        0.348011       0.602488     ...        \n",
       "1  -6577.618563  -8395.064863        0.295944       0.919263     ...        \n",
       "2 -14087.272830 -18263.731720       -0.091824       0.200487     ...        \n",
       "3  -6478.057380  -8517.461309        0.415471       0.506781     ...        \n",
       "4 -13613.273700 -17518.596880        0.119709       0.540239     ...        \n",
       "\n",
       "     rr_var  rr_var_1  rr_var_2     log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  0.000049  0.000022  0.000044  11.201408      0.781425          3.782768   \n",
       "1  0.001101  0.002392  0.008281   9.144809      2.459695          1.916463   \n",
       "2  0.000146  0.000197  0.000517  19.644293      2.044110          2.211211   \n",
       "3  0.001151  0.001939  0.005273   9.152490      3.104567          2.984304   \n",
       "4  0.001371  0.001967  0.004816  22.598280     10.004504          2.332943   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  \n",
       "0          2.772589           4.504121           4.499598     0.006479  \n",
       "1          1.592631           4.640224           4.694019     0.117561  \n",
       "2          1.800493           5.167088           5.119668     0.025986  \n",
       "3          2.890372           4.640224           4.789015     0.038117  \n",
       "4          1.735189           6.079932           6.396046     0.026922  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取39个特征数据\n",
    "if os.path.isfile(\"cinc_feat.csv\"):\n",
    "    features39_pd = pd.read_csv(\"cinc_feat.csv\")\n",
    "features39_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>Features_SD_10</th>\n",
       "      <th>...</th>\n",
       "      <th>features_temp_rs_22</th>\n",
       "      <th>features_temp_rs_23</th>\n",
       "      <th>features_temp_rs_24</th>\n",
       "      <th>features_temp_rs_25</th>\n",
       "      <th>features_temp_rs_26</th>\n",
       "      <th>features_temp_rs_27</th>\n",
       "      <th>features_temp_rs_28</th>\n",
       "      <th>features_temp_rs_29</th>\n",
       "      <th>features_temp_rs_30</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.298329</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A00005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  Features_SD_5  \\\n",
       "0          -11.0           11.0            0.0            0.0            0.0   \n",
       "1            9.0            7.0           16.0            0.0            0.0   \n",
       "2          -26.0           31.0            5.0            0.0            0.0   \n",
       "3           26.0            0.0           26.0            0.0            1.0   \n",
       "4           57.0           10.0           75.0            4.0            9.0   \n",
       "\n",
       "   Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  Features_SD_10  \\\n",
       "0            0.0       0.044264       0.031529       0.039185        0.013482   \n",
       "1            4.0       0.325171       0.296396       0.298329        0.171309   \n",
       "2            3.0       0.093895       0.088135       0.064279        0.056015   \n",
       "3            5.0       0.195561       0.251051       0.318723        0.107943   \n",
       "4           15.0       0.412665       0.503457       0.537868        0.263645   \n",
       "\n",
       "    ...    features_temp_rs_22  features_temp_rs_23  features_temp_rs_24  \\\n",
       "0   ...                    0.0                  0.0                  0.0   \n",
       "1   ...                    0.0                  0.0                  0.0   \n",
       "2   ...                    0.0                  0.0                  0.0   \n",
       "3   ...                    0.0                  0.0                  0.0   \n",
       "4   ...                    0.0                  0.0                  0.0   \n",
       "\n",
       "   features_temp_rs_25  features_temp_rs_26  features_temp_rs_27  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   features_temp_rs_28  features_temp_rs_29  features_temp_rs_30      id  \n",
       "0                  0.0                  0.0                  0.0  A00001  \n",
       "1                  0.0                  0.0                  0.0  A00002  \n",
       "2                  0.0                  0.0                  0.0  A00003  \n",
       "3                  0.0                  0.0                  0.0  A00004  \n",
       "4                  0.0                  0.0                  0.0  A00005  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取188个特征数据\n",
    "path = \"F:\\\\ECG\\\\ecg\\\\training2017\\\\\"\n",
    "if os.path.isfile(\"cinc_feat188.csv\"):\n",
    "    features188_pd = pd.read_csv(\"cinc_feat188.csv\")\n",
    "else:\n",
    "    data = np.loadtxt(path+\"TH902_features_188.txt\")\n",
    "    features188_pd = pd.DataFrame(data,columns=feature188_name,index=file_list)\n",
    "     \n",
    "    features188_pd['id']=file_list\n",
    "    col = feature188_name.copy()\n",
    "    col.insert(0,'id')\n",
    "    #features15_pd = features15_pd.reindex(columns=col)\n",
    "    features188_pd.to_csv(\"cinc_feat188.csv\",index=False)\n",
    "features188_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>QRS_Width_std</th>\n",
       "      <th>MAD</th>\n",
       "      <th>AFEv</th>\n",
       "      <th>IrrEv</th>\n",
       "      <th>OriginCount</th>\n",
       "      <th>PACEv</th>\n",
       "      <th>R_amp_std</th>\n",
       "      <th>RR_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>stepping</th>\n",
       "      <th>E</th>\n",
       "      <th>MOBILITY</th>\n",
       "      <th>COMPLEXITY</th>\n",
       "      <th>R_amp_CV</th>\n",
       "      <th>QRS_width_mean</th>\n",
       "      <th>sk_RR</th>\n",
       "      <th>kurt_RR</th>\n",
       "      <th>RR_range</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.11</td>\n",
       "      <td>A00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.89</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.13</td>\n",
       "      <td>A00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.28</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>11.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>A00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.62</td>\n",
       "      <td>A00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>58.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>28.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>A00005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CV  rmssd  QRS_Width_std   MAD  AFEv  IrrEv  OriginCount  PACEv  \\\n",
       "0  0.04  0.00            0.00  0.03  -6.0    0.0          6.0    0.0   \n",
       "1  0.04  0.00            0.00  0.03  -6.0    0.0          6.0    0.0   \n",
       "2  0.10  0.01            0.01  0.04 -14.0    8.0         22.0    0.0   \n",
       "3  0.19  0.06            0.00  0.15  26.0   26.0          0.0    0.0   \n",
       "4  0.41  0.07            0.01  0.18  58.0   76.0          8.0    5.0   \n",
       "\n",
       "   R_amp_std  RR_mean   ...    stepping      E  MOBILITY  COMPLEXITY  \\\n",
       "0       0.09     0.76   ...        0.04  11.90      0.16        9.03   \n",
       "1       0.07     1.03   ...        0.04  -0.95      0.24        5.89   \n",
       "2       0.12     0.74   ...        0.11  21.17      0.20        8.28   \n",
       "3       0.11     0.95   ...        0.32   0.12      0.30        5.23   \n",
       "4       0.16     0.54   ...        0.53  28.54      0.48        3.29   \n",
       "\n",
       "   R_amp_CV  QRS_width_mean  sk_RR  kurt_RR  RR_range      id  \n",
       "0      0.11            0.07   0.12     1.80      0.11  A00001  \n",
       "1      0.10            0.07  -0.41     2.62      0.13  A00002  \n",
       "2     -0.26            0.07   0.18    11.10      0.61  A00003  \n",
       "3      0.09            0.07   0.48     2.05      0.62  A00004  \n",
       "4      0.17            0.06   1.18     3.02      0.78  A00005  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./wclfeature/\"\n",
    "features38_pd = pd.read_csv(path+\"cinc_feat.csv\",header=None)\n",
    "features38_pd.drop([0,39],axis=1,inplace=True)\n",
    "features38_pd.columns = feature38_name\n",
    "features38_pd['id']=file_list\n",
    "features38_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>Features_SD_10</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11.201408</td>\n",
       "      <td>0.781425</td>\n",
       "      <td>3.782768</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.504121</td>\n",
       "      <td>4.499598</td>\n",
       "      <td>0.006479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.298329</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>9.144809</td>\n",
       "      <td>2.459695</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>1.592631</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.694019</td>\n",
       "      <td>0.117561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>19.644293</td>\n",
       "      <td>2.044110</td>\n",
       "      <td>2.211211</td>\n",
       "      <td>1.800493</td>\n",
       "      <td>5.167088</td>\n",
       "      <td>5.119668</td>\n",
       "      <td>0.025986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>9.152490</td>\n",
       "      <td>3.104567</td>\n",
       "      <td>2.984304</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.789015</td>\n",
       "      <td>0.038117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>22.598280</td>\n",
       "      <td>10.004504</td>\n",
       "      <td>2.332943</td>\n",
       "      <td>1.735189</td>\n",
       "      <td>6.079932</td>\n",
       "      <td>6.396046</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  Features_SD_5  \\\n",
       "0          -11.0           11.0            0.0            0.0            0.0   \n",
       "1            9.0            7.0           16.0            0.0            0.0   \n",
       "2          -26.0           31.0            5.0            0.0            0.0   \n",
       "3           26.0            0.0           26.0            0.0            1.0   \n",
       "4           57.0           10.0           75.0            4.0            9.0   \n",
       "\n",
       "   Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  Features_SD_10  \\\n",
       "0            0.0       0.044264       0.031529       0.039185        0.013482   \n",
       "1            4.0       0.325171       0.296396       0.298329        0.171309   \n",
       "2            3.0       0.093895       0.088135       0.064279        0.056015   \n",
       "3            5.0       0.195561       0.251051       0.318723        0.107943   \n",
       "4           15.0       0.412665       0.503457       0.537868        0.263645   \n",
       "\n",
       "      ...         rr_var  rr_var_1  rr_var_2     log_rr  log_rr_1_abs  \\\n",
       "0     ...       0.000049  0.000022  0.000044  11.201408      0.781425   \n",
       "1     ...       0.001101  0.002392  0.008281   9.144809      2.459695   \n",
       "2     ...       0.000146  0.000197  0.000517  19.644293      2.044110   \n",
       "3     ...       0.001151  0.001939  0.005273   9.152490      3.104567   \n",
       "4     ...       0.001371  0.001967  0.004816  22.598280     10.004504   \n",
       "\n",
       "   sample_entropy_1  sample_entropy_2  shannon_entropy_1  shannon_entropy_2  \\\n",
       "0          3.782768          2.772589           4.504121           4.499598   \n",
       "1          1.916463          1.592631           4.640224           4.694019   \n",
       "2          2.211211          1.800493           5.167088           5.119668   \n",
       "3          2.984304          2.890372           4.640224           4.789015   \n",
       "4          2.332943          1.735189           6.079932           6.396046   \n",
       "\n",
       "   correlation  \n",
       "0     0.006479  \n",
       "1     0.117561  \n",
       "2     0.025986  \n",
       "3     0.038117  \n",
       "4     0.026922  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#组合全部特征\n",
    "train_data = pd.merge(features188_pd,features38_pd,on='id')\n",
    "train_data = pd.merge(train_data,features39_pd,on='id')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00002</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00003</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00004</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00005</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID label\n",
       "0  A00001     N\n",
       "1  A00002     N\n",
       "2  A00003     N\n",
       "3  A00004     A\n",
       "4  A00005     A"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取标签\n",
    "path = \"F:\\\\ECG\\\\ecg\\\\training2017\\\\\"\n",
    "target = pd.read_csv(os.path.join(path,\"REFERENCE-v3.csv\"),header=None,index_col=False)\n",
    "target.columns=[\"ID\",\"label\"]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>Features_SD_10</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044264</td>\n",
       "      <td>0.031529</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11.201408</td>\n",
       "      <td>0.781425</td>\n",
       "      <td>3.782768</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.504121</td>\n",
       "      <td>4.499598</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.325171</td>\n",
       "      <td>0.296396</td>\n",
       "      <td>0.298329</td>\n",
       "      <td>0.171309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>9.144809</td>\n",
       "      <td>2.459695</td>\n",
       "      <td>1.916463</td>\n",
       "      <td>1.592631</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.694019</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093895</td>\n",
       "      <td>0.088135</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>19.644293</td>\n",
       "      <td>2.044110</td>\n",
       "      <td>2.211211</td>\n",
       "      <td>1.800493</td>\n",
       "      <td>5.167088</td>\n",
       "      <td>5.119668</td>\n",
       "      <td>0.025986</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.195561</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>9.152490</td>\n",
       "      <td>3.104567</td>\n",
       "      <td>2.984304</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>4.640224</td>\n",
       "      <td>4.789015</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.503457</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>22.598280</td>\n",
       "      <td>10.004504</td>\n",
       "      <td>2.332943</td>\n",
       "      <td>1.735189</td>\n",
       "      <td>6.079932</td>\n",
       "      <td>6.396046</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  Features_SD_5  \\\n",
       "0          -11.0           11.0            0.0            0.0            0.0   \n",
       "1            9.0            7.0           16.0            0.0            0.0   \n",
       "2          -26.0           31.0            5.0            0.0            0.0   \n",
       "3           26.0            0.0           26.0            0.0            1.0   \n",
       "4           57.0           10.0           75.0            4.0            9.0   \n",
       "\n",
       "   Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  Features_SD_10  \\\n",
       "0            0.0       0.044264       0.031529       0.039185        0.013482   \n",
       "1            4.0       0.325171       0.296396       0.298329        0.171309   \n",
       "2            3.0       0.093895       0.088135       0.064279        0.056015   \n",
       "3            5.0       0.195561       0.251051       0.318723        0.107943   \n",
       "4           15.0       0.412665       0.503457       0.537868        0.263645   \n",
       "\n",
       "   ...    rr_var_1  rr_var_2     log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  ...    0.000022  0.000044  11.201408      0.781425          3.782768   \n",
       "1  ...    0.002392  0.008281   9.144809      2.459695          1.916463   \n",
       "2  ...    0.000197  0.000517  19.644293      2.044110          2.211211   \n",
       "3  ...    0.001939  0.005273   9.152490      3.104567          2.984304   \n",
       "4  ...    0.001967  0.004816  22.598280     10.004504          2.332943   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  label  \n",
       "0          2.772589           4.504121           4.499598     0.006479      N  \n",
       "1          1.592631           4.640224           4.694019     0.117561      N  \n",
       "2          1.800493           5.167088           5.119668     0.025986      N  \n",
       "3          2.890372           4.640224           4.789015     0.038117      A  \n",
       "4          1.735189           6.079932           6.396046     0.026922      A  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"] = np.array(target[\"label\"])#target[\"label\"]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24b088c9470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFXCAYAAAC/aQfJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4g7AADGEHcAAIwh7gAAGPO/pnyuEOJI8n8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(train_data[train_data['E'].notnull()].reset_index()[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Features_SD_1</th>\n",
       "      <th>Features_SD_2</th>\n",
       "      <th>Features_SD_3</th>\n",
       "      <th>Features_SD_4</th>\n",
       "      <th>Features_SD_5</th>\n",
       "      <th>Features_SD_6</th>\n",
       "      <th>Features_SD_7</th>\n",
       "      <th>Features_SD_8</th>\n",
       "      <th>Features_SD_9</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-11.00000000</td>\n",
       "      <td>11.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.04426400</td>\n",
       "      <td>0.03152900</td>\n",
       "      <td>0.03918500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00002230</td>\n",
       "      <td>0.00004430</td>\n",
       "      <td>11.20140801</td>\n",
       "      <td>0.78142460</td>\n",
       "      <td>3.78276817</td>\n",
       "      <td>2.77258872</td>\n",
       "      <td>4.50412060</td>\n",
       "      <td>4.49959762</td>\n",
       "      <td>0.00647882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.00000000</td>\n",
       "      <td>7.00000000</td>\n",
       "      <td>16.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>4.00000000</td>\n",
       "      <td>0.32517100</td>\n",
       "      <td>0.29639600</td>\n",
       "      <td>0.29832900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00239223</td>\n",
       "      <td>0.00828122</td>\n",
       "      <td>9.14480873</td>\n",
       "      <td>2.45969485</td>\n",
       "      <td>1.91646295</td>\n",
       "      <td>1.59263079</td>\n",
       "      <td>4.64022393</td>\n",
       "      <td>4.69401936</td>\n",
       "      <td>0.11756109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-26.00000000</td>\n",
       "      <td>31.00000000</td>\n",
       "      <td>5.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>3.00000000</td>\n",
       "      <td>0.09389500</td>\n",
       "      <td>0.08813500</td>\n",
       "      <td>0.06427900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00019736</td>\n",
       "      <td>0.00051699</td>\n",
       "      <td>19.64429350</td>\n",
       "      <td>2.04411026</td>\n",
       "      <td>2.21121082</td>\n",
       "      <td>1.80049315</td>\n",
       "      <td>5.16708805</td>\n",
       "      <td>5.11966798</td>\n",
       "      <td>0.02598626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>26.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>5.00000000</td>\n",
       "      <td>0.19556100</td>\n",
       "      <td>0.25105100</td>\n",
       "      <td>0.31872300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00193868</td>\n",
       "      <td>0.00527312</td>\n",
       "      <td>9.15248984</td>\n",
       "      <td>3.10456705</td>\n",
       "      <td>2.98430358</td>\n",
       "      <td>2.89037176</td>\n",
       "      <td>4.64022393</td>\n",
       "      <td>4.78901548</td>\n",
       "      <td>0.03811713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57.00000000</td>\n",
       "      <td>10.00000000</td>\n",
       "      <td>75.00000000</td>\n",
       "      <td>4.00000000</td>\n",
       "      <td>9.00000000</td>\n",
       "      <td>15.00000000</td>\n",
       "      <td>0.41266500</td>\n",
       "      <td>0.50345700</td>\n",
       "      <td>0.53786800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00196747</td>\n",
       "      <td>0.00481638</td>\n",
       "      <td>22.59828023</td>\n",
       "      <td>10.00450437</td>\n",
       "      <td>2.33294272</td>\n",
       "      <td>1.73518912</td>\n",
       "      <td>6.07993157</td>\n",
       "      <td>6.39604595</td>\n",
       "      <td>0.02692229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Features_SD_1  Features_SD_2  Features_SD_3  Features_SD_4  \\\n",
       "0      0   -11.00000000    11.00000000     0.00000000     0.00000000   \n",
       "1      1     9.00000000     7.00000000    16.00000000     0.00000000   \n",
       "2      2   -26.00000000    31.00000000     5.00000000     0.00000000   \n",
       "3      3    26.00000000     0.00000000    26.00000000     0.00000000   \n",
       "4      4    57.00000000    10.00000000    75.00000000     4.00000000   \n",
       "\n",
       "   Features_SD_5  Features_SD_6  Features_SD_7  Features_SD_8  Features_SD_9  \\\n",
       "0     0.00000000     0.00000000     0.04426400     0.03152900     0.03918500   \n",
       "1     0.00000000     4.00000000     0.32517100     0.29639600     0.29832900   \n",
       "2     0.00000000     3.00000000     0.09389500     0.08813500     0.06427900   \n",
       "3     1.00000000     5.00000000     0.19556100     0.25105100     0.31872300   \n",
       "4     9.00000000    15.00000000     0.41266500     0.50345700     0.53786800   \n",
       "\n",
       "   ...     rr_var_1   rr_var_2      log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  ...   0.00002230 0.00004430 11.20140801    0.78142460        3.78276817   \n",
       "1  ...   0.00239223 0.00828122  9.14480873    2.45969485        1.91646295   \n",
       "2  ...   0.00019736 0.00051699 19.64429350    2.04411026        2.21121082   \n",
       "3  ...   0.00193868 0.00527312  9.15248984    3.10456705        2.98430358   \n",
       "4  ...   0.00196747 0.00481638 22.59828023   10.00450437        2.33294272   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  label  \n",
       "0        2.77258872         4.50412060         4.49959762   0.00647882      0  \n",
       "1        1.59263079         4.64022393         4.69401936   0.11756109      0  \n",
       "2        1.80049315         5.16708805         5.11966798   0.02598626      0  \n",
       "3        2.89037176         4.64022393         4.78901548   0.03811713      1  \n",
       "4        1.73518912         6.07993157         6.39604595   0.02692229      1  \n",
       "\n",
       "[5 rows x 268 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_data[train_data['E'].notnull()].reset_index()\n",
    "\n",
    "train_labels = train_df['label']\n",
    "map_dict = {\"N\":0,\"A\":1,\"O\":2,\"~\":3}\n",
    "train_labels = train_labels.map(map_dict)\n",
    "train_df[\"label\"] = train_labels.values#target[\"label\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8528, 268)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name = ['sk_RR',\n",
    " 'Features_SD_55',\n",
    " 'features_temp_11',\n",
    " 'pf_RR_1',\n",
    " 'Features_SD_22',\n",
    " 'Features_SD_48',\n",
    " 'Features_embcsoa_8',\n",
    " 'qrs_malin2_max',\n",
    " 'Features_ADC_9',\n",
    " 'Features_SD_16',\n",
    " 'sample_entropy_2',\n",
    " 'n_plus_mean',\n",
    " 'RR_min',\n",
    " 'Features_SD_47',\n",
    " 'Features_SD_13',\n",
    " 'CV_deltaRR',\n",
    " 'Features_CP_15',\n",
    " 'sample_entropy_1',\n",
    " 'features_temp_2',\n",
    " 'AFEv',\n",
    " 'se',\n",
    " 'r_high_similarbeats',\n",
    " 'qrs_malin_max',\n",
    " 'v40_mean',\n",
    " 'Features_SD_64',\n",
    " 'Features_CP_18',\n",
    " 'rr_var_2',\n",
    " 'Features_ADC_6',\n",
    " 'features_temp_rs_13',\n",
    " 'qrs_malin_mean',\n",
    " 'features_temp_rs_15',\n",
    " 'Features_RB_6',\n",
    " 'lorenz_plot',\n",
    " 'qrs_malin2_mean',\n",
    " 'Features_SD_57',\n",
    " 'Features_SD_14',\n",
    " 'Features_CP_17',\n",
    " 'Features_RB_4',\n",
    " 'features_temp_rs_7',\n",
    " 'Features_SD_52',\n",
    " 'Features_CP_12',\n",
    " 'Features_SD_33',\n",
    " 'Features_ADC_2',\n",
    " 'Features_SD_44',\n",
    " 'features_temp_rs_2',\n",
    " 'Features_SD_1',\n",
    " 'Features_SD_58',\n",
    " 'features_temp_rs_8',\n",
    " 'features_temp_rs_17',\n",
    " 'Features_SD_41',\n",
    " 'Features_CP_4',\n",
    " 'R_amp_CV',\n",
    " 'Features_RB_11',\n",
    " 'Features_SD_37',\n",
    " 'Radius',\n",
    " 'Features_SD_46',\n",
    " 'Features_ADC_13',\n",
    " 'Features_CP_8',\n",
    " 'Features_CP_22',\n",
    " 'Features_SD_60',\n",
    " 'IrrEv',\n",
    " 'features_temp_12',\n",
    " 'Features_RB_10',\n",
    " 'kurt_RR',\n",
    " 'Features_SD_28',\n",
    " 'Features_SD_59',\n",
    " 'Features_CP_7',\n",
    " 'perdiogram_1',\n",
    " 'features_temp_rs_16',\n",
    " 'Features_SD_35',\n",
    " 'Features_SD_51',\n",
    " 'v40_2_mean',\n",
    " 'Features_CP_26',\n",
    " 'Features_ADC_10',\n",
    " 'Features_RB_13',\n",
    " 'Features_SD_45',\n",
    " 'Features_CP_25',\n",
    " 'COSEn',\n",
    " 'Features_SD_43',\n",
    " 'Features_RB_9',\n",
    " 'Features_SD_42',\n",
    " 'Features_SD_38',\n",
    " 'Features_RB_8',\n",
    " 'Features_ADC_3',\n",
    " 'n_plus2_mean',\n",
    " 'features_temp_rs_1',\n",
    " 'Features_SD_39',\n",
    " 'Features_RB_14',\n",
    " 'Features_CP_14',\n",
    " 'Features_CP_19',\n",
    " 'Features_CP_16',\n",
    " 'Features_SD_36',\n",
    " 'Features_RB_12',\n",
    " 'RR_max',\n",
    " 'Features_SD_56',\n",
    " 'Features_CP_20',\n",
    " 'Features_SD_62',\n",
    " 'features_temp_3',\n",
    " 'features_temp_rs_10',\n",
    " 'HR_median'][:30]\n",
    "\n",
    "len(feature_name)#43：0.8132 0.8232    48：0.8143 -0.8260  51 0.8088-0.8233\n",
    "#feature_name = feature39_name+feature38_name+feature_adc_name+feature_sd_name#feature188_name[:175]\n",
    "#feature_name = feature16_name\n",
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name = list(set(feature_name + feature16_name))\n",
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Radius',\n",
       " 'sample_entropy_2',\n",
       " 'Features_SD_13',\n",
       " 'IrrEv',\n",
       " 'HR_median',\n",
       " 'COMPLEXITY',\n",
       " 'RR_min',\n",
       " 'se',\n",
       " 'r_high_similarbeats',\n",
       " 'percentage_nn50',\n",
       " 'Features_SD_64',\n",
       " 'Features_SD_47',\n",
       " 'Features_ADC_9',\n",
       " 'COSEn',\n",
       " 'AFEv',\n",
       " 'CV',\n",
       " 'lorenz_plot',\n",
       " 'Features_ADC_6',\n",
       " 'CV_deltaRR',\n",
       " 'stepping',\n",
       " 'Features_ADC_10',\n",
       " 'Features_SD_48',\n",
       " 'rr_var_2',\n",
       " 'Features_SD_55',\n",
       " 'nn50',\n",
       " 'Features_CP_18',\n",
       " 'sk_RR',\n",
       " 'sample_entropy_1']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name =  list(set(feature_name)-{'n_plus_mean',\"qrs_malin2_max\",'features_temp_11','Features_embcsoa_8','pf_RR_1',\n",
    "                                        'res_kstest','Features_CP_15',\n",
    "                                        'v40_mean','features_temp_rs_13','qrs_malin_max','qrs_malin_mean','v40_mean',\n",
    "                                        'features_temp_2','Features_SD_16','Features_SD_14','Features_SD_22','OriginCount', 'MOBILITY'\n",
    "                                        }|\n",
    "                     {'lorenz_plot','Features_ADC_6','Features_ADC_10'})#,'rr_var_2' ,'Features_SD_14'\n",
    "                        #'Features_SD_44','Features_SD_33',\"log_rr_1_abs\" Features_ADC_11\n",
    "    #'Features_SD_42',\n",
    "    #'rr_var_2',\n",
    "    #'Features_SD_1',\n",
    "    #'Features_ADC_13',\n",
    "    #'Features_ADC_3',\n",
    "    #'Features_SD_58',\n",
    "    #'Features_SD_38',\n",
    "feature_name\n",
    "\n",
    "#len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name_pre=['Radius',\n",
    " 'sample_entropy_2',\n",
    " 'features_temp_2',\n",
    " 'sk_RR',\n",
    " 'Features_SD_22',\n",
    " 'IrrEv',\n",
    " 'Features_SD_13',\n",
    " 'HR_median',\n",
    " 'COMPLEXITY',\n",
    " 'se',\n",
    " 'r_high_similarbeats',\n",
    " 'percentage_nn50',\n",
    " 'OriginCount',\n",
    " 'Features_SD_14',\n",
    " 'Features_SD_47',\n",
    " 'Features_ADC_9',\n",
    " 'COSEn',\n",
    " 'AFEv',\n",
    " 'CV',\n",
    " 'Features_SD_16',\n",
    " 'CV_deltaRR',\n",
    " 'lorenz_plot',\n",
    " 'Features_ADC_6',\n",
    " 'stepping',\n",
    " 'Features_ADC_10',\n",
    " 'Features_SD_48',\n",
    " 'Features_SD_55',\n",
    " 'nn50',\n",
    " 'RR_min',\n",
    " 'MOBILITY',\n",
    " 'sample_entropy_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Features_CP_18', 'Features_SD_64', 'rr_var_2'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(feature_name)-set(feature_name_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params2={\n",
    " 'learning_rate' : 0.01,\n",
    " 'n_estimators':819,\n",
    " 'max_depth':8,\n",
    " 'num_leaves':115,\n",
    " 'min_child_weight':0,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'min_child_samples':21,\n",
    " 'objective':'multiclass',\n",
    " 'reg_alpha':0.15,\n",
    " 'reg_lambda' : 0.01,\n",
    " 'num_class': 4,\n",
    " 'n_jobs':4,\n",
    " #class_weight =\"1\",\n",
    " 'random_state' :27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8528, 28)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[feature_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>Features_SD_13</th>\n",
       "      <th>IrrEv</th>\n",
       "      <th>HR_median</th>\n",
       "      <th>COMPLEXITY</th>\n",
       "      <th>RR_min</th>\n",
       "      <th>se</th>\n",
       "      <th>r_high_similarbeats</th>\n",
       "      <th>percentage_nn50</th>\n",
       "      <th>...</th>\n",
       "      <th>CV_deltaRR</th>\n",
       "      <th>stepping</th>\n",
       "      <th>Features_ADC_10</th>\n",
       "      <th>Features_SD_48</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>Features_SD_55</th>\n",
       "      <th>nn50</th>\n",
       "      <th>Features_CP_18</th>\n",
       "      <th>sk_RR</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "      <td>8528.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.07543856</td>\n",
       "      <td>1.66509864</td>\n",
       "      <td>0.83850122</td>\n",
       "      <td>5.65114916</td>\n",
       "      <td>72.93042800</td>\n",
       "      <td>7.06634029</td>\n",
       "      <td>0.69828330</td>\n",
       "      <td>2.53388954</td>\n",
       "      <td>0.89878401</td>\n",
       "      <td>0.73297608</td>\n",
       "      <td>...</td>\n",
       "      <td>28271612998510.56250000</td>\n",
       "      <td>0.10586069</td>\n",
       "      <td>297.93515478</td>\n",
       "      <td>0.36728078</td>\n",
       "      <td>0.00350397</td>\n",
       "      <td>0.29058893</td>\n",
       "      <td>26.05393996</td>\n",
       "      <td>0.53676441</td>\n",
       "      <td>-0.07349672</td>\n",
       "      <td>2.39622770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.15229096</td>\n",
       "      <td>0.94230839</td>\n",
       "      <td>0.19624256</td>\n",
       "      <td>10.96315764</td>\n",
       "      <td>21.38764428</td>\n",
       "      <td>2.32543838</td>\n",
       "      <td>0.22092895</td>\n",
       "      <td>0.74464064</td>\n",
       "      <td>0.17168202</td>\n",
       "      <td>0.28984632</td>\n",
       "      <td>...</td>\n",
       "      <td>3982293868470710.00000000</td>\n",
       "      <td>0.14878298</td>\n",
       "      <td>274.55739645</td>\n",
       "      <td>0.22286919</td>\n",
       "      <td>0.00957162</td>\n",
       "      <td>1.18965139</td>\n",
       "      <td>17.28131871</td>\n",
       "      <td>0.14557858</td>\n",
       "      <td>1.17191924</td>\n",
       "      <td>0.70399734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-169097428538972992.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-36.72056300</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-8.76000000</td>\n",
       "      <td>0.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.01000000</td>\n",
       "      <td>1.00318793</td>\n",
       "      <td>0.72500000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>62.07000000</td>\n",
       "      <td>5.69750000</td>\n",
       "      <td>0.56000000</td>\n",
       "      <td>2.32000000</td>\n",
       "      <td>0.91000000</td>\n",
       "      <td>0.58000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.23250000</td>\n",
       "      <td>0.02000000</td>\n",
       "      <td>233.00000000</td>\n",
       "      <td>0.22974775</td>\n",
       "      <td>0.00003900</td>\n",
       "      <td>0.16688725</td>\n",
       "      <td>14.00000000</td>\n",
       "      <td>0.44117600</td>\n",
       "      <td>-0.49000000</td>\n",
       "      <td>1.94741278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.03000000</td>\n",
       "      <td>1.73460105</td>\n",
       "      <td>0.83666700</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>70.87000000</td>\n",
       "      <td>7.29000000</td>\n",
       "      <td>0.72000000</td>\n",
       "      <td>2.82000000</td>\n",
       "      <td>0.96000000</td>\n",
       "      <td>0.87000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.22000000</td>\n",
       "      <td>0.04000000</td>\n",
       "      <td>267.00000000</td>\n",
       "      <td>0.32917800</td>\n",
       "      <td>0.00039367</td>\n",
       "      <td>0.24070600</td>\n",
       "      <td>25.00000000</td>\n",
       "      <td>0.54166700</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>2.51354221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.05000000</td>\n",
       "      <td>2.35137526</td>\n",
       "      <td>0.95000000</td>\n",
       "      <td>6.00000000</td>\n",
       "      <td>81.45000000</td>\n",
       "      <td>8.41000000</td>\n",
       "      <td>0.84000000</td>\n",
       "      <td>3.03000000</td>\n",
       "      <td>0.97000000</td>\n",
       "      <td>0.96000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.08250000</td>\n",
       "      <td>0.11000000</td>\n",
       "      <td>308.00000000</td>\n",
       "      <td>0.46029300</td>\n",
       "      <td>0.00327432</td>\n",
       "      <td>0.32346675</td>\n",
       "      <td>34.00000000</td>\n",
       "      <td>0.63636400</td>\n",
       "      <td>0.43000000</td>\n",
       "      <td>2.88776306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.76000000</td>\n",
       "      <td>4.61512052</td>\n",
       "      <td>4.29000000</td>\n",
       "      <td>108.00000000</td>\n",
       "      <td>204.55000000</td>\n",
       "      <td>17.26000000</td>\n",
       "      <td>1.77000000</td>\n",
       "      <td>3.29000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.99000000</td>\n",
       "      <td>...</td>\n",
       "      <td>257330024218593088.00000000</td>\n",
       "      <td>1.15000000</td>\n",
       "      <td>17241.00000000</td>\n",
       "      <td>4.73705000</td>\n",
       "      <td>0.27260395</td>\n",
       "      <td>98.25690400</td>\n",
       "      <td>167.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>8.55000000</td>\n",
       "      <td>5.03043792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Radius  sample_entropy_2  Features_SD_13         IrrEv  \\\n",
       "count 8528.00000000     8528.00000000   8528.00000000 8528.00000000   \n",
       "mean     0.07543856        1.66509864      0.83850122    5.65114916   \n",
       "std      0.15229096        0.94230839      0.19624256   10.96315764   \n",
       "min      0.00000000        0.00000000      0.00000000    0.00000000   \n",
       "25%      0.01000000        1.00318793      0.72500000    0.00000000   \n",
       "50%      0.03000000        1.73460105      0.83666700    1.00000000   \n",
       "75%      0.05000000        2.35137526      0.95000000    6.00000000   \n",
       "max      1.76000000        4.61512052      4.29000000  108.00000000   \n",
       "\n",
       "          HR_median    COMPLEXITY        RR_min            se  \\\n",
       "count 8528.00000000 8528.00000000 8528.00000000 8528.00000000   \n",
       "mean    72.93042800    7.06634029    0.69828330    2.53388954   \n",
       "std     21.38764428    2.32543838    0.22092895    0.74464064   \n",
       "min      0.00000000    0.00000000    0.00000000    0.00000000   \n",
       "25%     62.07000000    5.69750000    0.56000000    2.32000000   \n",
       "50%     70.87000000    7.29000000    0.72000000    2.82000000   \n",
       "75%     81.45000000    8.41000000    0.84000000    3.03000000   \n",
       "max    204.55000000   17.26000000    1.77000000    3.29000000   \n",
       "\n",
       "       r_high_similarbeats  percentage_nn50        ...         \\\n",
       "count        8528.00000000    8528.00000000        ...          \n",
       "mean            0.89878401       0.73297608        ...          \n",
       "std             0.17168202       0.28984632        ...          \n",
       "min             0.00000000       0.00000000        ...          \n",
       "25%             0.91000000       0.58000000        ...          \n",
       "50%             0.96000000       0.87000000        ...          \n",
       "75%             0.97000000       0.96000000        ...          \n",
       "max             1.00000000       0.99000000        ...          \n",
       "\n",
       "                        CV_deltaRR      stepping  Features_ADC_10  \\\n",
       "count                8528.00000000 8528.00000000    8528.00000000   \n",
       "mean       28271612998510.56250000    0.10586069     297.93515478   \n",
       "std      3982293868470710.00000000    0.14878298     274.55739645   \n",
       "min   -169097428538972992.00000000    0.00000000       0.00000000   \n",
       "25%                   -22.23250000    0.02000000     233.00000000   \n",
       "50%                     4.22000000    0.04000000     267.00000000   \n",
       "75%                    25.08250000    0.11000000     308.00000000   \n",
       "max    257330024218593088.00000000    1.15000000   17241.00000000   \n",
       "\n",
       "       Features_SD_48      rr_var_2  Features_SD_55          nn50  \\\n",
       "count   8528.00000000 8528.00000000   8528.00000000 8528.00000000   \n",
       "mean       0.36728078    0.00350397      0.29058893   26.05393996   \n",
       "std        0.22286919    0.00957162      1.18965139   17.28131871   \n",
       "min        0.00000000    0.00000000    -36.72056300    0.00000000   \n",
       "25%        0.22974775    0.00003900      0.16688725   14.00000000   \n",
       "50%        0.32917800    0.00039367      0.24070600   25.00000000   \n",
       "75%        0.46029300    0.00327432      0.32346675   34.00000000   \n",
       "max        4.73705000    0.27260395     98.25690400  167.00000000   \n",
       "\n",
       "       Features_CP_18         sk_RR  sample_entropy_1  \n",
       "count   8528.00000000 8528.00000000     8528.00000000  \n",
       "mean       0.53676441   -0.07349672        2.39622770  \n",
       "std        0.14557858    1.17191924        0.70399734  \n",
       "min        0.00000000   -8.76000000        0.00000000  \n",
       "25%        0.44117600   -0.49000000        1.94741278  \n",
       "50%        0.54166700    0.00000000        2.51354221  \n",
       "75%        0.63636400    0.43000000        2.88776306  \n",
       "max        1.00000000    8.55000000        5.03043792  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[feature_name].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.526412\n",
      "[400]\tvalid_0's multi_logloss: 0.427695\n",
      "[600]\tvalid_0's multi_logloss: 0.411534\n",
      "[800]\tvalid_0's multi_logloss: 0.409086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[808]\tvalid_0's multi_logloss: 0.408923\n",
      "fold:  1  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.549536\n",
      "[400]\tvalid_0's multi_logloss: 0.457654\n",
      "[600]\tvalid_0's multi_logloss: 0.442122\n",
      "[800]\tvalid_0's multi_logloss: 0.444507\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[603]\tvalid_0's multi_logloss: 0.442046\n",
      "fold:  2  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.56103\n",
      "[400]\tvalid_0's multi_logloss: 0.469564\n",
      "[600]\tvalid_0's multi_logloss: 0.454669\n",
      "[800]\tvalid_0's multi_logloss: 0.455526\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[664]\tvalid_0's multi_logloss: 0.453873\n",
      "fold:  3  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.559013\n",
      "[400]\tvalid_0's multi_logloss: 0.466545\n",
      "[600]\tvalid_0's multi_logloss: 0.450786\n",
      "[800]\tvalid_0's multi_logloss: 0.450743\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[703]\tvalid_0's multi_logloss: 0.450215\n",
      "fold:  4  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.544807\n",
      "[400]\tvalid_0's multi_logloss: 0.448455\n",
      "[600]\tvalid_0's multi_logloss: 0.431514\n",
      "[800]\tvalid_0's multi_logloss: 0.430282\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[765]\tvalid_0's multi_logloss: 0.430062\n",
      "fold:  5  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.518287\n",
      "[400]\tvalid_0's multi_logloss: 0.418268\n",
      "[600]\tvalid_0's multi_logloss: 0.405752\n",
      "[800]\tvalid_0's multi_logloss: 0.406685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[724]\tvalid_0's multi_logloss: 0.405161\n",
      "fold:  6  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.557113\n",
      "[400]\tvalid_0's multi_logloss: 0.460004\n",
      "[600]\tvalid_0's multi_logloss: 0.447891\n",
      "[800]\tvalid_0's multi_logloss: 0.450337\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[607]\tvalid_0's multi_logloss: 0.447799\n",
      "fold:  7  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.549455\n",
      "[400]\tvalid_0's multi_logloss: 0.458119\n",
      "[600]\tvalid_0's multi_logloss: 0.443084\n",
      "[800]\tvalid_0's multi_logloss: 0.444387\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[673]\tvalid_0's multi_logloss: 0.442237\n",
      "fold:  8  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.538292\n",
      "[400]\tvalid_0's multi_logloss: 0.446075\n",
      "[600]\tvalid_0's multi_logloss: 0.432441\n",
      "[800]\tvalid_0's multi_logloss: 0.433128\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[669]\tvalid_0's multi_logloss: 0.431676\n",
      "fold:  9  training\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[200]\tvalid_0's multi_logloss: 0.543578\n",
      "[400]\tvalid_0's multi_logloss: 0.445183\n",
      "[600]\tvalid_0's multi_logloss: 0.430435\n",
      "[800]\tvalid_0's multi_logloss: 0.430202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[669]\tvalid_0's multi_logloss: 0.429613\n",
      "fold f1 score is 0.7610074609830823\n",
      "F1 measure for Normal rhythm: 0.8996\n",
      "F1 measure for AF rhythm: 0.8158\n",
      "F1 measure for Other rhythm: 0.7326\n",
      "F1 measure for Noisy recordings: 0.5960\n",
      "Final F1 measure: 0.8160\n"
     ]
    }
   ],
   "source": [
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 10\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data_df = train_df[feature_name].astype('float64') #feature_name  columns\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data_df\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_data_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \\\n",
    "        train_label[train_fold], train_label[validate]\n",
    "        #print(X_validate)\n",
    "        #break\n",
    "        dtrain = lgb.Dataset(X_train, label_train)\n",
    "        dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        bst = lgb.train(lgb_params2, dtrain, num_boost_round=819, valid_sets=dvalid, verbose_eval=200,early_stopping_rounds=500)\n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "        oof[validate] = np.argmax(k_pred,axis=1)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = count + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "oof = list(map(int, oof))\n",
    "fold_f1_error = f1_score(train_labels.values, oof, average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_labels.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.save_model(\"lightgbm_05141_temp.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "def display_confusion_matrix(y_pred,y_true):\n",
    "    # Creates a confusion matrix\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "    # Transform to df for easier plotting\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = ['N','A','O','~'], \n",
    "                         columns = ['N','A','O','~'])\n",
    "\n",
    "    plt.figure(figsize=(16,10))\n",
    "    sns.heatmap(cm_df, annot=True,annot_kws={'size':25,'weight':'bold', 'color':'r'},fmt=\"d\")#,cmap=\"RdBu\"\n",
    "    plt.title('Xgboost \\nAccuracy:{0:.3f}'.format(accuracy_score(y_pred,y_true)))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAALICAYAAAApGmi2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XmYFOW1x/FfVXX37AMMO7gbIS4R\nouCKIOAuqFdcwDVGzaIGNS4IXjTEGOKaazQaNUYNuCGiqLghcUFRVEQR4oooyg7DMmsvVe/9Y5qe\nrmEKCmXogfl+nmcep7rq7Xp7HsqqOn3OKcsYYwQAAAAAALAJdq4nAAAAAAAAtg0EEQAAAAAAQCgE\nEQAAAAAAQCgEEQAAAAAAQCgEEQAAAAAAQCgEEQAAAAAAQCgEEQAAyDJv3jztv//++uSTTzKvlZeX\n64gjjtDrr7++0bHXXHONHnjggSaeofT666/rjjvuaPL9AAAANEQQAQCALHvvvbeuuuoqXXrppVq7\ndq1SqZQuu+wyDRkyRIcffniupydJ+uSTT7R27dpcTwMAALRAkVxPAACA5mbo0KGaNWuWRo0apZ12\n2kmlpaX6zW9+k1l/3333aeLEiSoqKlKvXr00bdo0/ec//5EkzZo1Sy+//LIqKyt16KGHasSIEYpE\nIvrggw908803q6amRtFoVJdddpn69u0rSfr73/+uKVOmyHEc7brrrho9erTat2+vV155Rffcc48s\ny5LjOLr66qsVi8X0+OOPy3VdlZSU6PLLL8/J3wgAALRMBBEAAGjEmDFjdNJJJ+nTTz/Vc889J8uy\nJEnTp0/XpEmTNHHiRJWUlOjaa6/1jVu6dKnGjx+vSCSi888/XxMmTNCxxx6r4cOH65577lGPHj30\n5Zdf6qyzztLEiRP13nvvafr06Zo4caIKCwt15513Zsoibr75Zt16663q2bOn3nrrLc2cOVOXXHKJ\nhg4dqtWrVxNAAAAAWx3lDAAANGLBggWqqqrSunXrNG/evMzrb7zxho455hiVlpbKsiydeeaZvnEn\nnniiCgsLFYvFdMIJJ2jGjBmaM2eOdtppJ/Xo0UOStMcee2i//fbTe++9pzfffFMnn3yyCgsLJUnn\nnHOO3n33XSUSCR1//PG65JJLdO2112rdunW68MILt94fAAAAoBEEEQAAaKC8vFy/+93vNHLkSI0c\nOVK///3vtWLFCklSJBKRMSazreM4vrHZy8YYRSIRua6byWTIXpdKpeR5nm+d53lKpVKSpMsvv1yP\nPvqo9tlnH02aNGmDgAUAAMDWRhABAIAsruvq8ssvV//+/TVo0CANGTJEhx12mC6//HK5rqt+/frp\nlVdeUUVFhSRp4sSJvvFTpkxRIpFQPB7X008/rb59+6pnz576+uuvNWfOHEnSl19+qffff18HHHCA\nDjvsMD311FOqrq6WJI0bN069e/eWbdsaMGCAampqNGzYMF1//fX6/PPPlUgk5DhOJtAAAACwNVkm\n++sUAABauLFjx2r27NkaP368YrGYJKmmpkannXaa+vbtq6uuukoPPvignnzySeXn52uPPfbQ3Llz\nNWXKFF1zzTVyXTdTCnHkkUfq8ssvl2VZevfdd3XbbbeptrZWlmXpkksu0VFHHSXP83TnnXfqlVde\nked52nnnnfWHP/xBnTp10quvvqo77rhDkUhElmXpvPPO0+DBg/Xhhx/qyiuvVP/+/TV69Ogc/8UA\nAEBLQhABAIDN8Mknn2j27Nk655xzJEkPPvigPv74Y/3f//1fjmcGAADQ9AgiAACwGSorKzVq1Ch9\n/fXXsixLnTt31g033KCOHTvmemoAAABNjiACAAAAAAAIhcaKAAAAAAAgFIIIAIDtTjKZVJ8+fXTB\nBRfkeio/2r333qtjjjlGRx55pO68804FJRDeeeedOvbYYzVo0CCNGDFC8Xjct37t2rUaOHCgXnrp\npQ3G3nHHHfrjH//YJPMHAADbF4IIAIDtztSpU/XTn/5Uc+fO1fz583M9nR/sjTfe0IsvvqhJkybp\n+eef18yZM/Xiiy9usN3MmTM1ZcoUPf3003ruuedUWVmpcePGZdYbYzRixAhVVlb6xi1dulTDhw/X\ngw8+2OSfBQAAbB8IIgAAtjuPPfaYBg4cqOOOO04PP/xw5vWJEyfq+OOP1+DBg3XOOedoyZIlga/P\nnDlTgwYNyozNXr7zzjt1/vnna/Dgwbryyiu1cuVKXXTRRTr99NM1YMAAnX322Vq1apUkacGCBTr7\n7LMz7//CCy9o1qxZOvzww+V5nqS6R0gefPDBKi8v12OPPaZrr71WUl0wZNCgQSosLFReXp5OPvlk\nPfvssxt8Xs/zlEgkVFtbq2QyqXg8rry8vMz6u+++W927d1e3bt184yZOnKgDDjhA55133pb4swMA\ngBaAIAIAYLvy1Vdfafbs2TrmmGN00kknafLkyVq9erU+++wz3XrrrfrnP/+p5557TgMGDNA999wT\n+PqmLFq0SE8//bRuvfVWTZkyRT179tQTTzyhadOmKT8/X5MnT5Yk/f73v9cxxxyjKVOm6L777tPt\nt9+u7t27q1WrVpo+fbokacqUKTr44INVVlamYcOG6cYbb5QkLVmyRJ07d87ss1OnTlq2bNkGczn4\n4IN1yCGHqH///urTp48qKip0+umnS5Lefvttvf/++xo+fPgG4y655BKdddZZsm0uBwAAQDiRXE8A\nAIAt6bHHHlP//v3Vpk0btWnTRjvssIMmTJigWCymPn36ZG7Kf/GLX0iSHnzwwUZfnzlz5kb307Nn\nT0UidafRc889Vx988IEefPBBffPNN/ryyy/Vo0cPrVmzRp999plOPfVUSVLnzp316quvSpLOPPNM\nTZgwQf369dMTTzyhq6++eoN9GGNkWZZvubEb/okTJ+r777/X9OnTFYvFNHLkSN100006//zz9Ze/\n/EX/+te/5DjOZvwVAQAAGkcQAQCw3aiurtbkyZMVi8U0YMAASVJlZaXGjx+vCy64wHdDXltbq0WL\nFslxnEZftyzL18QwmUz69lVYWJj5/ZZbbtGcOXM0ZMgQHXjggUqlUjLGZIIM2e//9ddfq0uXLho8\neLBuv/12vfvuu6qurlbv3r03+DydO3fW8uXLM8vLly9Xp06dNthu6tSpGjx4sIqLiyVJp512mm64\n4QZ17dpVNTU1mQaTCxcu1M0336zVq1dr2LBhIf6iAAAAfuQvAgC2G88995xat26t6dOn6z//+Y/+\n85//6NVXX1V1dbUqKir0zjvvZG7KH3/8cd1yyy068MADG329rKxMixcv1qpVq2SM0ZQpUwL3+9Zb\nb+ncc8/VSSedpLZt22rGjBlyXVfFxcXae++99cwzz0iqK08YNmyYKioqVFBQoBNOOEGjRo3S0KFD\nG33fgQMH6tlnn1V1dbUSiYQmTZqkI444YoPt9tprL02dOjUTvJg6dap69OihX/7yl3r11Vc1efJk\nTZ48Wfvss4+uvvpqAggAAOAHIxMBALDdeOyxx3Teeef5UvdLS0t19tln67XXXtNVV12V+Va+ffv2\n+vOf/6yOHTsGvj506FANGTJE7du31+GHH65PPvmk0f1efPHFuvnmm3XHHXcoGo1qv/3208KFCyVJ\nt912m8aMGaNx48bJsizdeOONat++vSTp5JNP1oQJE3TSSSf5PsPcuXN14403asCAAfriiy906qmn\nKplMauDAgZlts7f7zW9+o7Fjx+r4449XLBZT9+7ddf3112/5PzAAAGjxLBP0wGkAANBkjDG6//77\ntWjRIo0ZMybX0wEAAAiFTAQAAHJg4MCB6tChg+6+++5cTwUAACA0MhEAAAAAAEAoNFYEAAAAAACh\nEEQAAAAAAAChNMueCMmVX+d6CkCLUdDlsFxPAWgx2hWW5noKQIuxsnpdrqcAtCipxKJcT6HJ5Pr+\nNNput5zuvyEyEQAAAAAAQCgEEQAAAAAAQCjNspwBAAAAAIBmwXNzPYNmhUwEAAAAAAAQCkEEAAAA\nAAAQCuUMAAAAAAAEMV6uZ9CskIkAAAAAAABCIRMBAAAAAIAgHpkI2chEAAAAAAAAoRBEAAAAAAAA\noVDOAAAAAABAAENjRR8yEQAAAAAAQChkIgAAAAAAEITGij5kIgAAAAAAgFAIIgAAAAAAgFAoZwAA\nAAAAIAiNFX3IRAAAAAAAAKGQiQAAAAAAQBDPzfUMmhUyEQAAAAAAQCgEEQAAAAAAQCiUMwAAAAAA\nEITGij5kIgAAAAAAgFDIRAAAAAAAIIhHJkI2MhEAAAAAAEAoBBEAAAAAAEAolDMAAAAAABDA0FjR\nh0wEAAAAAAAQCpkIAAAAAAAEobGiD5kIAAAAAAAgFIIIAAAAAAAgFMoZAAAAAAAIQmNFHzIRAAAA\nAABAKGQiAAAAAAAQxHNzPYNmhUwEAAAAAAAQCkEEAAAAAAAQCuUMAAAAAAAEobGiD5kIAAAAAAAg\nFDIRAAAAAAAI4pGJkI1MBAAAAAAAEApBBAAAAAAAEArlDAAAAAAABKGxog+ZCAAAAAAAIBQyEQAA\nAAAACEJjRR8yEQAAAAAAQCgEEQAAAAAAQCiUMwAAAAAAEMAYN9dTaFbIRAAAAAAAAKGQiQAAAAAA\nQBAe8ehDJgIAAAAAAAiFIAIAAAAAAAiFcgYAAAAAAIJ4lDNkIxMBAAAAAACEQiYCAAAAAABBaKzo\nQyYCAAAAAAAIhSACAAAAAAAIhXIGAAAAAACCeG6uZ9CskIkAAAAAAABCIRMBAAAAAIAgNFb0IRMB\nAAAAAACEQhABAAAAAACEQjkDAAAAAABBPMoZspGJAAAAAAAAQiETAQAAAACAIDRW9CETAQAAAAAA\nhEIQAQAAAAAAhEI5AwAAAAAAQWis6EMmAgAAAAAACIVMBAAAAAAAgpCJ4EMmAgAAAAAACIVMhJZs\n/gJFDj9eVm1ckpSc9Ya00w6SpGj73UO/jXfIgXInP+p7zZo9R/Y/H5Y14z1p+UopFpPZfReZ44+W\nd+G5UnFRo+9lPTNF9r8fkzVnnhSPSzt0lXfskfJ+9yupTesf+EGBbUc3k9Jwr1IDvbh2kCtXlhbI\n0Qt2vv5qF2ml5Wwwpr1xNdKr1PFerbrKVYVsvWtFdZtdrLfsvBx8CqB52dFL6DfxcvVPVamzl1JC\nlv7r5OnxWCtNiLaSsawNxhQZVxfHyzUoWaEdvaRqLUtz7Xz9M6+NXo6WBO6rnZfSpfFVOjJVqU5e\nSlWWrQ+cAt2dV6aZkcKm/JhAsxb2/LazSWl+anno933YKtD5kTZNNW0AjbCMMSbXk2goufLrXE9h\n+2eMnBPPkP3Oe5mXtlQQwf7r3bL/8ldZAWk/ZvddlZo0TurSuf5F15Vz0RWyJz3X+JgO7ZV68mFp\nr+6h54VwCrocluspIO0sr1r3umsUdNu/RLaOi7TVJ1Y089oeJqVpqZXqog2PN0/ScLuV/uE0HrTD\n1teusDTXU2hxBiQr9c/qRSpU45c7L0WKdUFhV6WyAgntvJQmVS1UNy/R6Ji7YmX6U0GHDV7fzU1o\nUtVCdTKpDdZ5kkbld9RDedzsbC0rq9flegpI25zzG0GEbVcqsSjXU2gyNW8+lNP9F/T9RU733xCZ\nCC2U/e/HfAGEhrxDDgxcZ62rkDX3v5llc+yR9eumvSHnz7fVryvIl+n2E1lLl8taVndCsOYvkHPB\n7+ROeVJKX7TZt/zNF0AwXTtL+fmy5i+oG7N8hSKnn6fU2y9LpcHfAAHbqn1MUve7a7Q+PJCQNE8R\ntZbRrnIlSZ3laVKqXPtEOihuWZIxetBdnQkguJJmW1HtZlIqk5Et6a/eWk23Y5qXFXgAWopWxtU9\n1YszAYS4LH1mx7SDSamtqTuujklV6ur4Cv05vz4o8OfaZb4Awlw7T+1NSh3TYy5JlOvtSKFeixbX\n78wY/a1mcSaA4Eqa6+RrJy+hNsaTLemG2mV6N1KozxwyhNBybO75rVaW3rBige/XwXjaU3XHmSfp\nOTu/aT8AgA3QE6ElWrpM9h9v3ugm7uRHA3/Mnt0y23knD5b3m/Myy/Zd92V+N106KTVjqtxXJyv1\n8Vtyzxlav937s2W9837dwpq1su95oH7fvzhDqdnTlXr3VaXurJ+ntXSZ7Dvv/cEfG2jOLnUrMxdY\nFbJ0QKS9ekc7aI9oR11n1wfOdpWrU02NJOkoE9dBJplZd4JTpoMi7dUt0lFfqS4tNCpppFu5tT4G\n0KwMTaxVq3SQbZ1sHVW8i44u2VW9SnbXe05BZrvz4msUSSdm/sSN64RkRWbd1fkddUTJrupdsrve\nzxpzRXylb1+Hp6rUy63NLJ9VuIOOLt5FB5XsrgV23dEdlXRpg3HA9m5zz2/LLEcDI+0a/3HaaoVV\nf/tys12sZ+wCAU3O83L708wQRGiBnGv+IGtdxaY3bIT1nzdlP/mMJMl07CD35j/Wr4zHZb37QWbR\nO+8saYcu6Z068q78nf+9Zn9c99/p78iqrqkfN+qKTIaCGTpE3hGHZ9bZEyf/oHkDzd0RJp75/TG7\nQHOzMgf+YherJmvb3qbuG9JTvPoblvetqF5OfxuzxrL1d7u+hGGQqVVe86tcA5qckTTbyVeVLD0a\na6XP0xkANZatyVl9DUrkqV06g2BwVgBhmeVoXKyuH0/CsnVXXllmXS+3Vl28rCBe1rjZTn4mS2Gt\n5eiBWH2q9VHJSuWZ5ndBCDSVH3J+C3KhV62+6W0+VkR/sMlOBXKBcoYWxnruJdlTXpEkmdatZK1Z\nG35wVbWcq0ZnFt0xI6VWWfW9rif31j/JWrpMWrpM5uDe/vGFDRpKJeouvqxvF2ZeMm3LNmigaA7q\nLb36et223y+Wvl9cH5wAthOjnVJ1Na46y9O0BmmcnmWpVpYK0inZsXQ8oFfWxdbMBmNmZC0Xy2hP\npfSRKGlAy3JfXpnuyyuTjFFeg54Iu2QFAGpkaYVVd0nUMyub4GMn39d0MTsTQZJ6uLVanM4yyB73\noeNPr84eVySjPbyE5jqkYKNl+CHnt8Z0Nq7GevV9Ln7ntPL1MgGw9RBEaEnWrpMzcowkycRi8kZd\nIefq60IPt//xgKyF30uSvB77yJw82L9BYYHMmacGtK6SrDdn+JbNznVNHOVmfSOTTGoDDZ7kYH36\nuQxBBGxnxtvBXdv3Mwm1yTqyvrEcWcaou+qbty1pkFj2fYOnOPzUJPURfRHQUlmW4qq72WjnpXRi\ncp1+kVidWf1QrI3c9M3IHl79t6ZLbf8xU25HVCtL+enjcQ83rhejJbKM0e5ZPRSWNjjWFjd4nz3c\nOEEEtBibe34LMsatUOv0tk9Z+ZrB04ewNZFB5kMQoQVx/jA209zQG/5rmW7hn8CgREL2A+Mzi97w\n32RKDkKprJQz9vbMoonFZPoeWvd71/qnNFjrKqTvFkk7dq0f+9kX/vcqXy2gpXCM0S2uv8P4i3a+\nSmR8Xa7XNggiVMp/fLbl5AfoyGSFxlX7u4dPjJbqT/ntM8tlnpv5vaKRqs8qy1Z+usFiWfq/xfJ8\nmQ4Vlr3BmGzrxwEtWdD5rTHtjaszTHVm+Wa7uNHtAGwd9ERoIay335X1yJOS6h6x6F32280b/9Sz\nslbUNYMyu+wkM+jo8INrauWc/WtZX87PvOSdeZrUrm3d+/U5WCZSH89yRt8oxeu+CbJmz5H9xCT/\nXKqqBbQEljF60F2jflllCy9YeZpjRVXUIOcn2SCml2wQRCgOzBECWo6dPH+227dWVJOipZksBEkq\nzHpcarKRYHn2wxvXP/WhsEGQruG4hg98LKRHCVq4jZ3fGvNbr0rrwwuvWTHNsoOf3gA0CRor+jRJ\nJsIzzzwTuO6kk05qil1iY2rjcn5/raz0RYt725+kvM1LAXPuezjzu3f+2ZIdMv5UVS3n7F/Jfuvd\nzEuma2d5/3tl/TadOsg76zQ5Dz0qSbKnvCyrZx+pUyfpsy9kpRpcfjnEvrD9s9MXWGeY+pZTa2Xp\nEqeVJGlTeUDcogAbamtcfeTkq9S42s1LameT1KPV32t8tJWuLOgkWVaIY2vDLX7IGKCl2tT5raGY\nMfqVV/8F0l12UaPbAdh6miSIMH/+fN+yMUaTJk1Sfn4+QYQcsG++Q9bX30iSvDNOlTn0oM17g4/n\nypr738yid3zILISKCjnDLpA9s/6JDaa4WKmH/yGV+rvpemNGyfpyvuy3Z0qSrJXl0sryujF7dZf1\n38997wFszyLG6BF3tYaY+kZtCUlnOm20MN38rarBTUm0QdQg2iCM0LC8AWiJbs5vr5tVV7pwbny1\nbqpdJkk6K7lWMyKFmhRrpWrZmcdCRhvJGMg+tqrTx1V1g3KFhuMaHo/VNINDCxXm/NbQcaZWndLH\nZJUsvWzRTwTItSYJIlxxxRWZ37/99ltdc801OvzwwzVq1Kim2B02Zu6nsu95QJJk2pXJ/cM1m/0W\n9guvZH43P9vb368gSEWFnFPOlf3hx/VjS4rlPv4vqcc+G25fWCB3wkMy//y37EcnSt98K5WVyTvl\nRJmjBigy+PT6bTu233A8sJ2IGKMn3XINznokVlzSGU4bvZRVK1ohS0kp87yFEvlT3Uob3LSsssjg\nAbI9nNdGZyXW6GfpRoqnJNdpUqyV1liOWqXLE4q1YQppcVbpQnm6CVylbN/x2HBccYNyh/KNNI8D\ntldhz28NnZT1OONXrDzVEoRDLtBbyqdJGys+8sgjevjhhzVy5Ej179+/KXeFAPaLUzPlANbKckW7\n7R+4bXT/fpKk1N9ukhl2SuZ16423M797Rx6+6Z3WxuWccaE/gFDWRqkJD0o9fhY8LhaTd9EF8i66\nwPeyNXGyb9ns2X3TcwC2RcboYXe17wKrWpZOa+QCy7MsfS1H3VXXoK1zg5uWrg0at33GkxnQQuUZ\nT529lNZYjtbY/pv3hXY0E0TYId0v4Wsnpp1Tdb939PzldGVeytdA8UunrjTQsyx9a8f0k/QTGhqO\n69ygF8P6cUCLsRnnt4aOyBrzAk9kAJqFJgkiLFu2TCNHjlSrVq305JNPqlWrxmucsBX82OZNtXFZ\nc+bVv13PjQQB0pzfj5L97vv1Y9qWKTVpvLRXwM1/bVzWG2/JWrpMWrJM3mn/I+22S2a1Pe2N+vfa\nq7vUtmzzPwewDRjjVej0rBTPalk60SnTawEXTR9aMXVP15QektWcSpIOMPU3LZWy9CkP40ELNKNi\nvnZL38DfntdWN2c9hUHGqFvWYxlXprMD5jj56p+qkiTt59bINkZe+pvP/dz641OSPs56TOMcJz8T\nRDjArfFtlz2uSpa+pCkcWpjNPb+tt5tJZUoZJGmWxbGDHGmGzQ1zqUmuKgcNGqRoNKqDDjpIf/zj\nH33rbrvttqbYJQKYHbvKO+TARtdZa9fJmvdpZtnbv2ddw8UOWRdZn38pK1l/M2IaK0XIfs/JL8h+\nsr6xpolE5D5yf3AAQZIcW86vL5dVVXfRZi1fIfe2G+saXL30qqxnptTPcdipG90/sK060EvoGq/S\n99q5TuuNXmBNtvM1LH2z0sskdaxXqxftfJUaTxd7VZntplh5ipP+iRbov3ZeJohwQXy1XoqWaE76\nxv+y+CrtkRVEmBqt67fzUqRYl8ZXSZI6GFfnJNboobw2ihqji9OvS9IsJ1+L7foMn5cixTo5Wfe4\nuh5urQYmKzUtWqwS4+qXidW+/cQpL0IL8kPOb+vtmxUQr5E0j4A40CxYxmz55wy99957gesOOOCA\nTY5Prvx6S04HAay331XkpDMzy8lZb0g77eDf5pkpilw4XJJkSkuUmv9R8Bsao0i/42R9+kX9S61K\nZfbes9HNvVNPkjnrNEmSfdXozNMZJMnsvKOUny998VXmqRJmz25KvTpZihGF3pIKuhyW6ylA0rOp\nVTouK2WzRtJ7Ad+4vGrlaaxTIscYzUqt0D7pB8i5kj60otrNpNQ2nXKdktQ70l6fUM7QLLQrLM31\nFFqUfdxavVj5TaZXQUrSZ3aeWhtXO5j6koOv7agGFu+qmvTN/aNV32lAqj4QN9fOUzvjqlPWmDML\nd9C0aH2jX8cYTatcoJ+mAxOupE+cfO3kJVSWrqVNSTqyeBd96tAYbmtYWb0u11OAftj5bb0r3Qr9\nxauQJH2kiHpFOzTpXPHjpBKLcj2FJlPzyt053X/BURfldP8NNUk4L0ygANsGa/mK+oVNlBFYsz7y\nBRCkdLbDjJmNbm8O3D9TWeqN/L3s6e/Imr+gbty33/m37b6HUo//iwACtkudjKtjsi6wJKlA8j0/\nO9v3qku7di1Lp0faaGpqlbrIkyOpt/HXXl9hlxJAQIs118nX7wq66K81S1Qgo4ikfTz/sfalHdNZ\nhTtkAgiSdGlBZz1VtTBT7tBwzD2xMl8AQao7Hi8o7KqJVd+pk0nJkdSzQfnD9fkdCCCgRfmh57fM\n+KxShpVk8CCXaKzoQ04QNq6q/rm8pk3rjW5qvTfrh++nrI1Srzwt+//uqXsaxHeLpFhMZo/dZP5n\nkLxfnlVXagFshw42Cf3QS6PPrah6RjpopFehwV6tdpSrCtl6z4rqVrtYb9KECi3cM7FSzXHy9etE\nufqlqtTZSymluuaGz0ZL9FCszQaPaFxhR3R08S76bbxcJybXaScvqYQsfeLk6195bfRCtKTRfX3l\n5Kl/8a66NL5SR6cq1cVLqdKyNdvJ19/z2uqdSOFW+MRA8/Fjzm+SVJSVMF3+o94JwJbUJOUMPxbl\nDMDWQzkDsPVQzgBsPZQzAFvXdl3O8OLfcrr/gmOH53T/DRHSAwAAAAAAoRBEAAAAAAAAodATAQAA\nAACAIB6NFbORiQAAAAAAAEIhEwEAAAAAgCA84tGHTAQAAAAAABAKQQQAAAAAABAK5QwAAAAAAASh\nsaIPmQgAAAAAAGzDVq1apX79+mn+/Pn69ttvNWzYMJ1xxhm6/vrr5aWDIHfddZdOOeUUDR06VHPm\nzJGkwG03hiACAAAAAABBjJfbn01IJpO67rrrlJ+fL0kaO3asLrvsMj366KMyxmjatGmaN2+e3nvv\nPT355JO6/fbbNWbMmMBtN4UgAgAAAAAA26ibbrpJQ4cOVYcOHSRJ8+bN0wEHHCBJ6tu3r2bMmKFZ\ns2apT58+sixLXbp0keu6Ki/ZxnjBAAAgAElEQVQvb3TbTSGIAAAAAADANmjSpEkqKyvTYYcdlnnN\nGCPLsiRJRUVFqqioUGVlpYqLizPbrH+9sW03hcaKAAAAAAAEacaNFZ966ilZlqV33nlHn376qUaM\nGKHy8vLM+qqqKpWWlqq4uFhVVVW+10tKSmTb9gbbbgqZCAAAAAAAbIMeeeQRjR8/XuPGjdOee+6p\nm266SX379tXMmTMlSW+++aZ69eql/fbbT2+99ZY8z9PixYvleZ7Kysq01157bbDtppCJAAAAAABA\nkBDNDZuTESNGaPTo0br99tu122676eijj5bjOOrVq5dOP/10eZ6n6667LnDbTbGMMaapP8TmSq78\nOtdTAFqMgi6HbXojAFtEu8JNpwgC2DJWVq/L9RSAFiWVWJTrKTSZmkl/zun+C04eldP9N0Q5AwAA\nAAAACIVyBgAAAAAAgjTjxoq5QCYCAAAAAAAIhSACAAAAAAAIhXIGAAAAAACCUM7gQyYCAAAAAAAI\nhUwEAAAAAACCGJPrGTQrZCIAAAAAAIBQCCIAAAAAAIBQKGcAAAAAACAIjRV9yEQAAAAAAAChkIkA\nAAAAAEAQMhF8yEQAAAAAAAChEEQAAAAAAAChUM4AAAAAAEAQQzlDNjIRAAAAAABAKGQiAAAAAAAQ\nhMaKPmQiAAAAAACAUAgiAAAAAACAUChnAAAAAAAgiDG5nkGzQiYCAAAAAAAIhUwEAAAAAACC0FjR\nh0wEAAAAAAAQCkEEAAAAAAAQCuUMAAAAAAAEoZzBh0wEAAAAAAAQCpkIAAAAAAAEMWQiZCMTAQAA\nAAAAhEIQAQAAAAAAhEI5AwAAAAAAAYxncj2FZoVMBAAAAAAAEAqZCAAAAAAABOERjz5kIgAAAAAA\ngFAIIgAAAAAAgFAoZwAAAAAAIIihnCEbmQgAAAAAACAUMhEAAAAAAAjCIx59yEQAAAAAAAChEEQA\nAAAAAAChUM4AAAAAAEAQj8aK2chEAAAAAAAAoZCJAAAAAABAEDIRfMhEAAAAAAAAoRBEAAAAAAAA\noVDOAAAAAABAEGNyPYNmhUwEAAAAAAAQCpkIAAAAAAAEobGiD5kIAAAAAAAgFIIIAAAAAAAgFMoZ\nAAAAAAAI4tFYMRuZCAAAAAAAIBQyEQAAAAAACGJorJiNTAQAAAAAABAKQQQAAAAAABAK5QwAAAAA\nAAShsaJPswwiFHQ5LNdTAFqMvct2zvUUgBbjq3WLcz0FAACAH6VZBhEAAAAAAGgOjEdjxWz0RAAA\nAAAAAKEQRAAAAAAAAKFQzgAAAAAAQBAaK/qQiQAAAAAAAEIhEwEAAAAAgCCGxorZyEQAAAAAAACh\nEEQAAAAAAAChUM4AAAAAAEAQGiv6kIkAAAAAAABCIRMBAAAAAIAgHo0Vs5GJAAAAAAAAQiGIAAAA\nAAAAQqGcAQAAAACAIDRW9CETAQAAAAAAhEImAgAAAAAAQQyNFbORiQAAAAAAAEIhiAAAAAAAAEKh\nnAEAAAAAgCA0VvQhEwEAAAAAAIRCJgIAAAAAAAGMR2PFbGQiAAAAAACAUAgiAAAAAACAUChnAAAA\nAAAgCI0VfchEAAAAAAAAoZCJAAAAAABAEDIRfMhEAAAAAAAAoRBEAAAAAAAAoVDOAAAAAABAEOPl\negbNCpkIAAAAAAAgFDIRAAAAAAAIQmNFHzIRAAAAAABAKAQRAAAAAABAKJQzAAAAAAAQwFDO4EMm\nAgAAAAAACIVMBAAAAAAAgpCJ4EMmAgAAAAAACIUgAgAAAAAACIVyBgAAAAAAgnhermfQrJCJAAAA\nAAAAQiETAQAAAACAIDRW9CETAQAAAAAAhEIQAQAAAAAAhEI5AwAAAAAAQShn8CETAQAAAAAAhEIm\nAgAAAAAAAYxpvpkIruvqf//3f7VgwQI5jqOxY8eqqqpKN9xwgxzHUSwW00033aR27dppwoQJevzx\nxxWJRPTb3/5W/fv3V3l5ua688krV1taqQ4cOGjt2rAoKCja6T4IIAAAAAABsg1577TVJ0uOPP66Z\nM2dq7Nixqqio0OjRo7Xnnnvq8ccf1/33368LLrhA48aN01NPPaV4PK4zzjhDhx56qO6++24NGjRI\nJ598su677z498cQT+sUvfrHRfVLOAAAAAADANuiII47QDTfcIElavHix2rVrp9tvv1177rmnpLpM\nhby8PM2ZM0c///nPFYvFVFJSop122kmfffaZZs2apcMOO0yS1LdvX82YMWOT+yQTAQAAAACAIM28\nsWIkEtGIESM0depU/e1vf1OHDh0kSR9++KHGjx+vRx55RNOnT1dJSUlmTFFRkSorK1VZWZl5vaio\nSBUVFZvcH5kIAAAAAABsw2666Sa9/PLLGj16tKqrq/XCCy/o+uuv13333aeysjIVFxerqqoqs31V\nVZVKSkp8r1dVVam0tHST+yKIAAAAAABAEM/k9mcjnnnmGd17772SpIKCAlmWpalTp2r8+PEaN26c\ndtxxR0nSvvvuq1mzZikej6uiokLz589Xt27dtN9+++mNN96QJL355pvaf//9N/nnsEwzbDUZiXXN\n9RSAFmPvsp1zPQWgxfhq3eJcTwFoMeKpZK6nALQoqcSiXE+hyaw7/8ic7r/0gamB66qrqzVy5Eit\nXLlSqVRKF154oUaNGqXOnTtnsgp69+6t4cOHa8KECXriiSdkjNGvf/1rHX300Vq5cqVGjBihqqoq\ntWnTRrfddpsKCws3Oh+CCEALRxAB2HoIIgBbD0EEYOsiiNB0NhZEyAUaKwIAAAAAEMA088aKWxs9\nEQAAAAAAQChkIgAAAAAAEIRMBB8yEQAAAAAAQCgEEQAAAAAAQCiUMwAAAAAAEMTL9QSaFzIRAAAA\nAABAKGQiAAAAAAAQgEc8+pGJAAAAAAAAQiGIAAAAAAAAQqGcAQAAAACAIJQz+JCJAAAAAAAAQiGI\nAAAAAAAAQqGcAQAAAACAIF6uJ9C8kIkAAAAAAABCIRMBAAAAAIAAhsaKPgQRsEndTErDvUoN9OLa\nQa5cWVogRy/Y+fqrXaSVlrPBmF5eQhd7VeprEuokV3FZ+sKK6BkrX3faRaqySIJBy/bTZKXOrl6i\nXol1KvOSqrQcfRAr1T+LdtDn0aINti/zkrqg8nv1TaxWBzehKsvRnGiJHirqotmx0sD9dE3V6ldV\n3+ugxFqVeUmttSOaFS3V/UVd9VUj+wG2Z/3cGr2QWC5JetPO07F5nRrdbj8vrt+mKtTHq1VHU3cO\n+8qKarJTqHsiJYHnsEPcWv3KrdChblxt5WqtbM2083RnpFRvO/lN9rmAbU1/L66p7ipJ0htWTAMj\n7Rrd7mcmqeFupfqnryerZGmWFdM/7EI9axdszSkDyGIZY5pdWCUS65rrKSDtLK9a97prlBewfols\nHRdpq0+saOa1a9wKjfEqtGFooc7ncnRUpJ0WNRJ8wNa3d9nOuZ5Ci3NO1WJdVvlto8dIUpaubNVN\nr+eXZV7bOVWjf66epw5ecoPtPUljS3bVhMINb4b2TVTonjWfqti4ofaDpvfVusW5nkKLVWg8TYsv\n1b6m7jgKCiJcmVyr61JrAs9hX1gRHZ/XUYst//cwo5JrdG1qbaNjPEl/iLTWbdFWP+YjYDPFUxv+\nPxO5V2g8vZlaqZ5KSQoOIpznVeked23gN5732IX6ndO6CWeKzZVKLMr1FJrM6lMPz+n+2zz5ek73\n3xBfByPQPiap+7MCCAlJsxXRgqxLq87yNClVrrx0LOpor1Z/ygogVMvSB1ZUi7P+qXWXq8fdcqn5\nxa+AJndMzUpdkRVAqLJs/TdSpLgsSVJURjes+0qt1gcMTN3y+gCCK2lepEhr00E4W9LVFd/oJ6lq\n337yjKu/rP0yE0BIyNLcSJGq09+grt9PmZto0s8LNAdFxtNTieWZAEKQI90ajckKIFTL0odWTEuy\nznvdTErjEit957B+bo0vgLAm/W1pdfq4tiX9MbVGR7o1W+wzAduiIuPpObc8E0AIsodJ+QIIVbL0\nvhXV2vQxJUm/9ap1oVvVhLMFsng5/mlmCCIg0KVupdbnF1TI0gGR9uod7aA9oh11nV2S2W5XuTrV\n1F0YXelVZl7/Trb2jrTXQZH22iXSUffZhZl1B5ukDjPcvKBliRhPV1d+k1n+OFqso9vtr2Ft99WZ\nZT/LBBJKjavjaldKkg5JrFWPZP1xdUnrn+qMtvvq+Hb7aaFTF+KLyuiCyu99+xpcs1JdvbgkKS5L\nZ5b9TGe23Vcnt+2ZCUCUGldnVS9pss8LNAeHuLV6J75EfdPHw8ZcnhUI+N5y9PO8Ljosv7O65XfV\nA05xZt1BXlyHZr3fxamKzO8fWjHtnd9VffM7q1deZ5VnXWpdnFr3Yz8OsM3q48U1K7VC/UJc/13k\nVWUCCN/K0Z6RDjo40l57RDrqq6yg3qUeQQQgFwgiINARpv4C6TG7QHOzShb+Yhcr+/uU3iahmDHq\nk3Vi+IddpO/S6Z6eZelPWYGHujGkGaJl6RtfrbZZJQl/KtlNFXbdMfJltEiPFHbWpPwOuqdoB30Z\nqQu6HZUOJkjS3EiRZuS1kSRV2BE9Vtg5s65fYrVipj5UfVS8ftzreWX6It3/YImTp2cLOmTWHRlf\ntSU/ItBsxIzRs/FlmppYpt3Nxr/1XL/9IVmBgfudEn1v15/DxjYoReiVte1qy9Z/ragSksZGW2lN\nOlD3rR3Vm3Z9L4RdQ8wD2N7EjNGLqVV63V2ln2jD8rrG1MjSR4qoRtJf7SItTh9T5Zat57KOqd03\nkdEAbCnGMzn9aW5orIhAo51SdTWuOsvTNCvmW+dZlmplqUB1/6hjRnJk9FuntboYV13kanqDMVVZ\nKWiSFFPzOyCApnRgov5bzhV2NHNjv94dJRv2p9g7Vf8tyydRfyDuo6zlQuNpt1SNPku/517J+nFz\no8UbjDtbdRkIO7lxlXipTDAD2F4UyGigV5tZfsGuO2Md7zVeUuDIaHi0rTqZlLoYV2/Z/m5A1Q2+\nd4lm/f7rWF09d8QY/5nNGO2WFTBfaHGcoeUpkNGRWV9MPW/lyUgabIKzg0Y5pRrllMo2ZoP+JLtn\n9fn5JrB7CYCmxNkMgcZnlR80tJ9JqE3WpdI3lqMay9ZDVvCYAQ1OFgtorIgWZo+svgVfRwpU4qV0\nZvUS7Z2sVNyyNStWqqcLOqg2fWxYxmiXVP0Nz3LHH5hbZvuXd01V67NokTq4cZVkXWQttzc+brdU\njT6O+QMUwPZihWzdEm2lvzslujcZnHlTY9n6d6Q4cP3hDYIP3zYSEEhZ6R4Ixmhnk9LlqXW+Pgx3\nRzjO0HKtkK2xdrH+ZhfpAXdNqDGeZdWVgxujrvJ0gVelE0x9cPBOO/iYBdB0CCJgsznG6BbXX9f5\nor3xR1cVG09/dOtrRuOSpllBz3wAtk/tskoZYsZowqqP1cWrLwE6Ml6us6uW6OI2P9WCSKGKjOvL\n2KlsEHirbrDcOp0q3drzp3dW2v7tauyG4ygtwvYnIel30TI96hSp9kc+VrjYeLouWX/TE5f02kYe\n2XhjarWGZ/VJSEgaFW2jF53gQDuwvUpI+q3dSuPsQtVa1ia3b8zFXpXu8OqvPT1Jt9tFutvhUcXY\nSpphc8Nc2io9EVavXq377rtva+wKTcwyRg+6a3xNcV6w8jTHigaOyTdGT7vl2jOrbu0Bu1AryURA\nC1OUlR3w82SFL4CwXlcvrr+v/kwlXkoFxn/GSjUoCUo1uBhbv/2mxiUbLBd4nBmx/amxbP0rUvKj\nAwj5xtOExHL9NKufwUNO8UbPYTt5/rrv6Xa+rzcC0JLUWLbud4p+cABBknZp0EvhQyuqyVbBj50a\ngB+oSYMIc+bM0YgRIzRo0CAtXbq0KXeFrcA2Rg+5a3SGqU/pXCtLlzjBz70uNJ6edVepf1bQYaEc\n/a9d2qRzBZoju8FjTedGijSkbF/1ad9btxXX90Po6sV1ZvUSWZvoGxK0dlPjAIRTaDw9lVihfllN\nFL+zHP0h2mbj4+RpphXT8vRl1kCvVm/Hl+jsVOVGxwFoXCtjNNOKamG6B0Ivk9R0d6WuzcpyBZqS\n8XL709xs8XKGRCKhKVOm6JFHHlEsFlNlZaWmTZum/Hwi8NuyiDF6xF2tIVl1aAlJZzptAhtFlaSf\nBZz9xIZ1sjQk0kbrfuQ3Q8C2qMZypKxvM0e3+om+Tj+F4d9FXdQrsU79EqslSQPi5Xok6+kLkhRp\nEByINliuSR9XNQ2+IW04ruFyjc3xCDRUYjw9lVjue5TjOlkaGmu/yXPY/+R1lCRFjdE9yVUa5lYp\nKumO5CpNt/P0jR2cvQdgQ7+KtK77xRj92avQ1elHio/xKvSaFdMMmxJZYGva4leOAwYM0Oeff65b\nb71Vjz76qDp06EAAYRsXMUZPuuW+AEJc0jCnjV4KSM8sMZ5edlf5AghrZel4p61mN3hqA9BSrM56\nAkKl5WQCCOt9mNXccEe3VlWW4ys9yC6HkKSiBinTa9IBvbUNnrSw6XHc0ADZSoyn5+LLfAGEtbJ0\nUqyDPtqMm5WkZenKaJtMKW2epCFu9caGANgYy9Jou0Qrsm5hzjSNP3EFQNPZ4pkI55xzjp5//nkt\nWrRIp5xyiowhrXabZowedlf7HsNTLUunbSSAkGeMnnXLdUBWs7aVsnVcpEwfEkBACzY/Uqh90o9s\njBhPMkbKqhHNbpRombqu1IucPO3i1gXw2rv+HgodGvRUWJAOSiyzY6qRrYL0rcumxxHoBdbLM0YT\nE8vVOysIvlK2TszbeAChxHjawaT0hRWVm3Vcr7EcrZGtsvTxuKPhufZAGIXG045y9Z0cVWdl/7iW\npe/kqH36mNq5QaAcaBLNsKQgl7Z4JsKvfvUrPfvsszr77LP1/PPPa+7cubrlllv0xRdfbOldYSsY\n41Xo9KwMhGpZOtEpCwwgSNK97hodlnXxtUK2joi0JYCAFm92tD7TIF9Ge6YDCuvt5NYfa4udupuV\n/0brO0/3TPprP3+WrK+vrrZsfR2pazJlLEufRws3Mq5+eaGTp3WkVgMZf0+uUp+sDIQVsnVcXsfA\nAEI3L6nFNQu1tPY7fRBfoj5erW99J5PKBBAkaTlNhYGNKjaeliWXaF1qqealVug04z+m8ozR7lnN\nupdtnT7xALI02VF3wAEH6JZbbtHUqVPVqVMnXX311U21KzSRA72ErvH8TaDOdVrrtY18EzPEq9FZ\nWWllSUknOmWaS7o0oGn5ZarNKk8YVbFArdKPfdwpVaMTapZn1r2dV1f/+VpeWea1vVNV6hOv65lQ\n7KU0rHpJZt2bsTZKZH1Tkz2uX3y1uifrAhYd3LhOqFmRWfdqXtst8tmA7cH/uFUa5tYH95KSTsnr\noHl2cBB8vhXxHdd/Tq5R+/Q3owXG098S5b7tX3ToKA9sTKVl65usZOnr3Artms7gcYzR7d5atcrq\n7TOFJ59gK6Cxop9lmmG9QSTWNddTgKRnU6t0XFYZQ42k9wKyCV618jTWLtbs1Ar9LCs6vFpW4OMf\nx9sFetDm+b65tnfZzpveCFvM+VXfa3jld5nlKsvWt06BdktVKz99UbTOcjSkbQ8td/LkGKMJqz7W\nT9y64Jwr6dNIkXZw42qdvqhKSRpatq++zMpaKPZSenbVR2qbDlLEZenLSKF2dWtUlD4bVViOTmrb\nUysdsoS2lq/WLc71FFq0exMrdVY6SPCmnadj8zrVrzRG78WXaO+sUrzVsvVJQKbOY06R/h2pyy76\nTWqdbkuuzqyrlKXPrah2bZCF8IRTqF/G2m/Jj4SNiKeSm94IOfFAarXOTX/p9IYV08BIO9/6QV6t\nnnHrA3C1kuYpqq5y1SnrmHrLiulwp62vNBC5k0osyvUUmszKY/vldP/tXnwjp/tvaIv3RMD2oZNx\ndUxWAEGSCiT1Mxs+116SvpejA03SF0CQpDYygWPeNty4oOX5V2FXdXHjOiWddVBkPO2VVdZQYTm6\nolV3LU+XM7iWpStad9f9q+epg5eUI2X6Kqx3a8kuvgCCJFXaEV3RqpvuWvOZio2rPBnfuKQsXV+6\nOwEEIK23SfgCCJLURp76evFGt38nKyvvH06JdvNSujj9uLliGe3f4Nw3xS7QRVEyf4AwnrfzdbUp\n1VhvnRxJ+ZL2l//4fNeKaojThgACkAMEEdCog01is2tdDgkIFgCoZyxLN5TurjdjbXR6zVLtnaxS\noXG1zInp7VhrPVTUVUscf8nQN5ECndK2hy6oWqTD4+Xq5CZUZTn6JFqsh4q6aFasVaP7mh0r1ZC2\nPXRh1fc6NL5Gbb2k1tkRzYqW6p9FXfVFlEwgYL2D3caDBaFYlq6OlWmKW6BfpSp1kBdXW7laJ1sf\n2TE97BTrKaeQmx1gM9zuFOt1O6bhbpX6moQ6yVW1LM21ohpvF+ghq1ApjilsLc2wpCCXKGcAWjjK\nGYCth3IGYOuhnAHYurbrcoajc1zO8DLlDAAAAAAAbBOaY3PDXOKZKAAAAAAAIBSCCAAAAAAAIBTK\nGQAAAAAACEA5gx+ZCAAAAAAAIBQyEQAAAAAACEAmgh+ZCAAAAAAAIBSCCAAAAAAAIBTKGQAAAAAA\nCGKsXM+gWSETAQAAAAAAhEImAgAAAAAAAWis6EcmAgAAAAAACIUgAgAAAAAACIVyBgAAAAAAAhiP\nxorZyEQAAAAAAAChkIkAAAAAAEAAGiv6kYkAAAAAAABCIYgAAAAAAABCoZwBAAAAAIAAxtBYMRuZ\nCAAAAAAAIBQyEQAAAAAACEBjRT8yEQAAAAAAQCgEEQAAAAAAQCiUMwAAAAAAEMB4NFbMRiYCAAAA\nAAAIhUwEAAAAAAACGJPrGTQvZCIAAAAAAIBQCCIAAAAAAIBQKGcAAAAAACAAjRX9yEQAAAAAAACh\nkIkAAAAAAEAAMhH8yEQAAAAAAAChEEQAAAAAAAChUM4AAAAAAEAAY3I9g+aFTAQAAAAAABAKmQgA\nAAAAAASgsaIfmQgAAAAAACAUgggAAAAAACAUyhkAAAAAAAhgDOUM2chEAAAAAAAAoZCJAAAAAABA\nAOPlegbNC5kIAAAAAAAgFIIIAAAAAAAgFMoZAAAAAAAI4NFY0YdMBAAAAAAAEAqZCAAAAAAABOAR\nj35kIgAAAAAAgFAIIgAAAAAAgFAoZwAAAAAAIIDxKGfIRiYCAAAAAAAIJTAT4a677trowEsuuWSL\nTwYAAAAAgObEmFzPoHkhEwEAAAAAAIQSmImQnWlQXV2thQsXqlu3bqqtrVVhYeFWmRwAAAAAAGg+\nNpmJ8M477+jEE0/URRdd9P/s3Xl8VPW9//H3mSWTfQHCvsgmggqKa1vEiru1dWmxFrW11l6Ldav+\nqhStpba97bXCbdWilavXylKKu15t73VBULCWggsqWBVRAmFNQjKTZJZzvr8/EiZzApM5KskMyevZ\nRx6PnJlz5nzHcnLO+ZzP5/PVrl27dNJJJ+mVV17pirEBAAAAAJBVxrGy+pNrMgYR5syZo0WLFqm0\ntFSVlZVauHChbr/99q4YGwAAAAAAyCEZp3h0HEeVlZXJ5VGjRnXqgAAAAAAAyBWOyb1sgGzKGETo\n37+/li5dKsuyVF9fr4ULF2rgwIFdMTYAAAAAAJBDMpYz3HbbbXr66adVXV2tU045RevWrdNtt93W\nFWMDAAAAAAA5JGMmQu/evTVnzhyFw2H5/X4VFBR0xbgAAAAAAMg6QzmDS8YgwnvvvacZM2Zoy5Yt\nkqQRI0boP/7jPzR06NBOHxwAAAAAAMgdGYMIP/vZz3TdddfpxBNPlCQ999xzmjlzphYsWNDpgwMA\nAAAAIJuMyfYIckvGngjRaDQZQJCkU089VeFwuFMHBQAAAAAAck/aIMKWLVu0ZcsWHXLIIbrvvvtU\nU1Oj3bt3a8GCBTr66KO7cowAAAAAACAHWMbsOzljypQpsixL+3rbsiy98MILnTaoQN6gTvtsAG6H\n9hqW7SEAPcYH9VuyPQSgx4gm4tkeAtCjJGKbsz2ETvPGsK9ldf9HfPxUVvffXtqeCC+++GJXjgMA\nAAAAAOS4jI0VN27cqAULFqixsVHGGDmOo6qqKi1cuLArxgcAAAAAQNYwxaNbxsaK119/vUpLS7Vu\n3TqNHTtWW7Zs0ejRo7tibAAAAAAAII14PK4f//jHmjZtmr7xjW+42g48/fTT+uY3v5lcXrJkic4/\n/3xdcMEFWrp0qSSppqZGl112maZNm6brrrtOTU1NGfeZMYgQj8d1zTXX6IQTTtC4ceM0b948rVq1\n6rN8PwAAAAAAsJ889dRTKi8v16JFizRv3jz94he/kCStW7dOjzzySLLH4Y4dOzR//nwtXrxY999/\nv+bMmaNYLKa5c+fq7LPP1qJFizRu3Dj95S9/ybjPjEGEgoICxWIxHXTQQXrnnXeUn5//Ob8mAAAA\nAAAHBmOy+9ORM844Q9dee21y2e/3q7a2VnfccYdmzpyZfP2tt97SkUceqby8PJWUlGjo0KFav369\nVq9erRNOOEGSNHnyZK1cuTLjf4+MPRG+9rWv6Qc/+IHuuOMOffOb39TLL7+sfv36ZfxgAAAAAADQ\neYqKiiRJ4XBY11xzja699lrdfPPNmjlzpkKhUHK9cDiskpIS13bhcNj1elFRkRoaGjLuM2MQ4eKL\nL9a5556r4uJizZ8/X2vXrtWkSZM+9ZcDAAAAAOBA4+R4Y8Xq6mr98Ic/1LRp03TQQQfp448/1qxZ\nsxSNRvXBBx/oV7/6lY4//nhFIpHkNpFIRCUlJSouLlYkElF+fr4ikYhKS0sz7i9tEOHuu+9Ou9F7\n772nq6666lN+NQAAAAAAsL/s3LlTl112mW699VZ94QtfkCQ988wzkqSqqipdf/31uvnmm7Vjxw79\n7ne/UzQaVSwW04cffqiDDz5YEydO1LJly3T++edr+fLlOuqoozLuM2MmQjYc2mtYtocA9Bjv1VVl\newhAj/HrvpOzPQSgxxptsk0AACAASURBVLhx69JsDwEAOt29996r+vp6zZ07V3PnzpUkzZs3b69e\nhpWVlbrkkks0bdo0GWP0ox/9SKFQSNOnT9dNN92kJUuWqKKiQrNnz864T8uYTK0aut6E/l/M9hCA\nHoMgAtB1CCIAXYcgAtC14rHN2R5Cp1k16Lys7v+YzY9ndf/tZZydAQAAAAAAQMrRcgYAAAAAAHJB\nrjdW7GqeMhEaGxu1fv16GWPU2NjY2WMCAAAAAAA5KGMQ4dVXX9U555yjK6+8Ujt37tRJJ52kV155\npSvGBgAAAAAAckjGIMKcOXO0aNEilZaWqrKyUgsXLtTtt9/eFWMDAAAAACCrTJZ/ck3GIILjOKqs\nrEwujxo1qlMHBAAAAAAAclPGxor9+/fX0qVLZVmW6uvrtXDhQg0cOLArxgYAAAAAQFbRWNEtYybC\nbbfdpqefflrV1dU65ZRTtG7dOt12221dMTYAAAAAAJBDMmYi9O7dW3PmzOmKsQAAAAAAgByWMYgw\nZcoUWdbe6RsvvPBCpwwIAAAAAIBcYShncMkYRJg/f37y90Qioeeee06xWKxTBwUAAAAAAHJPxp4I\ngwYNSv4MGzZMl19+uZ5//vmuGBsAAAAAAFnlZPkn12TMRFi1alXyd2OM3n//fUWj0U4dFAAAAAAA\nyD0Zgwh33nln8nfLslRRUaHf/OY3nTooAAAAAACQezIGEc466yx961vf6oqxAAAAAACQU4xorJgq\nY0+EhQsXdsU4AAAAAABAjsuYidC/f399+9vf1oQJExQKhZKvX3XVVZ06MAAAAAAAkFsyBhGOOOKI\nrhgHAAAAAAA5xzHZHkFuSRtEePzxx3XeeeeRcQAAAAAAACR10BPhoYce6spxAAAAAACQcxxZWf3J\nNRkbKwIAAAAAAEgdlDO8//77Ovnkk/d63Rgjy7L0wgsvdOrAAAAAAABAbkkbRBg2bJjuu+++rhwL\nAAAAAAA5xeRgSUE2pQ0iBINBDRo0qCvHAgAAAAAAcljaIMLEiRO7chwAAAAAAOQcJ9sDyDFpGyve\neuutXTkOAAAAAACQ45idAQAAAAAAeJK2nAEAAAAAgJ6OxopuZCIAAAAAAABPyEQAAAAAACANGiu6\nkYkAAAAAAAA8IYgAAAAAAAA8oZwBAAAAAIA0KGdwIxMBAAAAAAB4QiYCAAAAAABpMMWjG5kIAAAA\nAADAE4IIAAAAAADAE8oZAAAAAABIw6GawYVMBAAAAAAA4AmZCAAAAAAApOHQWNGFTAQAAAAAAOAJ\nQQQAAAAAAOAJ5QwAAAAAAKRhsj2AHEMmAgAAAAAA8IRMBAAAAAAA0nCyPYAcQyYCAAAAAADwhCAC\nAAAAAADwhHIGAAAAAADScCwr20PIKWQiAAAAAAAAT8hEAAAAAAAgDaZ4dCMTAQAAAAAAeEIQAQAA\nAAAAeEI5AwAAAAAAaTjZHkCOIRMBAAAAAAB4QiYCAAAAAABpOMzw6EImAgAAAAAA8IQgAgAAAAAA\n8IRyBgAAAAAA0nBEPUMqMhEAAAAAAIAnZCIAAAAAAJCGyfYAcgyZCAAAAAAAwBOCCAAAAAAAwBPK\nGQAAAAAASMOhr6ILmQgAAAAAAMATMhEAAAAAAEjDyfYAcgyZCAAAAAAAwBOCCAAAAAAAwBPKGQAA\nAAAASMNkewA5hiACJEmLdr2lQxORDte5qWy0/pbfJ7l8fLRO0xq36vB4g4qMrR3+PL2SV64HigZp\nmz+U9nOOi9ZpatM2TYg3qMJJqMny6cNAof6a30ePFvRVwiJBBj3TIU5c19kN+rLTrP6ylZClDVZA\nT/sK9Ht/ierTHBvHOlFdZTfoi05MfWWrWZbWW0E96ivQPf4SxSxaCqNnGdK8Vd/Y8YIkaVOorx7p\ne2qH604I/0sDozuU78TU5A/p49AAvVZ2mHYHSva5zcGNH+vw8PvqG6tVQLbq/UX6sGCwVpWMU7SD\n89+YyEYdGvlQfeO1ynNiivnytC2vl9YWjdIHhUM/35cGDgDDTEI/ciI6zWnWYNmKytJaK6gHfYWa\nbxXIpJyv4vEtnj93mZWnUwJ9Mq8IYL8giAD5jNHIROOn2ua6ho/13Ub3H/fBdlQXNm3T2c079aPy\nMfpHXpl7I2M0s+EjfbNpm+vloLF1ZLxBR8Yb9JXmHZpePlYRH/800bOcZTdpYWKXClyxbqPxJq7x\ndlzfsiM6Na+vNlvuY+NyO6zfJ2rlT3ktT0bHmpiOtWP6htOks4KVaiA4hx4i4CQ0uW5N5hWN0Yl1\nqzUx/J7r5WK7SYc2btCopk/0WOXJ2hpquzGxjKMzalbqkMaPXdv0StSrV8O7GhfZoEcrp2hXXsVe\n+zqjZqXGNm50vVzgRHVQc7UOaq7WW82j9EKv4z7VdwUOJKc7zVpi16ow5TxXIKMTTEwn2DGdYzXr\nm/4KJQh8IwcxxaMbV5XQQXaT8lv/oDfL0qpg6T5/anxBSdK5TdtdAYRdvqA+8Bcku5YWG1u/r1uv\nAXbUtZ+pTdtcAYSw5dfbgSLVptwUTYiH9dP6DZ30TYHcVG4c3Z8SQHAkvWUFtSElNDBCtv4Yr3Ft\nN9KJ6z9TAggxSWusoKpStjvGxPSbRF0nfwMgNwSduM7duVR947UZ1z2m4R1XAKHZl6dtwV5y1HKl\nGDIJnbVrhSzT1pP7+Pq1rgBCvb9QNSnZCkVOs87fuVR5Tsy1r3GRDa4AQtQKamuwl5qtYPK18ZEP\nNCbykfcvCxxAyo2jBSkBhKikNQpqR8qtyNdMs2Y5DcnlZVZe2p832j0HfcrK75LvAaAFj3uhg+Nt\nWQjvB4p0ea9D065rGaMrw5uSyy/lVeiG8oOVsHw6Plqnu+rWK09GhcbR1eFPNLNsdHLd76QEHtYF\nivRvFWNV7wsqZGzdUfcvTY613OicGd2l39tRVXeQEgp0J2c5TapovbCyJZ0TrNTzvpYLolsTuzXT\nrpcknWKiGmBsVVstQYILnEbtuQWJyNKXg3211pcnnzG6N1Gjbzstx/aFTqOuNTzdQfc2KLpdp9W8\nqvJEOOO6hXaTjq9/O7n8QcFgPdt7kmzLr6HN1fr6jhclSWV2WMObt2hDwWCFnKiOaliX3ObNotF6\nseIYybI0LrJBp9e8Kqklk+Ho+ne1svyI5LpjG9uCAzuC5Xq48hRF/SGFnKimbn9elfGW89+hkQ16\nr2j45/sPAeSgS51Glbee53bL0uRAH71rBVVgHP3N3qUvmrgkaboT0SxfiRKW1WF5woOJWh1hEpKk\nP1sFutNf3PlfAkASmQjQmJReCJ8EOo7kHpKIqF/KE5Z7igcnexj8PVSuxwr6Jt+b0lyjAseWJA1O\nNGtISmbCg4UDVd+a2RC1/Lq/aJBrP4fGM18EAt3FIGMnf19rBZMBBEn6vd9dkz2k9aKp/XbP+/K1\n1pcnSXIsS3enbFcko97McIxuym9snb/9BV2w/TlPAQRJGtO4UYHW48eWpecqjpPdGpz7JH+A3i4a\nqbeKRmll6XiF/YWSpCHN2xRMOeZWlE2QWgNz7xaN0Ib8gcn3UoMGklRstwXr3ykameybEPWF9E7R\nyOR7JfanKy0EDhRG0iorqLAs/bevUO+2ZuE0WT4tsQqS65XKqG+G89WpTrMuMk2SpC3y6Wp/WYfr\nA/uDk+WfXEMmAnRwSj+EqgxP/we3K1H4OFDgWn49r1QXtpYsFMjR2EREa/JKFfH59fOSEap0Yurr\nxLQuWOTarsnyu5aDJhcPF6BzfJzy77+03b/98nanji0p636cUgrU0XbNknYSM0Y3FTC2hkW3Jpc3\n5A+SkTSyeXPabYY2t62/La+3mv3uAPpzvY7fa5uylABFoy+0VwPFLaG+GtHcknFXajeqJBFRQ6Dl\nXFcfKFavREuadp4Td20XSgnM7wlYAN3N7/3F+r2KJWPU/kpzpNqCc02StnVwvio0jv5g704u3+Qv\n1W56/gBdjiACdHBKJsL4eFhLdr2pYYkmNVp+rckr1f1Fg/RusCVNzN9ugpOAMVJKhnSkXTBgVKJR\na/JKVesL6rHCfmnHcFxst2t5s5/aNvQc/+MrULV8GiBHI2TrlsRu3ekvUbkc3ZlS2/2cla+qlMDB\nn/2FusmuV7GMTjRRfc8Oa7GvUIONrV+n9EFY4CuSTSkDurlGX0j/KD1MrxeP0Wk1f+9w3T7xtuOj\nJlim4kSjjgyvV+94nWJWnjYWDNC6wuEyKTcnvpTzn28fge5Yu6anveN1ySDC2qJROqi5WpJ0RPg9\nbQ711da83hoQ26kjUvoyvJ2SlQB0S5alPY+j+hpbU50m/cBpuw69J8P56jonouGtQYfVVlCLrYK0\n6wL7E4833Qgi9HAVTlx9U56KfCHlZj7fJHRKtEZfjtbol6Uj9HhBP21tTZfeY3RrkGCPUe1meaho\n98RlX/raUV2a0i+hxgronSC1beg5Gi2fzglWamFil0abhG6x63VLax+EPdZYQV0W7OV6rcoK6IJg\nH/1XfJcGytEfErX6g9wN5Z6z8vXjQHmnfwcgW2z59HzFsXq3cLhsjzP7FNlNrt8v2fqM8k1bRsCY\npo91RMN7erLyJEX8LTcpDSlZAvkmrpJEWA2BtnNV77g7GF7gtGXufVA4VMsSE/Wl+jdV6EQ1dcfz\nrnUdWVpVMk7vFR3kafzAge4rTrOesN3NghdZBZrpK02zhRQ0RtNTAg63+4qTJUUAuhb5Pz3cwfGI\na9lWS9PDjf78ZMQtIOmW+g06PNagt4PF2p2SbXBN+BMVOy012kMSTbqosdr1eQUZyhLKnbjm1q1T\n75Rgw4NFA3lqih7nX1ZAj/r2ncockaV/95dpR7tMH0laY+Xpf337fhKzTT79e6BUTaR6ohtL+AJa\nWzzacwDBb2xXVt3w5i2uAMIe/eK1+tqOl5KzM2zK7y87JfXuxLo18rf2SOgX3aVxje6ZhYJOwrX8\nUcFAbQ+2m/qx1da83lpbPMrT+IHu4CDjPj42yK9FvoIOr/++ZZrUv/Xq9AP59TgzMgBZ06mZCFVV\nVaqurtaAAQM0ePDgztwVPodVwVINsZu1zZ+nmaWjVdXaXPH4aJ3urluvoIwCkq6IVOmqirH676JB\nui78iSTpyHiD/rpzjar8+RqZaFSoXblDRyGEXk5cf6x9V6MTbU+E3gkUaUHhwA62ArqfPGP0dHyn\nTjAtTy7jktZbQRUbR8Nlq0hGjyR26jemVLMCbQ2kKoytpfHtOqT1Yqy5dbtK42iQbPWTo6Xx7boy\nUKEH6FwNSGqZZai9j/IHaGnFMYpZQR1T/46OCq+XJPWP12hs40d6t2ikIv4CvV00ShMi70uSRjdt\n0qAtjyvsL1TveN1e5X4m5WaoX3SXvrHjeeXtOVatoHYHSlSeaFDIxDUwtlOXbH1Wj/Y9WdvyenfW\nVwdyRh85+qcVVJlxNFq2RsjW/9g1ut8p1A/8ZfvMMLjabutLcq+vyHWMAZ3N8M/NpVOCCJFIRDfc\ncIPq6uo0aNAgbdy4Ub1799acOXNUXMyFbC55LVSu10L7TnX+e6hcz+T30bnNOyRJx8Z2K2AcPVg4\nUGPiEZ0Z3SVJKjW2xrX2VfjQX6CD7KbkLPUR395PTiWp0o7pvtp3NSIlpXS7L6gbyseQhYAe51q7\nIRlAqJel04N99Xpr6dB0u0H/2drfYIZdr7/58vV3X0tbql8kdicDCJvk1+l5fbXBCsgyRr+yd+t6\nu6WR2+8TtXrel69PLCrYgITVcru/50wTt/z6W68vqbm1UeLy8okaGt2anHZxVGOV3m3tVbC8fKJ6\nJeo1JNrSQLjQiaqwtWxhR7A8uY2U0iPBGJ1eszIZQPg41F9P9TlRCV9AeU5MX925XEOj2xQycZ2x\na6X+1P9sUrTR7f3cX6qft/5+hR3R3U5LOdD3TKOWmTz92XJn5h1pYjpCbdkLj/vIQgCyqVNyXGfP\nnq0zzjhDixcv1uzZs/Xoo4/q1FNP1e23394Zu0Mnei9lFoWQjHo5cRnL0oyy0ZpVOkLvBIrULEs1\nVkAPF/TTteVjlBo22Nmuh4LU0gPhgdq3XQGEbb48XV5xqKozzA4BdEffSqnxfMBflAwgSNI9/hKt\naZ0KS5IuslvXNUYXOm09SOYESrSh9abFWJZu8ZclO1wHJV3A1HFAC8tSk6/tXFMXKEkGEPa8vyWv\nMrlY1jqrgtRSOvFY5UlaVjZRuwJlSsinBn+BVpWM04sVx7h2s6eXQr9YjXon2nqcLCufqERr6UXM\nl6eXyo9KvtcrUa/+sV3753sCB4g/+ov0RspzzYucpr3WOcdpTv7+uoIExdHlmOLRrVOOwPXr1+vW\nW291vTZ16lQ98sgjnbE77AeFjq2AHNX7gq7XA+3SPhN7aqstS48X9NPjBe4ZF46IuZvBvR9wR5LL\nnLjurV2noSlTRVb5Q/q3inHMyIAea3jK3PMb9nFhtMEKaKJp6RsyrHXdvnJUnJI+vaHdn3PHsvSJ\nFVC/1lrvYe3qT4GebFewTIXR7ZIk/z5698RT+itY7cv0LL/WlI7VmtKxrtcPiXzkWt4ZbMnyK7Mb\nXK/vDpR0uFxqh7VVfbx8DeCAEjJGg2WrRj7VtuvV85EV0BGt56mhKefEPU4xbdeNz/p44ARkW6dk\nIgQC+45N+P37Tm1H9syue08rt7+mV3f8Q7fvfn+v9w+Lt9Wf7fQFVeML6kvRWp3XuE1XhDfpsLj7\n4uhLsbZUzloroH+lBBF8xmh23b80MiUD4WN/vr5bcSgBBPRo4ZRmbeOcvW/2R6cEAOpa05xTt5Gk\nccY9E4rfGFfjqjqaKwJJW0KpmQZhFdruJ59libZzX33rDAx+Y2tEU5UOD7+vL+x+U2Xtzn8HNbfN\nMrQjWK7m1vNa3HIH59vP4lCRcAffo9beGXzAge7d+DaFE9Van9iua5yw+01jNDblfLW93fkqZIyO\nTDnHrW53TAHoep1yVVleXq61a9e6Xlu7dq3KysrSbIFs+cSfr6LWpzBfiO3WeU3bku+d2FyjU6Jt\naZXP5Lc8GbmxYaNmNWzQlZEq/SBcJX9rtsLhsQZ9q3Fr2/oFfdoyFyRd0rhFx8TbLpbqLb+ml4/V\ndkoY0MO9nPJU5TtORJNS0jb/zW7QhJSLp1da1220fK4LqR/ZDRrntHaYN0az7N2qTEmAe8XiOAP2\nWF84PJlf4JejU2pek781gNc/ulMjmqqS627Mb2n2a2TpzF0rdErtP3R8/ds6puFdqfX8N6KpSgc3\nfpzc5p3WHgqStCWvj+yUy60T61Yr1JqNF3Timlz3evI9Wz5tDZGFgO5nbcr56monookpM6L8xAnr\nkJR+B8+0m3VhnOJKDa2tIdCGLKCcwa1TyhluvPFGTZ8+Xccdd5yGDBmiqqoqvfrqq7rnnns6Y3f4\nHBYVDtA3mraptDV1bFb9Bn03skW2rL16Fswraplh44mCvsnZGU6I1elvO1er1hfUyERj8h/UDl9Q\n9xYNSW4fMrYujbQ9pZGkqOXTz+s/3Oe4/lQ0UC+H9j0VFtDd/NZfqq85TQpIKpDR/8Z3aL0VUL6R\nRqZcWFXJrwW+tj4lv/aX6ZHETkkt5Q2vxbfpXSuo3sbRYLWlg66xgvo/mlABSTXBMr1dNEqHRz6Q\nJI1s3qzvVz+uBn+Ra6aFen+h3m4NCDiWT+sKhydnZzg88oGGNm9VwvKrV2J3MjdoZ7BMbxaPTu4r\n6g/pzeKDNbF1xodBsR26vPoJ1QRKVZ4Iu6aXfLP4YEX30UsIOND92l+iryaaFZRUJqMViZ16RwGV\ny2hYyvnqffl1b7vpjkemlDfUydLmfUx3DKBrdUomwuDBg/XII4/omGOOUTwe1/jx47VkyRINGTIk\n88boUjv8ebq+fIzqU/4gD7Ob95o1YXrFWDW01oguKByg14NtNZx9nbjGpAQQtvuC+kHFuOT6knRS\ntFa92tVkVzpxHROv3+dPH3vvObuB7up1X56+E+itxtbbEL+kQ03CFUColk9fD/ZRY0p2z//4C/Rj\nf3lyraCkCSbuCiC8bwV0YbAPU2EB7SytOFob8tumFC5wYuobr00GEMK+Aj3Z58vJJoiStLJsgmpS\nehiU2WH1Tgkg7AqU6fE+U+S0u8l5ufxIvVcwLLmcZxLqH69xBRA+zB+kl8uP2J9fEcgZb1hBfddf\nrj1XlwFJE5RwBRDWK6CzA73V1K6coX9KEGFH59y6ABmZLP/kmk5rbRoKhXT66ad31sdjP1qVV6av\n956gbzdW60vROg20m+VYlqr8+VoaqtBDhQMVTrmIils+fb9inC5prNaZzTs1NNGUXP+FUC/NLxyg\niM/9T+uIWEP73QJI8ai/UK/78nR1okGnmGYNMQk5svSR5dezvgL93l+inft4+nJXoETLfCFdZTfo\nRCeq/rIVk6X3rYAe9xXqHn+xwvRDAPZiW3492efLGtv4kQ6LfKA+sToF5Gi3v0gbCgbrnyVjk30N\n9mj2h/Tnfmfo2Pp3NLJpk0oTEdmWT7XBMr1XOExvFh8sex/HqWP59GyfSVrfNEyHhz9Uv9gu5TtR\nxX1BbQ9W6J2ikVpfeBBTO6Jb+4uvUGusPF3nhHWyE9Vg2YrL0noroIetAt3rK3QFyvcoSrmFat+Q\nEUB2WMaYnAtuTOj/xWwPAegx3quryrwSgP3i130nZ3sIQI9x49al2R4C0KPEY5uzPYROc9eQi7O6\n/6s3Lcjq/ttjklUAAAAAANJwSBRzIScIAAAAAAB4QiYCAAAAAABp5OI0i9lEJgIAAAAAAPCEIAIA\nAAAAAPCEcgYAAAAAANKgnMGNTAQAAAAAAOAJmQgAAAAAAKRhsj2AHEMmAgAAAAAA8IQgAgAAAAAA\n8IRyBgAAAAAA0nCsbI8gt5CJAAAAAAAAPCETAQAAAACANJji0Y1MBAAAAAAA4AlBBAAAAAAADmBv\nvvmmLrnkEknSrl27NH36dF100UW68MIL9cknn0iSlixZovPPP18XXHCBli5dKkmqqanRZZddpmnT\npum6665TU1NTxn1RzgAAAAAAQBom2wPIYN68eXrqqadUUFAgSfrtb3+rr371qzrrrLP097//XRs2\nbFBBQYHmz5+vRx99VNFoVNOmTdOXvvQlzZ07V2effbbOP/983XffffrLX/6iSy+9tMP9kYkAAAAA\nAMABaujQobrrrruSy2vWrNG2bdt06aWX6umnn9axxx6rt956S0ceeaTy8vJUUlKioUOHav369Vq9\nerVOOOEESdLkyZO1cuXKjPsjiAAAAAAAQBqOTFZ/Mjn99NMVCLQVGWzevFmlpaV68MEHNWDAAM2b\nN0/hcFglJSXJdYqKihQOh12vFxUVqaGhIeP+CCIAAAAAANBNlJeXa8qUKZKkKVOm6O2331ZxcbEi\nkUhynUgkopKSEtfrkUhEpaWlGT+fIAIAAAAAAN3EUUcdpWXLlkmSVq1apVGjRmn8+PFavXq1otGo\nGhoa9OGHH+rggw/WxIkTk+suX75cRx11VMbPp7EiAAAAAABpONkewKd000036ZZbbtHixYtVXFys\n2bNnq6ysTJdccommTZsmY4x+9KMfKRQKafr06brpppu0ZMkSVVRUaPbs2Rk/3zLG5FyzyQn9v5jt\nIQA9xnt1VdkeAtBj/Lrv5GwPAegxbty6NNtDAHqUeGxztofQaX4x7KKs7v+nHy/M6v7bIxMBAAAA\nAIA0cu6pe5bREwEAAAAAAHhCEAEAAAAAAHhCOQMAAAAAAGkcaI0VOxuZCAAAAAAAwBMyEQAAAAAA\nSMOxsj2C3EImAgAAAAAA8IQgAgAAAAAA8IRyBgAAAAAA0nBksj2EnEImAgAAAAAA8IRMBAAAAAAA\n0iAPwY1MBAAAAAAA4AlBBAAAAAAA4AnlDAAAAAAApOFkewA5hkwEAAAAAADgCZkIAAAAAACkwRSP\nbmQiAAAAAAAATwgiAAAAAAAATyhnAAAAAAAgDYoZ3MhEAAAAAAAAnpCJAAAAAABAGkzx6EYmAgAA\nAAAA8IQgAgAAAAAA8IRyBgAAAAAA0nBorehCJgIAAAAAAPCEIAIAAAAAAPCEcgYAAAAAANKgmMGN\nTAQAAAAAAOAJmQgAAAAAAKThZHsAOYZMBAAAAAAA4AlBBAAAAAAA4AnlDAAAAAAApGForehCJgIA\nAAAAAPCETAQAAAAAANKgsaIbmQgAAAAAAMATgggAAAAAAMATyhkAAAAAAEjDobGiC5kIAAAAAADA\nEzIRAAAAAABIgzwENzIRAAAAAACAJwQRAAAAAACAJ5QzAAAAAACQBo0V3chEAAAAAAAAnpCJAAAA\nAABAGk62B5BjyEQAAAAAAACeEEQAAAAAAACeUM4AAAAAAEAahsaKLmQiAAAAAAAAT8hEAAAAAAAg\nDRorupGJAAAAAAAAPMnJTIT1dZuyPQSgx7AdYqtAV7lp20vZHgLQY4QCedkeAgB0SzkZRAAAAAAA\nIBfQWNGNcgYAAAAAAOAJmQgAAAAAAKRB8a8bmQgAAAAAAMATgggAAAAAAMATyhkAAAAAAEjDMTRW\nTEUmAgAAAAAA8IRMBAAAAAAA0iAPwY1MBAAAAAAA4AlBBAAAAAAA4AnlDAAAAAAApOFQ0OBCJgIA\nAAAAAPCETAQAAAAAANIwZCK4kIkAAAAAAAA8IYgAAAAAAAA8oZwBAAAAAIA0nGwPIMeQiQAAAAAA\nADwhEwEAAAAAgDSY4tGNTAQAAAAAAOAJQQQAAAAAAOAJ5QwAAAAAAKRhKGdwIRMBAAAAAAB4QiYC\nAAAAAABpMMWjG5kIAAAAAADAE4IIAAAAAADAE8oZAAAAAABIwxgaK6YiEwEAAAAAAHhCJgIAAAAA\nAGk4TPHoQiYCAAAAAADwhCACAAAAAADwhHIGAAAAAADScLI9gBxDJgIAAAAAAPCETAQAAAAAANIw\nNFZ0IRMBAAAAAAB4QhABAAAAAAB4QjkDAAAAAABpOJQzuJCJAAAAAAAAPCETAQAAAACANIwhEyEV\nmQgAAAAAAMATsf79IQAAGfxJREFUgggAAAAAAMATyhkAAAAAAEjDyfYAcgyZCAAAAAAAwBMyEQAA\nAAAASMMwxaMLmQgAAAAAAMATgggAAAAAAMATyhkAAAAAAEjDoZzBhUwEAAAAAADgCZkIAAAAAACk\nYQyZCKnIRAAAAAAAAJ4QRAAAAAAAAJ5QzgAAAAAAQBq53FgxHo9rxowZ2rx5s3w+n37xi18oEAho\nxowZsixLo0eP1s9+9jP5fD7dfffdeumllxQIBDRz5kyNHz/+M+2TIAIAAAAAAAegZcuWKZFIaPHi\nxVqxYoV+97vfKR6P67rrrtNxxx2nW2+9VS+88IIGDhyof/zjH3r44YdVXV2tq6++Wo8++uhn2idB\nBAAAAAAA0jA5nIkwfPhw2bYtx3EUDocVCAT0xhtv6Nhjj5UkTZ48WStWrNDw4cM1adIkWZalgQMH\nyrZt1dTUqFevXp96nwQRAAAAAAA4ABUWFmrz5s0688wzVVtbq3vvvVerVq2SZVmSpKKiIjU0NCgc\nDqu8vDy53Z7XCSIAAAAAANBDPPjgg5o0aZJuuOEGVVdX6zvf+Y7i8Xjy/UgkotLSUhUXFysSibhe\nLykp+Uz7ZHYGAAAAAADScIzJ6k9HSktLk8GAsrIyJRIJjRs3Tq+99pokafny5Tr66KM1ceJEvfLK\nK3IcR1u2bJHjOJ8pC0GSLGMyjCoLQvlDsj0EoMewHSfbQwB6DF9raiGAzpfnD2Z7CECPEm78KNtD\n6DSTB52c1f0v3/xC2vcikYhmzpypHTt2KB6P69vf/rYOO+ww/fSnP1U8HteIESP0y1/+Un6/X3fd\ndZeWL18ux3H0k5/8REcfffRnGg9BBKCHI4gAdB2CCEDXIYgAdK3uHEQ4IctBhJc7CCJkA+UMAAAA\nAADAE4IIAAAAAADAE2ZnAAAAAAAgDUc51wEgq8hEAAAAAAAAnpCJAAAAAABAGmQiuJGJAAAAAAAA\nPCGIAAAAAAAAPKGcAQAAAACANIyhnCEVmQgAAAAAAMATMhEAAAAAAEiDxopuZCIAAAAAAABPyETA\nPkWjVZ7XXWbl6bS8vq7XjnJiutIO6wQnqv6yFZWl962AnvAV6A/+YkUs4ldAJic5UT1n75LUcpyd\nHOizz/WOdmL6oRPRZBNLHm//sgJ6wsrXXb4ijjcgjVfj23WUiXe4zsX+Ci3xFyaXK42tGXaDznKa\nNUi2GuTTa1aeZvuLtcIX6uwhAweUE+0mPRPbJkl62RfSmaEBnrabZDfr2djW5NPO4oKD9rnexqZP\n1EdOh591Uqi/VvnyvQ4ZgAcEEbDf3Zio1yy7Xv6U10IyOsrEdZQd1yVOo84I9tFmi39+QDqFxtFv\n7d0Z15thN+jnTsNex9vRJq6jTcvxdlqgjzZb/rSfAfREPmM0LkMAob3RJq7n4js1MOWmJV+OzjbN\nOivRrGv9Zfqjv3h/DxU4IBUaR7+O13zq7ULG0V3xnRnTpQeYRMYAArC/GMoZXLiLwz4ts/LSvlcm\noyNSLrye9hUkfz/NadYv7PrkcqMsrbMCGmDs5EXXwSahhfEafTlYKVlWJ4weOLAVGUdP2TU6QokO\n1zvdadYvnYbkcqMsvWsFNDDleBsjW4vtGp3g78PxBqQYo4T2nL2aJP0jzXlv+54AnDG6P1GbPLZs\nSW9YQQ03CfWSkU/SHHu3XrFCescX7OzhAzmtyDh6JLZN4z9loE6SfpLYrdGm4/OfJB3uxJK/18qn\nt9Mcdw1UbwP7HUEE7FP78oRUD8RrkkGExb4C3RUoSb53faLthmaT/Dopr1KbrIB8xuiuRJ0udyKS\npC+YmCaZmF6xSP0EUk1yovovu06jZGdc9/854eTvm+TT5ECf5PF2t7Nb/+Y0SpK+YOI6wcT0Mscb\nkDTeabu5WWsFdWqwssP1TzVRHZ9yQ3ROoLf+z5evcuNoZXy7RslWUNIMp0GX+Hp11rCBnPdFu1n3\nxHdqpIdAQHuHOTFdm8ichSe5gwgv+vP1nQ6uXYHPiyke3QjN4VM51WnWRa03Jlvk0zWBiuR7ecZo\nkokml//oL9Km1pIFx7L0q0Cp67OOSfnjD/R0ecbor4ldesne5SmA0HK8tR1D9/rcx9svfSWu9Y/5\nDE+DgO4s9Qnphx7K677hNCV/X2UF9X+tNdZ1lk9zU0oYvuI0K8TFJnqgPGP0ZHSr/i+29TMFEHzG\n6A+xnfKax3N4yjlwg0X2D9CVyESAZ4XG0d3x2uTyjEC5dqc0bPPL6IeBCg0wtgYZW6+0azAVkTuV\nOkhtEZBUIKNTU4Jw/2OFZCR9NeW1VH4ZTfeXt5Yu2Hq5XSp2++Mtj+MNcDk8JYiwwcPl0NEpNyzt\nSx9WpiwXy2isieuNDsoCge6oQI5OdpqTy8/6CmQkfSUlANeRHybqdVTrcVYjn3pl6HdweEo20Qb6\nbAFdiiMOnl1rh3VQ6xPS1VZQf0nphSBJTZZPf/IXpd3+pJQTiyRt5A8+sJcd8unXvmLd6SvS/XZd\n2vWaLJ8etArTvj+lXfDhIxorAi6pmQjHmpj+Gd+m0SahsHx6xcrTf/hLtMbXEgiwjNHBKU9Wq9sd\nT+0blx5iEnpDBBHQM+2UT7cHyzTXX6p74zs9bTPMieuWRMs5b5d8mhMo068StWnXzzeORqYcw2fZ\njfpRYreGmoRq5deL/nzdHijXh/QnwX7i8DDGhbs4eBI0Rj+w2+qvf+sv+VRN2oqNo5+nNFyMSnqR\nqbCApJik6b4yzfcVqvlzNkAsNo5us9v6k0QlvUA/BCCpT0rzUUmuLKACOTrPNOuriWZd6S/Xg/4i\nlcgo9Qja3S7TJ9xuOdMTVKA7isnSNcHeWuQvUvOnnFr4zvguFbXepN0crMh4uzbOxF03MV9NyXYY\nIFsX2RGdazfq4rxKPedPH3AH8NnQEwGeXOg0qn/rRdGH8uuJdlkIHck3Ro/Ed+mQlKc4/+0r0k6e\njAJJTZZP8/xFnzuAkG+MHrdrNDZlZof7fYUcb0CK9h3jbUmvW0H9S4Hk7X9A0ly7Tsc6seTNzR7x\ndkGD9svFPLFCD9Rk+fRAoORTBxCmJcLJMojlvnwtCJRk2MLdVFFqCZb/08pzZbkWyeih2A4Nc+gJ\nhM/PGJPVn1zTaUGEV199VbW16dOQcGC5KiUL4V5/sYzHG51C4+iJ+E6dlPKU5xP59dNA2X4fI9DT\nFRpHT9m7dFJK7fYn8usWX2kHWwE900tWnjbJr79bQR0a7Kfjgn11WF4/fSXQW3uOoICkm+16ZTrj\n5d7lHXBgqDS2fh2vkSQ1S7om2NvTdo2ytNIX0jb59FdfgcbmD9GX8wfqsPzBuiLlM0pkdF2ivoNP\nAvBZdFoQwRijG2+8sbM+Hl3oCCeWnNJRkp7we8tCKDGOnm4XQKiXpanB3qr/lFFqAB0rMY6etWs0\nJSWAUC9LXw9UcLwB7bzoy9dpwUqNzOuvycG+rqZsL/jytcjXlv58komq/XPM9o2B2y+3L28AsG+/\nje9S79b8n98GyvWBxx4GDweKdVpogEYWDNXUUD9tT8m2Wxgo0bLW2VMk6RSPjR0BeNdpPRHi8bii\n0X13FceB5ZyUP76vW0F94qEhYolx9Gx8h45NCT7slqWvBfvoDR/NpoD9qcQ4+l97117H29n+3nqd\nDvHAp/ZmynRx+WqZPSUuJaeeK2kXNChtt1xDtSiQ0el2o75ht0wbvt4Kas5+zFJ9y8rTiWopkRj8\nGaabBNqjsaJbpwUR/vznP+v666/vrI9HFzrZaQsG/TUlsptOyBg9Ht/puqHZKZ/ODvbR6wQQgP0q\nZIyesmv2Ot7OCvTSGgIIQIeKjaOgpNp22Trtp0RtkqWPFNDBrb1GBhjb9f7AdsvrmX0IyOjc1gCC\nJB1i4qpt/jjtuuGmjZKkM/P66eWUjNgyY8uRpYYOjuH2PUsAfH6dFiqPRCIaP358Z308ukjIGB2Z\nkh7t5abknkStTkjZZod8Oi1YSQAB6AR/tOv2Ot5OCfQmgAB04C/xXdoV26KaeLUWJmr2ev/olKDc\nVvm0w/JrTUqa9ReNu6nbsSnLYVlaZzGtHJCJ9Tme7L7UvEXbmz7W5uZN+vf43sfwkSkPwN7heMR+\nYLL8v1zTaUGEyy+/XMuXL++sj0cXGWvirpmu12SoVTvfbtRFTltkOS7pvGBvvcM8vcB+93WnSReb\ntnKjuKRz/L30NhdMQIc+sALJkoRTTFSX2pHke2c7TTo/pYxvT3+Ep6y2TLyjTFxntHaTLzWOfpiy\n/bO+fEU/5ywrQE/wLyuol32hff78q102z57X61ozDjb6AipsPYYvssM6JSWr4YpEvSuwtzhQ3AXf\nBuhZLJODc0aE8odkewho9XW7UYtan9LUyVK/0KD0Kxuj1fFtOiyl9qxWlt5Kc0OzyF+kB/1F+3W8\n+PRsh/nMc9X9iVp9pzVIsMzK08mBPm1vGqPXEzt0uLwdbwt8BfpvH8dbtvm4ucwJA4ytN+PbVJ7y\ndOd9+WXL0iEpx1SVfJoY7Kc6yye/MfpnYrsObT3H7ZkWcrhJqHfr5yQkHRfoq7UEznNCnp//H7Lt\n3tgOXdwaZHvZF9KZoQGetrso0aA/xncll4sLDnK9f5gT0/LoFteDrnetoApkNDzlOvQtK6gTQwMV\n529vlwg3fpTtIXSa8f2/kNX9v7X11azuvz2K9tCh/il1npnmmT/WxFwBBEmqkNGJ7dI+91hpQp9/\ngEAPdZyJuwIIUsfH2wpDeQOwR7Xl19RAbz2c2JUMJIyWu6/BZvl0dqBP8smnbVm6MNBL/xvfqYFy\n5Je77EGS/p+/jAAC0AXe9uXpimAf3RPfqT05QuPaHY/rraDOD/UjgID9wsm95+5ZRftgdKgo5SlN\nTYbGNF909n3zAmD/a1+TDeDTWeYL6chgP/3OV6T1CqhJLf0M1loB/cpXognBfnq3XUDgPSuoicG+\n+k9fsT6QX1G1NDJ91grp5EAfzfWTNg10lYcDxfpiaKAe8BdrgxVQVC0zE6228nRzoEJfCg3QVpqc\nAp2Ccgagh6OcAeg6lDMAXYdyBqBrdedyhkP7HZfV/b+z7bWs7r89MhEAAAAAAIAnBBEAAAAAAIAn\nFAoBAAAAAJAGjRXdyEQAAAAAAACeEEQAAAAAAACeUM4AAAAAAEAaRpQzpCITAQAAAAAAeEImAgAA\nAAAAadBY0Y1MBAAAAAAA4AlBBAAAAAAA4AnlDAAAAAAApEFjRTcyEQAAAAAAgCdkIgAAAAAAkAaN\nFd3IRAAAAAAAAJ4QRAAAAAAAAJ5QzgAAAAAAQBo0VnQjEwEAAAAAAHhCJgIAAAAAAGkY42R7CDmF\nTAQAAAAAAOAJQQQAAAAAAOAJ5QwAAAAAAKTh0FjRhUwEAAAAAADgCZkIAAAAAACkYQyZCKnIRAAA\nAAAAAJ4QRAAAAAAAAJ5QzgAAAAAAQBo0VnQjEwEAAAAAAHhCJgIAAAAAAGnQWNGNTAQAAAAAAOAJ\nQQQAAAAAAOAJ5QwAAAAAAKThUM7gQiYCAAAAAADwhEwEAAAAAADSMEzx6EImAgAAAAAA8IQgAgAA\nAAAA8IRyBgAAAAAA0jA0VnQhEwEAAAAAAHhCJgIAAAAAAGk4NFZ0IRMBAAAAAAB4QhABAAAAAAB4\nQjkDAAAAAABp0FjRjUwEAAAAAADgCZkIAAAAAACk4ZCJ4EImAgAAAAAA8IQgAgAAAAAA8IRyBgAA\nAAAA0qCxohuZCAAAAAAAwBMyEQAAAAAASMMRmQipyEQAAAAAAACeEEQAAAAAAACeUM4AAAAAAEAa\nNFZ0IxMBAAAAAAB4QiYCAAAAAABpOGQiuJCJAAAAAAAAPCGIAAAAAAAAPKGcAQAAAACANIwoZ0hF\nJgIAAAAAAPCETAQAAAAAANKgsaIbmQgAAAAAAMATgggAAAAAAMATyhkAAAAAAEjDUM7gQiYCAAAA\nAADwhEwEAAAAAADSYIpHNzIRAAAAAACAJwQRAAAAAACAJ5QzAAAAAACQBo0V3chEAAAAAAAAnpCJ\nAAAAAABAGmQiuJGJAAAAAAAAPCGIAAAAAAAAPKGcAQAAAACANChmcCMTAQAAAAAAeGIZukQAAAAA\nAAAPyEQAAAAAAACeEEQAAAAAAACeEEQAAAAAAACeEEQAAAAAAACeEEQAAAAAAACeEEQAAAAAAACe\nEEQAAAAAAACeEETA5/Laa6/p6KOPVnV1dfK1O+64Q4899lgWRwV0f/fdd58mTZqkaDSa7aEA3dam\nTZt09dVX65JLLtGFF16oWbNmKRwOZ3tYAABkFUEEfG7BYFA/+clPZIzJ9lCAHuPpp5/WWWedpWee\neSbbQwG6pebmZl155ZW6/PLLNX/+fC1evFgTJkzQDTfckO2hAd3SsmXLdPHFF+uKK67QSy+9pBUr\nVmjFihXZHhaAfSCIgM/t+OOPV1lZmRYuXJjtoQA9wmuvvaahQ4fqwgsv5LgDOslLL72kY445RhMm\nTEi+dt5556m2tlabNm3K4siA7sm2bT344IO64oordP/99+uBBx7Q2LFjsz0sAPsQyPYA0D3MmjVL\nU6dO1aRJk7I9FKDbe/jhhzV16lSNGDFCeXl5evPNN103OgA+v02bNmno0KF7vT548GBt2bJFQ4YM\nycKogO5rypQpkqSJEydq/vz5WR4NgI6QiYD9oqKiQjNnztSMGTPkOE62hwN0W7t379by5cv10EMP\n6Xvf+57C4bAWLFiQ7WEB3U6/fv1UVVW11+sbN27UwIEDszAiAAByA0EE7DdTpkzR8OHD9fjjj2d7\nKEC39dRTT+nrX/+6HnjgAd1///1asmSJVqxYoZqammwPDehWTj75ZK1cuVJvvfVW8rWHH35YvXr1\nIgsBANCjEUTAfnXzzTcrPz8/28MAuq2HH35Y55xzTnK5oKBAp512mpYsWZLFUQHdT1FRke69917N\nnTtXF154oaZOnao333xTc+bMyfbQAADIKsvQUh8AAAAAAHhAJgIAAAAAAPCEIAIAAAAAAPCEIAIA\nAAAAAPCEIAIAAAAAAPCEIAIAAAAAAPCEIAIAoNuqqqrSYYcdpnPOOUfnnnuuvvKVr+i73/2utm7d\n+pk/87HHHtOMGTMkSd///ve1bdu2tOveeeed+uc///mpPn/MmDF7vXbXXXfprrvu6nC7KVOmqKqq\nyvN+vHwmAABAewQRAADdWt++ffXkk0/qiSee0DPPPKMxY8bo9ttv3y+fPW/ePPXr1y/t+6tWrZJt\n2/tlXwAAALkgkO0BAADQlY477jjNmTNHUsvT+/Hjx2vdunVatGiRXn75Zf3pT3+S4zg69NBD9bOf\n/UyhUEhPPPGE7rnnHhUXF2vQoEEqLCxMbv/QQw+psrJSP//5z7V69WoFg0FdeeWVisVievvtt3XL\nLbfo7rvvVn5+vmbNmqW6ujrl5+frpz/9qcaNG6eqqir9+Mc/VmNjoyZMmJBx/AsWLNCTTz6ppqYm\nBYNBzZ49WyNGjJAk3f3/27mbkKjWMIDj/9GpoZwg0BatDArSsOgDIYysbcIoFLkoI1ctok3IEME0\nGRr0JUEUbYoQsbJFZaVhzi76XhQUFBShtEglC8IxsmbOXUTn3hAvXuhu8v9bnXOeOed959kc5pnn\nfU+f5tWrV8RiMQ4dOkRZWRkfPnwgnU4zNDREJBKhqamJqqqq/y/BkiTpj2YngiRpxvj27Rt9fX2s\nXLkyvFZdXU1fXx8fP37kypUrXL58me7uboqLizl//jzDw8OcOHGCzs5Ourq6yGazk57b0dHB+Pg4\nt2/f5sKFC5w5c4aamhoqKipobW1l6dKl7Nu3j2QyybVr12hpaWHv3r0AtLS0sHnzZrq7u1m9evW/\nzn9sbIxMJkNHRwe3bt1i48aNdHZ2hvHS0lKuX7/O7t27wyUXhw8fZsuWLVy9epWzZ8+STqcZGxv7\nHemUJEkzkJ0IkqQ/2sjICHV1dQBMTEywYsUKmpqawvjPf/8fPXrE4OAg9fX1wI+Cw7Jly3j69Cmr\nVq2ipKQEgEQiwcOHD38Z48mTJ9TX11NQUMCCBQvo6en5JZ7NZnnx4gX79+8Pr42Pj/Pp0yceP35M\nW1sbALW1taRSqSm/Szwep62tjZ6eHgYGBrh79y7l5eVhfOvWrQBs2LCBZDLJ58+fuX//Pm/fvuXU\nqVMAfP/+nXfv3v2HDEqSJP3NIoIk6Y/2c0+EqcRiMQByuRybNm0Kf8Rns1lyuRwPHjwgCILw89Ho\n5FdnNBolEomE54ODgyxcuDA8z+fzzJ49+5d5DA0NMX/+fIDw+ZFIhIKCqZsE379/z44dO2hoaKC6\nupqSkhJevnwZxgsLC8PjIAiIRqPk83na29vDsUZGRiguLiaTyUw5jiRJ0lRcziBJEj/2Sujv72d0\ndJQgCGhubqa9vZ01a9bw7NkzhoeHyefz9Pb2Trq3srKS3t5egiBgdHSUhoYGJiYmKCwsJJfLMW/e\nPBYtWhQWEe7du8f27dsBqKqq4saNGwDcuXOHr1+/TjnH58+fU1paSmNjI8uXLyeTyfyycePNmzcB\n6O/vZ/HixcydO5e1a9dy8eJFAN68eUMikeDLly+/J2mSJGnGsRNBkiSgrKyMPXv2sHPnTvL5POXl\n5ezatYtYLEYqlaKxsZE5c+awZMmSSfdu27aN1tZWamtrAThw4ADxeJz169dz8OBBjh49yvHjx2lu\nbubcuXPMmjWLkydPEolESKfTJJNJurq6qKiooKioaMo5rlu3jkuXLlFTU0MQBFRWVvL69eswPjAw\nQF1dHUVFRRw5cgSAVCpFOp0mkUgAcOzYMeLx+O9MnSRJmkEiwT97NCVJkiRJkqbgcgZJkiRJkjQt\nFhEkSZIkSdK0WESQJEmSJEnTYhFBkiRJkiRNi0UESZIkSZI0LRYRJEmSJEnStFhEkCRJkiRJ0/IX\nsoEI3TiVwpgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_confusion_matrix(oof,train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_importances(model_name,feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(12, 16))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('{0} Features (avg over folds)'.format(model_name))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAR4CAYAAAAblHcQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XtYVWXe//HP3pwEAY+JpVbgKZPU\nxBK1fpaHSlPxxGGcQB9tTFNJGx3PiqiZaYnpeEgj8whaFI6NVtrkTE+pyWQKk5laFmpIiSgeQNj7\n90ePezIOia7Fxu37dV1ek2uvdd/f9dWa/eG+194Wu91uFwAAAADghlmdXQAAAAAAuAoCFgAAAAAY\nhIAFAAAAAAYhYAEAAACAQQhYAAAAAGAQAhYAAAAAGISABQAo0e7du9WjRw9J0sKFC/Xuu++WeX5K\nSoqeeeaZEl/7+OOPtXDhwt+dMzo6Wtu2bSt/saVYtGiRQkNDFRYWdtWvAwcOXPeYU6ZMUXp6umE1\nlsdXX32liRMnOmVuM+Tl5SkqKkpPPvmkPvjgg1LPW7RokeLj40t87f7771dmZmaZczz99NO6dOnS\nDdcLANfC3dkFAAAqv+eee+6Grj9w4IByc3MNqqZ8unfvrmnTphk23qeffqrIyEjDxrtWNptNkydP\n1tKlSyt8brN89dVX+vnnn/Xhhx+aNoevr6969OihhQsXavz48abNAwBXELAAAL9rwoQJaty4sYYM\nGaKdO3dq/vz5slqtatasmT799FOtX79ekpSdna2hQ4fq5MmTcnNz08svv6y8vDwlJSWpqKhIfn5+\nio2N1UsvvaSPPvpIfn5+atGihY4cOaI1a9ZIkj788EO99tprunTpknr27Knhw4crMzNTAwcOVIcO\nHZSenq6ioiLFxsYqOTlZR48eVXBwsF555RVZreXbmLF06VJ98MEHstlsqlevnqZPn66AgADt27dP\n8+bNU0FBgbKzs9W+fXu98MILWrBggU6dOqWxY8fqpZde0vz58/XHP/5RTzzxhKRfVuCu/D44OFid\nO3fWwYMHNX/+fPn4+Gj27Nk6c+aMioqKFB0drf79++v8+fOaOHGijh07JqvVqubNmys+Pr7YvWzd\nulX169dXQECAJOkf//iHli9froKCAp0+fVq9e/fW6NGj9ec//1nNmzfX4MGDJUnr16/Xnj17lJCQ\noNdee01vvfWWqlatqjZt2mjHjh366KOPivUlOTlZa9askdVqVe3atTV16lTVrl1bHTt21Pvvv6/b\nbrtNkhQeHq6RI0eqXbt2mj9/vj7//HMVFRXp3nvv1ZQpU+Tr66tOnTqpRYsW+vrrr/X888+ra9eu\nkqSjR49q0qRJysrKUlhYmJKTk/XJJ59o8eLFstlsqlq1qiZOnKgWLVpcVdvevXs1c+ZMWSwW3Xff\nfbLZbJJUZh+7deum+fPna8iQIapdu3a5/o4AQHmxRRAAcM1ycnL0l7/8RfPmzVNqaqratm2rrKws\nx+s//PCDJk+erL/97W9q06aNXn/9dbVs2VJRUVHq3r27xowZo02bNikjI0NbtmxRUlKSfvjhh6vm\nOH/+vDZu3KiNGzdq8+bN2rlzpyQpMzNTHTt2VEpKilq1aqXZs2frlVde0Xvvvae9e/dq3759Jdb8\n97///artgYsXL5Ykvfvuuzp06JA2bdqk1NRUdezYUVOmTJEkrV69WrGxsdq0aZPee+89ffTRR0pP\nT9eYMWNUp04dzZ8/Xy1btiyzV5cvX9ajjz6q999/X82aNVNsbKz+/Oc/KyUlRWvXrlViYqL27dun\nDz/8UOfPn1dqaqreeustRx9/6/3339cjjzwiSbLb7UpMTNSLL76olJQUJScn67XXXtPp06cVHh6u\nd955x3HdO++8o4iICP3rX/9SSkqK3nrrLaWkpOj8+fMl1v3ZZ59p5cqVWr16tTZv3qwePXpoxIgR\n8vX1VdeuXbV582ZJ0pEjR/TTTz/p4Ycf1muvvSY3NzelpKRo8+bNjh5d0bhxY23dutURriQpKChI\ns2bN0p133qnU1FQdP35c06dP16JFi7R582bFxsbq2WefVV5enuOagoICPffcc5owYYLeffddtW3b\n1rH1r6w+enl5KTg42PF3CQDMxAoWAOCa7d27Vw0bNtQ999wjSerTp49mzZrleL1Fixa66667JEnN\nmjUrcevXzp07FRYWJi8vL0lSZGSkY/VKkvr37y93d3f5+vrq8ccf16effqqGDRvKw8NDnTp1kiTd\neeeduv/+++Xr6ytJqlOnTqlbEEvbIviPf/xDBw4cUL9+/ST9sgXv4sWLkqQXX3xR//znP7Vs2TId\nPXpU+fn5unDhQvmaJalNmzaSpO+++07ff/+9Jk2a5Hjt0qVL+s9//qOHH35YCxYsUHR0tNq3b6+B\nAwc6evhrR48eVUxMjCTJYrFo2bJl+vjjj7VlyxYdOXJEdrtdFy9eVNu2bZWfn68DBw7I29tbp0+f\nVrt27TR79mw98cQT8vf3lyT98Y9/1K5du4rN869//Uvdu3dXzZo1JUl9+/bV7NmzlZmZqfDwcM2Y\nMUNDhgzR22+/rX79+slqterjjz/WuXPn9Omnn0r6JVzWqlWrWB/KsmvXLoWGhqpBgwaSpHbt2qlm\nzZpXPe926NAhubu7q127dpKkHj16OP5sQ0JCyuxj/fr19e233/5uHQBwowhYAIBr5ubmJrvdftWx\nX29lc3f/7/+tWCyWYuf+9pzfXn9ljivsdrvjfA8PD1ksFsdrHh4e13EH/2Wz2fT0009rwIABkn5Z\nHbkS0p566ik1bdpUDz/8sLp166Yvv/yyxHu5UuMVly9fvuo1Hx8fSXJsj0xNTXW89tNPP8nPz09e\nXl768MMPtXv3bu3atUv/8z//o/j4eEeYvOLX/bxw4YL69OmjLl26qE2bNurXr5+2b98uu90ui8Wi\n/v37KzU1VR4eHurfv78sFovc3d2vqvXXff5tX0q6x8LCQrVp00aFhYXav3+/tmzZouTkZMc1kyZN\nUseOHSX9sgqZn59frA9lsdlsV/35/nre3x77tSt/Pxo0aFBmHz08PEq9ZwAwElsEAQDXrHXr1vru\nu+908OBBSb9sWzt79myxN8a/5ebm5nij3LFjR23evFkFBQUqLCy8ajub9MvWPbvdrtzcXG3dulUP\nP/ywKffy0EMP6a233nJsQVu4cKH+8pe/6OzZszpw4IDGjh2rxx57TD/++KO+//57R/D49b38eoXl\n8OHD+vrrr0ucKzAwUFWqVHEErJMnT6pHjx5KT0/X+vXrNXHiRD300EMaN26cHnroIf3nP/8pcYzv\nv/9eknTs2DHl5eVp9OjR6tSpk3bv3q2CggJHjX369NFHH32k999/X3379pX0S98/+OADnTt3TpIc\n2+h+6+GHH9bf//53nT59WpL09ttvq3r16o7VoPDwcM2cOVNNmzbV7bff7ujlunXrHDVMnTpVr7zy\nyjX/WUi/rFh98sknjm19n332mU6ePHnVVsymTZvKbrc7tvrt2LHDEYp/r4+ZmZkKDAwsV00AcD1Y\nwQIAXLPq1avrlVde0fjx42W1WhUcHCx3d3d5e3uXeV1oaKjGjh2rmTNnavLkyfr222/Vu3dv+fj4\nqH79+ldd7+fnp759++rSpUt66qmnFBoaWubHcF+v8PBwZWVlKSIiQhaLRbfffrtefPFF+fv7a+jQ\noerTp498fHwUEBCg1q1b69ixY2rXrp26du2qcePGKS4uTsOHD9eECRO0c+dOBQUFlboVztPTU0uW\nLNHs2bO1cuVKFRYW6rnnnlNISIiaNWumPXv2qHv37vL29tbtt9+u6OjoYmM8/vjj+vDDD9WvXz81\nbdpUjzzyiLp16yZPT081adJEjRo10rFjx3TnnXfqtttu07333qvCwkLHh2K0a9dOERERioyMVJUq\nVdS4ceMS/9w6dOigQYMGaeDAgbLZbKpZs6aWL1/uWGns3bu3XnnllasC1LPPPqu5c+eqT58+Kioq\nUrNmzTRhwoRy/Xk0atRI06dP18iRI1VUVKQqVapo2bJl8vPzc5zj4eGhv/71r4qLi9Mrr7yiZs2a\nObYi9u7du9Q+FhQUaN++fZo9e3a5agKA62Gxl7bnAQCA38jLy9OSJUs0atQoeXt7KyMjQ88884z+\n9a9//e4q1hWffPKJfv75Z4WFhUmSZs2aJS8vL40bN87M0m96RUVF6tu3r1577TVHaCqPAwcO6Isv\nvnA8x/XGG2/oyy+/VEJCgtGlVjopKSn65ptv+Jh2ABWCgAUAKJcFCxZo+/btcnd3l7u7uyZOnHhN\nH2JwRVZWliZMmKCffvpJNptN99xzj+Li4q5aqUDJ9u/fr3Xr1mnu3LnlvjYvL0+TJk3S0aNHHSt2\nM2fOvK6wdjM5f/68Ro0apcWLF1/Ts2AAcKMIWAAAAABgED7kAgAAAAAMQsACAAAAAIMQsFxMRkaG\ns0twOfTUHPTVHPTVHPTVePTUHPTVHPTVeK7cUwKWi7l06ZKzS3A59NQc9NUc9NUc9NV49NQc9NUc\n9NV4rtxTAhYAAAAAGISA5WK8vLycXYLLoafmoK/moK/moK/Go6fmoK/moK8oDz6m3cWc2bJDtrN5\nzi4DAAAAlZzV31fVe3R2ytxpaWkKCQlxytxmc3d2ATCW7WyeinLPObsMAAAA4JbEFkEAAAAAMAgB\nCwAAAAAMQsACAAAAAIMQsAAAAADAIAQsAAAAADAIAQsAAAAADELAAgAAAACDELAAAAAAwCAELAAA\nAAAwCAELAAAAAAxCwAIAAAAAgxCwAAAAAMAg7s4uAKW7fPmyJk2apOPHj6ugoEDDhw9X586dnV0W\nAAAAKsClwsu6XFRk2vhul9zllptr2vhlyc/Pd8q8FYGAVYlt3rxZ1atX17x585STk6M+ffoQsAAA\nAG4BiV98pg+PHJTd7InWrTB7hhJZLBb16tVLsbGxTpnfTASs35GSkqK3335bNptNJ06cUKNGjRQU\nFKTJkycXO3fHjh3avn275syZI0nq3bu3Xn/9dW3dulUffPCBCgsL5efnp0WLFmnLli2OcWNjY9Wu\nXbti4z3xxBN6/PHHHb93c3Mz70YBAABQaXxw5KCzSzCV3W5XamoqAetW5e/vr6VLl+qee+7Ru+++\nqxo1apR43iOPPKJ58+bpwoULOnz4sO68807VqFFDZ86c0apVq2S1WjVkyBAdOHDgqnFLU7VqVUlS\nXl6eYmNjNXr0aONvDgAAAJXOYw3v0YdHvpbd/DUsp7iyguWKCFjXIDAwUJJUo0aNUsOV9MsK0+OP\nP64PPvhA+/btU3h4uKxWqzw8PPT888/Lx8dHP/74owoLC68atywnT57UiBEjNGDAAPXs2dOYGwIA\nAEClNvj+dhpwXxtzn8Hy91X1ft1MG78sGRkZat++vVPmNhsB6xpYrdar/rcs/fv31/Tp05WTk6Np\n06bp4MGD2r59uzZt2qSLFy+qb9++stvt1zTeTz/9pMGDB2vatGklbiEEAACA66ri7qEq7h6mje9W\nxVvVqlUzbfyyeHl5OWXeikDAMliDBg0kSZ07d5bVatVdd90lb29v9e3bV56enrrtttt06tSpaxpr\n2bJlOnv2rJYsWaIlS5ZIklasWKEqVaqYVj8AAACA62exX1lOgUs4vT5VRbnnnF0GAAAAKjm3an6q\nOSDMKXOnpaUpJCTEKXObjRWs67Bjxw6tWrWq2PGYmBh17dq13OPFxcXpyJEjxY6zWgUAAADcXFjB\ncjGsYAEAAOBasIJljt//1AYAAAAAwDUhYAEAAACAQQhYAAAAAGAQAhYAAAAAGISABQAAAAAGIWAB\nAAAAgEH4HiwXY/X3dXYJAAAAuAnwvtEcBCwXk3l3gIKDOzu7DJeSnp6u4OBgZ5fhcuirOeirOeir\n8eipOeirOegryoMtgi4mPz/f2SW4HHpqDvpqDvpqDvpqPHpqDvpqDvqK8iBgAQAAAIBBCFgAAAAA\nYBACFgAAAAAYhIAFAAAAAAYhYAEAAACAQQhYLsbLy8vZJbgcemoO+moO+moO+mo8emoO+moO+ory\nsNjtdruzi4Bxzmx5R0Xncp1dBgAAAG4Bbn7VVL1Hn3Jfl5aWppCQEBMqcj6+aNjFFJ3LVVHuGWeX\nAQAAANyS2CIIAAAAAAYhYAEAAACAQQhYAAAAAGAQAhYAAAAAGISABQAAAAAGIWABAAAAgEEIWAAA\nAABgEAIWAAAAABiEgAUAAAAABiFgAQAAAIBBCFgAAAAAYBACFgAAAAAYxN3ZBVyRmZmpXr16qXnz\n5o5jbdu21ciRI695jOTkZPXt21ceHh5mlFjM/v37lZCQILvdLpvNpo4dO2rw4MHavXu3Ro8erUaN\nGslut6uwsFAxMTHq3r17qWOdOXNGjz/+uJo0aSJJ6tKliwYOHKhZs2bp3//+t6pWrSpJWrJkifz8\n/Crk/gAAAHDzulRYqMtFNlPncLuUL/fc3HJfd/78eeVex3Wenp7y9vYu93UVqdIELElq1KiR1qxZ\nc93XL1++XL179zaworLFx8dr7ty5atiwoS5fvqyoqCiFhoZKkkJDQ7VgwQJJv/wFio6OVmBgoJo1\na1biWP/5z3/Uo0cPTZ069arjGRkZWrlypWrWrGnuzQAAAMBlvPHvA/rwyHeyV8RkazdWxCySJKvV\nqp49eyo2NrbC5iyvSr9F8OWXX1ZUVJQiIyO1detWSdKePXsUExOjmJgYRURE6Ntvv9WmTZuUnZ2t\nMWPGaPfu3RozZoxjjA4dOkiSJkyYoGHDhikqKkq5ubkljr1u3TqFh4crMjJSc+fOLbO2O+64Q+vW\nrVN6erqsVqs2bNige++9t9h5VatWVWRkpLZt21bqWOnp6crIyNBTTz2l2NhYnTp1SjabTceOHdO0\nadMUFRWlt956q9z9AwAAwK3ng4oKVxXMZrMpNTXV2WWUqVIFrMOHDys6Otrxa/PmzcrMzFRSUpJW\nr16tZcuW6ezZs/rmm280b948rV69Wp06ddK2bdsUHh6u2267zbFqVJrQ0FAlJSVp3759JY6dkpKi\nyZMnKzk5WQ0aNFBhYWGpY73wwguqVauW4uLi1L59e82dO1cFBQUlnlurVi3l5OSUOlZQUJBiY2O1\ndu1adenSRbNmzdKFCxf01FNPad68eVq5cqXWr1+vgwcPXlszAQAAcMt6rOHdsji7CBNYrVaFhYU5\nu4wyVeotgitWrFBGRoaio6MlSYWFhTpx4oQCAgI0e/Zs+fj4KCsrS61bty5zXLv9v/k9MDBQknTo\n0KESx54zZ44SExM1f/58tWrV6qprfy0/P18ZGRkaMWKERowYoZycHE2aNEnJycmO56h+7cSJE6pb\nt26pNYaGhjr2k3bt2lWvvvqqvL29FRMT4zgeGhqqgwcP6p577inzfgEAAHBr+5/W9+kPLZqZ/wyW\nfzXV6BtV7uu+/PJLtWzZstzX8QzWDQoKClLbtm01c+ZM2Ww2LVmyRPXr19egQYO0fft2+fr6avz4\n8Y4QZLFYZLPZ5OXlpezsbEnS8ePHr3qAzmKxlDl2QkKCZsyYIS8vLw0ZMkRffPGFHnzwwWK1WSwW\njRs3TitXrlSTJk1Uo0YN1atXT56ensXOzcvL06ZNm7Rw4cJS73XKlCl67LHH1L17d3322Wdq3ry5\nvvvuO40ZM0bvvPOObDab/v3vf6tPnz431FMAAADcGqq4u6uKye/23ap4qVq1auW+rmrVqtd13c2g\nUgesTp06ac+ePRowYIAuXLigLl26yNfXV2FhYYqIiJC/v79q166tU6dOSZLatGmjoUOHKjExUX5+\nfgoPD1fDhg1Vv379ax67adOm6t+/v2rUqKGAgIBSk7Wnp6cSEhI0bdo0FRUVyWKx6L777lO/fv2U\nlpamXbt2KTo6WlarVUVFRRo1apSCgoJKvdc///nPmjRpkjZs2CBvb2/NmjVLderUUc+ePRURESEP\nDw+FhYWpcePGxjQXAAAAgOEs9tL2wOGm9POGVSrKPePsMgAAAHALcKtWXbX+MKjc16WlpSkkJMT4\ngiqBSr2CVRns2LFDq1atKnY8JiZGXbt2LddYBQUFGjJkSLHjgYGBio+Pv94SAQAAAFQSBKzf0blz\nZ3Xu3NmQsTw9PW/oe74AAAAAVG6V6mPaAQAAAOBmRsACAAAAAIMQsAAAAADAIAQsAAAAADAIAQsA\nAAAADELAAgAAAACD8DHtLsbNr5qzSwAAAMAtgveexRGwXEzm3Y0VHBzs7DJcSnp6Oj01AX01B301\nB301Hj01B301B31FebBF0MXk5+c7uwSXQ0/NQV/NQV/NQV+NR0/NQV/NQV9RHgQsAAAAADAIAQsA\nAAAADELAAgAAAACDELAAAAAAwCAELAAAAAAwCAHLxXh5eTm7BJdDT81BX81BX81BX41HT81BX81B\nX1EeFrvdbnd2ETDOT5sXq+jsz84uAwAAAOXg5l9LtXuNdHYZFSYtLU0hISHOLsMUfNGwiyk6+7MK\nc085uwwAAADglsQWQQAAAAAwCAELAAAAAAxCwAIAAAAAgxCwAAAAAMAgBCwAAAAAMAgBCwAAAAAM\nQsACAAAAAIMQsAAAAADAIAQsAAAAADAIAQsAAAAADELAAgAAAACDuDu7AAAAAKCyuVRo0+Uie4XN\n537psqrk5lbYfKXx9PSUt7e3s8u4qVWKgJWZmalevXqpefPmjmNt27bVyJEjr3mM5ORk9e3bVx4e\nHmaUWEx+fr4SEhL05ZdfymKxyMfHR/Hx8br99tsVHR2tixcvOv5yurm5ae7cuQoICChzzFWrVumn\nn37S2LFjJUmbN2/WG2+8IavVqn79+mnAgAGm3xcAAMCtbvW+H7Xj6BlVXLySpG+kDX0rdMaSWK1W\n9ezZU7Gxsc4u5aZVKQKWJDVq1Ehr1qy57uuXL1+u3r17G1hR2WbPnq2goCCtX79ekvThhx9q9OjR\nSk5OliTNnTtXDRs2lCStX79eiYmJmjhxYoljXbp0SVOmTNH+/fv12GOPOY6/9NJL2rJli3x8fPTk\nk0/qySefVLVq1Uy+MwAAgFvb9qNnnF2C09hsNqWmphKwbkClCVglefnll/X555/Lbrdr0KBB6tat\nm/bs2aPFixdL+iWYzJ07V3v37lV2drbGjBmjgQMHKikpSQsWLJAkdejQQf/7v/+rCRMm6MyZMzpz\n5oyWL1+ulStXFht73bp1evfdd2W1WtW6dWuNHz++xLoKCgr00UcfacaMGY5jXbt2VZs2bUo8Pzc3\nVz4+PqXeZ35+vnr37q327dvr6NGjjuNNmzbVuXPn5O7uLrvdLovFUu4eAgAAoHy6BFV3wgpW5XBl\nBQvXr9IErMOHDys6Otrx+/DwcGVmZiopKUn5+fmKiIhQhw4d9M0332jevHkKCAjQsmXLtG3bNg0f\nPlxLly7VggULtG/fvlLnCA0N1aBBg7Rz584Sx05JSdHUqVPVqlUrrV+/XoWFhXJ3L96iM2fOqHbt\n2sUCT40aNRz/PH78eHl7e8tisSgwMFDjxo0rta5q1arpoYceUkpKylXHGzdurH79+snb21tdu3aV\nv7//7/YRAAAANyamVV1FBNep2Gew/GvrtvDS3y9WFJ7BunGVJmD9dovgihUrlJGR4QhdhYWFOnHi\nhAICAjR79mz5+PgoKytLrVu3LnNcu/2//2IEBgZKkg4dOlTi2HPmzFFiYqLmz5+vVq1aXXXtr9Wo\nUUNnz54ttqr0t7/9TU888YSkq7cIXo+DBw/q448/1o4dO+Tj46Nx48Zp69at6tat23WPCQAAgGtT\nxd2qKhX4Ttm9igePgriISvsx7UFBQWrbtq3WrFmjN998U926dVP9+vU1ZcoUvfDCC3rxxRdVp04d\nRwiyWCyy2Wzy8vJSdna2JOn48ePK/dWnsVwJQ6WNvXHjRs2YMUNr167VV199pS+++KLE2jw8PPTQ\nQw9dFQi3bdumN99807AP2fDz81OVKlXk5eUlNzc31axZU2fPnjVkbAAAAADmqDQrWL/VqVMn7dmz\nRwMGDNCFCxfUpUsX+fr6KiwsTBEREfL391ft2rV16tQpSVKbNm00dOhQJSYmys/PT+Hh4WrYsKHq\n169/zWM3bdpU/fv3V40aNRQQEKCWLVuWWt/EiRM1Z84cRUVFSfplm9+iRYsMu/969eopMjJSAwYM\nkIeHh+6880716dPHsPEBAAAAGM9iL20fHG5KWWtnqDD3lLPLAAAAQDm4V6ujgKemO7uMCpOWlqaQ\nkBBnl2GKSruCVRns2LFDq1atKnY8JiZGXbt2LddYBQUFGjJkSLHjgYGBio+Pv94SAQAAAFQiBKwy\ndO7cWZ07dzZkLE9Pzxv6ni8AAAAAlV+l/ZALAAAAALjZELAAAAAAwCAELAAAAAAwCAELAAAAAAxC\nwAIAAAAAgxCwAAAAAMAgfEy7i3Hzr+XsEgAAAFBOvIdzHQQsF/Nj0CMKDg52dhkuJT09nZ6agL6a\ng76ag74aj56ag76ag76iPNgi6GLy8/OdXYLLoafmoK/moK/moK/Go6fmoK/moK8oDwIWAAAAABiE\ngAUAAAAABiFgAQAAAIBBCFgAAAAAYBACFgAAAAAYhIDlYry8vJxdgsuhp+agr+agr+agr8ajp+ag\nr+agrygPi91utzu7CBjnu79NV8HZLGeXAQAAcMvx9A/Q3T1nOLuMm0JaWppCQkKcXYYp+KJhF1Nw\nNksFuSecXQYAAABwS2KLIAAAAAAYhIAFAAAAAAYhYAEAAACAQQhYAAAAAGAQAhYAAAAAGISABQAA\nAAAGIWABAAAAgEEIWAAAAABgEAIWAAAAABiEgAUAAAAABiFgAQAAAIBB3J1dgCRlZmaqV69eat68\nueNY27ZtNXLkyGseIzk5WX379pWHh4cZJRazf/9+JSQkyG63y2azqWPHjho8eLB2796t0aNHq1Gj\nRrLb7SosLFRMTIy6d+9e6lgXLlxQXFycMjMzdfnyZU2dOlUtWrRwvD516lRVq1ZNY8eOrYhbAwAA\ncCn5hXYVFpk/T8GlIuXm5po/kSRPT095e3tXyFwon0oRsCSpUaNGWrNmzXVfv3z5cvXu3dvAisoW\nHx+vuXPnqmHDhrp8+bKioqLprQtOAAAgAElEQVQUGhoqSQoNDdWCBQskSefPn1d0dLQCAwPVrFmz\nEsd6/fXX1bhxY7300ks6ePCgDh486AhYSUlJOnTokB544IGKuTEAAAAX8tYX+frkaKHsFTLbUWl9\n3wqZyWq1qmfPnoqNja2Q+XDtKvUWwZdffllRUVGKjIzU1q1bJUl79uxRTEyMYmJiFBERoW+//Vab\nNm1Sdna2xowZo927d2vMmDGOMTp06CBJmjBhgoYNG6aoqCjl5uaWOPa6desUHh6uyMhIzZ07t8za\n7rjjDq1bt07p6emyWq3asGGD7r333mLnVa1aVZGRkdq2bVupY33yySfy8PDQkCFDtGTJEj388MOS\npC+++EJffvmlIiMjy9c4AAAASJL+VWHhqmLZbDalpqY6uwyUoNIErMOHDys6Otrxa/PmzcrMzFRS\nUpJWr16tZcuW6ezZs/rmm280b948rV69Wp06ddK2bdsUHh6u2267zbFqVJrQ0FAlJSVp3759JY6d\nkpKiyZMnKzk5WQ0aNFBhYWGpY73wwguqVauW4uLi1L59e82dO1cFBQUlnlurVi3l5OSUOlZOTo7O\nnj2r119/XZ06ddLcuXN16tQpLV68WNOmTbu2BgIAAKCYh4PcZXF2ESawWq0KCwtzdhkoQaXdIrhi\nxQplZGQoOjpaklRYWKgTJ04oICBAs2fPlo+Pj7KystS6desyx7Xb//szi8DAQEnSoUOHShx7zpw5\nSkxM1Pz589WqVaurrv21/Px8ZWRkaMSIERoxYoRycnI0adIkJScnq0mTJsXOP3HihOrWrVtqjdWr\nV1enTp0kSY8++qhee+01bdu2TTk5ORo6dKiys7N16dIlBQUFqW/fill2BgAAcAX97/dSz/s8K+QZ\nLA//umrYf775E4lnsCqzShOwfisoKEht27bVzJkzZbPZtGTJEtWvX1+DBg3S9u3b5evrq/HjxztC\nkMVikc1mk5eXl7KzsyVJx48fv+pBQ4vFUubYCQkJmjFjhry8vDRkyBB98cUXevDBB4vVZrFYNG7c\nOK1cuVJNmjRRjRo1VK9ePXl6ehY7Ny8vT5s2bdLChQtLvdeQkBDt3LlTwcHB+vzzz9WoUSPHNkhJ\nSklJ0dGjRwlXAAAA18HL3SKvCnjX61nFTdWqVTN/IlRqlTZgderUSXv27NGAAQN04cIFdenSRb6+\nvgoLC1NERIT8/f1Vu3ZtnTp1SpLUpk0bDR06VImJifLz81N4eLgaNmyo+vXrX/PYTZs2Vf/+/VWj\nRg0FBASoZcuWJdbm6emphIQETZs2TUVFRbJYLLrvvvvUr18/paWladeuXYqOjpbValVRUZFGjRql\noKCgUu/1mWee0ZQpUxQZGSl3d/ffff4LAAAAQOVksZe2Dw43pUPrhqkg94SzywAAALjleFa7Q03+\nuMzZZdwU0tLSFBIS4uwyTFFpV7Aqgx07dmjVqlXFjsfExKhr167lGqugoEBDhgwpdjwwMFDx8fHX\nWyIAAACASoSAVYbOnTurc+fOhozl6el5Q9/zBQAAAKDyqzQf0w4AAAAANzsCFgAAAAAYhIAFAAAA\nAAYhYAEAAACAQQhYAAAAAGAQAhYAAAAAGISABQAAAAAG4XuwXIynf4CzSwAAALgl8T4MEgHL5eQF\nhis4ONjZZbiU9PR0emoC+moO+moO+mo8emoO+moO+oryYIugi8nPz3d2CS6HnpqDvpqDvpqDvhqP\nnpqDvpqDvqI8CFgAAAAAYBACFgAAAAAYhIAFAAAAAAYhYAEAAACAQQhYAAAAAGAQApaL8fLycnYJ\nLoeemoO+moO+moO+Go+emoO+moO+ojwsdrvd7uwiYJwDW6cp/9yPzi4DAADgluflV1f3dYt3dhmV\nUlpamkJCQpxdhin4omEXk3/uR13MPeHsMgAAAIBbElsEAQAAAMAgBCwAAAAAMAgBCwAAAAAMQsAC\nAAAAAIMQsAAAAADAIAQsAAAAADAIAQsAAAAADELAAgAAAACDELAAAAAAwCAELAAAAAAwCAELAAAA\nAAzi7uwCJCkzM1O9evVS8+bNHcfatm2rkSNHXvMYycnJ6tu3rzw8PMwosZj9+/crISFBdrtdNptN\nHTt21ODBg7V7926NHj1ajRo1kt1uV2FhoWJiYtS9e/ffHfPzzz/X2LFjtXPnTknS5s2b9cYbb8hq\ntapfv34aMGCA2bcFAABwy8u/bFeR7cbHsV0qUm5u7o0P9Cuenp7y9vY2dEwYq1IELElq1KiR1qxZ\nc93XL1++XL179zaworLFx8dr7ty5atiwoS5fvqyoqCiFhoZKkkJDQ7VgwQJJ0vnz5xUdHa3AwEA1\na9as1PFOnjypxMREFRYWOo699NJL2rJli3x8fPTkk0/qySefVLVq1cy9MQAAgFvYe2kF+vybIoNG\n+056s69BY/3CarWqZ8+eio2NNXRcGKdSbxF8+eWXFRUVpcjISG3dulWStGfPHsXExCgmJkYRERH6\n9ttvtWnTJmVnZ2vMmDHavXu3xowZ4xijQ4cOkqQJEyZo2LBhioqKUm5uboljr1u3TuHh4YqMjNTc\nuXPLrO2OO+7QunXrlJ6eLqvVqg0bNujee+8tdl7VqlUVGRmpbdu2lTpWfn6+pk+frri4uKuON23a\nVOfOnVNBQYHsdrssFss19Q0AAADXx7hwZQ6bzabU1FRnl4EyVJoVrMOHDys6Otrx+/DwcGVmZiop\nKUn5+fmKiIhQhw4d9M0332jevHkKCAjQsmXLtG3bNg0fPlxLly7VggULtG/fvlLnCA0N1aBBg7Rz\n584Sx05JSdHUqVPVqlUrrV+/XoWFhXJ3L7lFL7zwgt58803FxcXphx9+UI8ePTR+/PgSz61Vq5Yy\nMjJKrSs+Pl6DBw9WQEDAVccbN26sfv36ydvbW127dpW/v39ZLQQAAMANeqCxm/YeLpLd7uxKSnZl\nBQuVV6UJWL/dIrhixQplZGQ4QldhYaFOnDihgIAAzZ49Wz4+PsrKylLr1q3LHNf+q387AgMDJUmH\nDh0qcew5c+YoMTFR8+fPV6tWra669tfy8/OVkZGhESNGaMSIEcrJydGkSZOUnJysJk2aFDv/xIkT\nqlu3boljZWVlae/evfr+++/117/+Vbm5uRozZoyeeeYZffzxx9qxY4d8fHw0btw4bd26Vd26dSvz\nfgEAAHD9ngzxVJcWxjyDVcW/rlqFvXLjA/0Kz2BVfpUmYP1WUFCQ2rZtq5kzZ8pms2nJkiWqX7++\nBg0apO3bt8vX11fjx493hCCLxSKbzSYvLy9lZ2dLko4fP37Vg4VXttiVNnZCQoJmzJghLy8vDRky\nRF988YUefPDBYrVZLBaNGzdOK1euVJMmTVSjRg3Vq1dPnp6exc7Ny8vTpk2btHDhwhLvMyAgQO+/\n/77j9x06dNCCBQt0/PhxValSRV5eXnJzc1PNmjV19uzZ628oAAAAromXhzGPZXhXceP5+VtQpQ1Y\nnTp10p49ezRgwABduHBBXbp0ka+vr8LCwhQRESF/f3/Vrl1bp06dkiS1adNGQ4cOVWJiovz8/BQe\nHq6GDRuqfv361zx206ZN1b9/f9WoUUMBAQFq2bJlibV5enoqISFB06ZNU1FRkSwWi+677z7169dP\naWlp2rVrl6Kjo2W1WlVUVKRRo0YpKCioXPdfr149RUZGasCAAfLw8NCdd96pPn36lL+RAAAAACqM\nxV7aPjjclPZuHKqLuSecXQYAAMAtz7vaHWoT8Zqzy6iU0tLSFBIS4uwyTFFpV7Aqgx07dmjVqlXF\njsfExKhr167lGqugoEBDhgwpdjwwMFDx8fHXWyIAAACASoSAVYbOnTurc+fOhozl6el5Q9/zBQAA\nAKDyq9TfgwUAAAAANxMCFgAAAAAYhIAFAAAAAAYhYAEAAACAQQhYAAAAAGAQAhYAAAAAGISABQAA\nAAAG4XuwXIyXX11nlwAAAADxvuxWRcByMZYGEWoTHOzsMlxKenq6gump4eirOeirOeir8eipOeir\nOegryoMtgi4mPz/f2SW4HHpqDvpqDvpqDvpqPHpqDvpqDvqK8iBgAQAAAIBBCFgAAAAAYBACFgAA\nAAAYhIAFAAAAAAYhYLkYLy8vZ5fgcuipOeirOeirOeir8eipOegr4Hx8TLuLOX98gz4+mOXsMlzO\nxwedXYFroq/moK/moK/Go6fmqOx99fYLUNvHZzu7DMA0BCwXc/Fcls6fPe7sMgAAAIBbElsEAQAA\nAMAgBCwAAAAAMAgBCwAAAAAMQsACAAAAAIMQsAAAAADAIAQsAAAAADAIAQsAAAAADELAAgAAAACD\nELAAAAAAwCAELAAAAAAwCAELAAAAAAziMgErOjpaR44cMXWOtWvXmjp+SY4dO6YePXpU+LwAAAAA\nys/d2QXcTJYuXaqnnnqqwuZ79913tXr1auXk5FTYnAAAwPUUXLaryObsKn5huVSk3NxcZ5dxFU9P\nT3l7ezu7DLiICgtY3377rSZOnCh3d3e5ubnppZde0quvvqoff/xROTk5+n//7/9p9OjRmjBhgtzd\n3XXixAkVFBSoe/fu+sc//qGTJ09qyZIlOnnypJYtWyar1ars7GxFRkbqj3/8o2Oec+fOafLkyY5Q\nMmXKFDVt2rTEmi5fvqzp06fr2LFjstlsGj16tNq2bauePXvqwQcf1Ndffy2LxaIlS5Zo7dq1ys3N\nVVxcnFq0aKG3335bNptNsbGxys7O1ptvvilPT0/dfffdio+P19/+9jft2LFDeXl5ysnJ0YgRI9Sk\nSRONGzdOb731liRp9OjRGjx4sFq0aFFifdWqVdPatWvVtWtXg/80AADArWLH54X68lAlSVeSpO/1\n8ht9nV3EVaxWq3r27KnY2FhnlwIXUGFbBD/99FM1b95cb7zxhoYNG6bc3Fy1atVKr7/+ujZs2KAN\nGzY4zq1Xr54SExMVFBSkzMxMrVixQo899pg++ugjSVJWVpaWLl2qjRs3atWqVfr5558d1y5btkyh\noaFas2aNZs6cqbi4uFJr2rRpk2rUqKF169ZpyZIlio+PlySdP39eTz75pNauXas6deron//8p4YP\nH65q1ao5xvP399eGDRt0zz33aNGiRXrzzTe1YcMG+fn5KTk5WZJ04cIFvfHGG0pMTNSLL76oBg0a\nqEqVKjp8+LDOnDmjzMzMUsOVJD366KPy8fG53pYDAABUsnBVOdlsNqWmpjq7DLiIClvB6t+/v1as\nWKGnn35afn5+GjlypA4cOKBdu3bJ19dXBQUFjnPvvfdeSb+EmKCgIMc/Xznn/vvvl6enpySpcePG\n+v777x3XHjp0SLt27dLWrVslSWfPni21pkOHDiktLU379++XJBUWFjpWvq7UcPvttys/P7/YtYGB\ngZKkH374QY0aNZKvr68k6YEHHtAnn3yili1b6oEHHpDValXt2rXl7++v06dPKzw8XCkpKbrjjjvU\nq1ev8rYRAACgXFo2sWr/NzbZ7c6upPK6soIFGKHCAtaOHTsUEhKikSNHasuWLQoLC9PTTz+t+Ph4\nHTt2TBs3bpT9//7Nt1gsZY711VdfqaioSAUFBTp8+LDuuusux2tBQUHq1auXevbsqZ9//lmbNm0q\ndZygoCDVrVtXw4YN06VLl7R06VJVq1at1Brsv/ovk9X6y+Jf/fr1deTIEV24cEE+Pj7as2ePI3xl\nZGRIkn766Sfl5eWpVq1aeuKJJ5SYmKjq1atr4cKF19I6AACA69b5AXc93KryPIPl43e7OvRMcHYZ\nV+EZLBipwgJWcHCwxo0bp0WLFslqtWr9+vWKi4tTWlqavL29ddddd+nUqVPXNFZhYaH+9Kc/6cyZ\nMxo+fLhq1qzpeG3YsGGaPHmyNm7cqLy8PI0cObLUcaKiojRlyhQ99dRTysvL04ABAxzBqSQNGzbU\n2LFj1b59e8exmjVratSoUYqJiZHVatWdd96psWPH6r333tNPP/2kgQMH6ty5c5o+fbrc3Nzk5uam\nBx54QKdPn1b16tWv6X4BAABuhKdH2T+8rkg+VdwcP9AGXJHFbr+5Fox3796tpKQkLViwwNmllCkl\nJUVHjx7V2LFji70WFxenxx9/XO3atTN83o/felrnzx43fFwAAAAjVPWvp0f6r3R2GeWSlpamkJAQ\nZ5fhUly5p7fEx7THxcWV+B1ZK1asUJUqVSq0lsGDB6tOnTqOcLV48WLt3r272HkvvPCCGjRoUKG1\nAQAAALgxN90KFsrGChYAAKjMWMGC5No9rbCPaQcAAAAAV0fAAgAAAACDELAAAAAAwCAELAAAAAAw\nCAELAAAAAAxCwAIAAAAAgxCwAAAAAMAgt8QXDd9KvP0CnF0CAABAqXivAldHwHIxVev9QW2Dg51d\nhktJT09XMD01HH01B301B301Hj01B30FnI8tgi4mPz/f2SW4HHpqDvpqDvpqDvpqPHpqDvoKOB8B\nCwAAAAAMQsACAAAAAIMQsAAAAADAIAQsAAAAADAIAQsAAAAADELAcjFeXl7OLsHl0FNz0Fdz0Fdz\n0Ffj0VNz0FfA+fgeLBeTfWK9thz60dlluJzvDjm7AtdEX81BX81BX41HT81xs/W1qm9dPfrYC84u\nAzAMAcvFnM/7UefOHnd2GQAAAMAtiS2CAAAAAGAQAhYAAAAAGISABQAAAAAGIWABAAAAgEEIWAAA\nAABgEAIWAAAAABiEgAUAAAAABiFgAQAAAIBBCFgAAAAAYBACFgAAAAAYhIAFAAAAAAYhYAEAAACA\nQdydXUBmZqZ69eql5s2bO461bdtWI0eOvOYxkpOT1bdvX3l4eJhRYomysrL02GOP6cUXX1S3bt0k\nSbt379bo0aPVqFEj2e12FRYWKiYmRt27d5cknTx5Ui+++KJOnz6tS5cuqXnz5po0aZI8PT1LnKOo\nqEhz5sxRenq6CgoKNGrUKD366KMVdo8AAACXL9tVZDNvfPdLRcrNzTVvgt/w9PSUt7d3hc2HW4/T\nA5YkNWrUSGvWrLnu65cvX67evXsbWNHvS0lJUUxMjNavX+8IWJIUGhqqBQsWSJLOnz+v6OhoBQYG\nqkmTJnr22WcVFxenli1bSpJmzZqlV199VWPHji1xjtTUVBUWFiopKUlZWVnaunWr+TcGAADwfz7d\nU6T/fG03eZZMLXu9r8lz/JfValXPnj0VGxtbYXPi1lIpAlZJXn75ZX3++eey2+0aNGiQunXrpj17\n9mjx4sWSpEuXLmnu3Lnau3evsrOzNWbMGA0cOFBJSUmOgNOhQwf97//+ryZMmKAzZ87ozJkzWr58\nuVauXFls7HXr1undd9+V1WpV69atNX78+FJrs9vtSk1N1fr16/Xss8/q0KFDatKkSbHzqlatqsjI\nSG3btk3nzp1T3bp1HeFKksaNGyebrfQfCX3yySdq0qSJhg4dKrvdrqlTp15vOwEAAMrN/HBV8Ww2\nm1JTUwlYME2leAbr8OHDio6OdvzavHmzMjMzlZSUpNWrV2vZsmU6e/asvvnmG82bN0+rV69Wp06d\ntG3bNoWHh+u2225zhKrShIaGKikpSfv27Stx7JSUFE2ePFnJyclq0KCBCgsLSx3rs88+U5MmTVSz\nZk3169dP69atK/XcWrVqKScnR6dOnVKDBg2ues3Ly6vMJeqcnBwdO3ZMy5cv15/+9CdNnDixzHsE\nAAAw0r1NLbJYnF2FsaxWq8LCwpxdBlxYpVjB+u0WwRUrVigjI0PR0dGSpMLCQp04cUIBAQGaPXu2\nfHx8lJWVpdatW5c5rt3+35+6BAYGSpIOHTpU4thz5sxRYmKi5s+fr1atWl117W9t3LhRmZmZGjJk\niC5fvqyDBw+Wus3vxIkTqlu3ru644w598MEHV72Wk5Ojffv2lfpcVfXq1fXII4/IYrHowQcf1Hff\nfVfm/QIAABip/YNueuB+c5/B8vW7XY89+ap5E/wGz2DBbJUiYP1WUFCQ2rZtq5kzZ8pms2nJkiWq\nX7++Bg0apO3bt8vX11fjx493hCCLxSKbzSYvLy9lZ2dLko4fP37VA5OW//vxS2ljJyQkaMaMGfLy\n8tKQIUP0xRdf6MEHHyxW2+nTp/Xll19q+/btcnNzkyRNmTJF77zzjpo2bXrVuXl5edq0aZMWLlyo\nu+++W5mZmdq/f79atGghu92uxYsXy8vLq9SAFRISop07d+rxxx/XwYMHdfvtt994cwEAAMrBw8Mi\nMz9GzLuKm6pVq2biDEDFqpQBq1OnTtqzZ48GDBigCxcuqEuXLvL19VVYWJgiIiLk7++v2rVr69Sp\nU5KkNm3aaOjQoUpMTJSfn5/Cw8PVsGFD1a9f/5rHbtq0qfr3768aNWooICDgqmelfi01NVWPPfaY\nI1xJUkREhP7yl78oLi5Ou3btUnR0tKxWq4qKijRq1CgFBQVJkhYuXKj4+HhdvHhRFy5cUKtWrTR6\n9OhS+xAREaHp06crIiJCdrtdM2bMuJG2AgAAADCZxV7WXjjcdLakDNa5s8edXQYAAMA18fOvpx59\nE51dRpnS0tIUEhLi7DJciiv3tFKuYFUGO3bs0KpVq4odj4mJUdeuXQ2da+TIkcW+/8HX11dLly41\ndB4AAAAA5iJglaJz587q3Llzhcx15aPnAQAAANzcKsXHtAMAAACAKyBgAQAAAIBBCFgAAAAAYBAC\nFgAAAAAYhIAFAAAAAAYhYAEAAACAQfiYdhdT1beus0sAAAC4Zrx3gashYLmY2+4YoEeDg51dhktJ\nT09XMD01HH01B301B301Hj01B30FnI8tgi4mPz/f2SW4HHpqDvpqDvpqDvpqPHpqDvoKOB8BCwAA\nAAAMQsACAAAAAIMQsAAAAADAIAQsAAAAADAIAQsAAAAADELAcjFeXl7OLsHl0FNz0Fdz0Fdz0Ffj\n0VNz0FfA+fgeLBdz7Mf1Sj/8o7PLcDnph51dgWuir+agr+agr8ajp+Zwdl/9fOvqyS4vOLcIwIkI\nWC7mXN6Pyj133NllAAAAALcktggCAAAAgEEIWAAAAABgEAIWAAAAABiEgAUAAAAABiFgAQAAAIBB\nCFgAAAAAYBACFgAAAAAYhIAFAAAAAAYhYAEAAACAQQhYAAAAAGAQAhYAAAAAGMTd2QUAAACg4ly+\nbJetyLzxL7kXKTc317wJfsXT01Pe3t4VMhdwrQhYBtq9e7eSkpK0YMGC3z130aJF2rJli+rUqSNJ\nOnPmjLp3767hw4crJSVFr776qho0aCBJOnv2rFq3bq3p06ebWj8AAHBt/95VpMMH7SbPkqk1K/ua\nPMcvrFarevbsqdjY2AqZD7gWBCwnGjRokP7whz9IkgoKCtS9e3dFRERIknr06KGxY8dKkmw2mwYM\nGKADBw7ovvvuc1q9AADg5mZ+uKpYNptNqampBCxUKjyDdQO+/fZbRUVF6amnntLAgQOVlZUlSbp4\n8aKGDBmizZs3X/NYOTk5KiwslJeXV7HXzp8/r3PnzsnPz8+w2gEAwK2n0T0WWSzOrsI4VqtVYWFh\nzi4DuAorWDfg008/VfPmzTVhwgTt3btXR44c0YULFzRs2DDFxMSoc+fOZV6/atUqvffeezp58qQC\nAgI0a9Ys+fr6SpK2bNmiffv2KTs7W1WrVtWwYcN09913V8BdAQAAV9U61E33hZj7DJa/7+3q0/1V\n8yb4FZ7BQmVEwLoB/fv314oVK/T000/Lz89PHTp00J49e9S0aVMVFBT87vVXtgimp6fr+eefvypA\nXdki+MMPP+jpp58mXAEAAEN4eFgkD/PGr+LtpmrVqpk3AVDJsUXwBuzYsUMhISF688039cQTT2jF\nihV65JFHtHjxYiUkJDi2DP6e4OBg/elPf9Lzzz8vm8121WsNGjTQ9OnT9dxzz+nixYtm3AYAAAAA\ngxCwbkBwcLASEhI0YMAAJSUlKTo6WpJUu3ZtjRo1SpMmTZLdfm0Pk4aHh8vX11cbNmwo9lr79u3V\nvn17vfpqxSy3AwAAALg+Fvu1JgDcFJLeHazcc8edXcb/Z+/eo6qs87ePX3tzEkHxGKRSgqSZ5AlT\nS50UzSYbxccUzIIxLUcnc7SfpikzkYZJnvIwHrLIJM8zTHTSSptnmqbUYlLDdNRsNERFEzEgOe39\n/NETv0xA1O/Nhu37tZZr6d73/n4/XK4lXtz3vjcAALhOBdRrruGDk109hlHp6emKiIhw9RhuxZ0z\n5T1YFioqKtLo0aMveTwkJEQzZ850wUQAAAAArETBspC3t7dSUlJcPQYAAACAasJ7sAAAAADAEAoW\nAAAAABhCwQIAAAAAQyhYAAAAAGAIBQsAAAAADKFgAQAAAIAh3KbdzdTzD3L1CAAA4DrG/0VwvaNg\nuZmbg0YoPDzc1WO4lYyMDDK1ALlag1ytQa7mkak1yBVwPS4RdDOFhYWuHsHtkKk1yNUa5GoNcjWP\nTK1BroDrUbAAAAAAwBAKFgAAAAAYQsECAAAAAEMoWAAAAABgCAULAAAAAAyhYLkZHx8fV4/gdsjU\nGuRqDXK1BrmaR6bWIFfA9fgcLDfz1Zl1+uSdk64ew+18ctTVE7gncrUGuVqDXM0jU2tYkWsDvyBF\n955tfmHADVGw3My5/JPK+f64q8cAAAAArktcIggAAAAAhlCwAAAAAMAQChYAAAAAGELBAgAAAABD\nKFgAAAAAYAgFCwAAAAAMoWABAAAAgCEULAAAAAAwhIIFAAAAAIZQsAAAAADAEAoWAAAAABji6eoB\nTImNjVVCQoJatWpl2R6vv/66Hn74YcvW/6WkpCT9+9//VklJiWJiYhQdHV1tewMAgNqnpNgpR6n5\ndQs9S5Wbm2t+4Z/x9vaWr6+vpXsA1cFtClZ1WL58ebUVrB07dujYsWPauHGjioqKdP/99+vee+9V\nQEBAtewPAABql/3/KtW3XzktWj1TbywfYtHaP7Lb7Ro4cKAmTJhg6T6A1aqtYH3zzTd6+umn5enp\nKQ8PD73wwgtavHixThPfAIsAACAASURBVJ48qZycHP3qV7/SxIkTNW3aNHl6eiorK0tFRUUaMGCA\n/v73v+vEiRNatmyZTpw4oRUrVshut+v06dOKiYnRQw89VLbP999/rxkzZignJ0eSFB8frzZt2pQ7\nU3FxsZ555hkdPXpUDodDEydOVLdu3TRw4EB17dpV//nPf2Sz2bRs2TK9/vrrys3NVUJCgtq3b6+/\n/vWvcjgcmjBhgk6fPq3XXntN3t7eatmypWbOnKm33npL27dvV15ennJycvT444+rdevWmjJliv7y\nl79IkiZOnKhRo0apffv2l8zWqVMntW3btuzPpaWl8vSkDwMAgPJZV66qh8PhUFpaGgULtV61vQfr\nk08+Ubt27fTqq69q7Nixys3NVceOHfXKK69o/fr1Wr9+fdmxzZs3V3JyskJDQ5WZmalVq1apf//+\n+vDDDyVJp06d0vLly7Vp0yatXr1a3333XdlrV6xYoe7duyslJUWzZs1SQkJChTNt3rxZDRs21Nq1\na7Vs2TLNnDlTkpSfn6/7779fr7/+um644QZ99NFHGjdunAICAsrWq1+/vtavX69bb71VS5Ys0Wuv\nvab169erXr162rhxoySpoKBAr776qpKTkzVnzhwFBwerTp06Onz4sM6dO6fMzMxyy5Uk+fj4KCAg\nQMXFxZo2bZpiYmLk5+d3LX8FAADAjQXfZpNsrp7i6tntdkVFRbl6DOCaVdspkaFDh2rVqlV69NFH\nVa9ePY0fP15ffvmlduzYIX9/fxUVFZUde9ttt0n6scSEhoaW/f6nYzp16iRvb29J0i233KJjx46V\nvfbgwYPasWOHtmzZIkk6f/58hTMdPHhQ6enp2rt3rySppKSk7MzXTzPceOONKiwsvOS1ISEhkqRv\nv/1WYWFh8vf3lyTdcccd+vjjj9WhQwfdcccdstvtatKkierXr6+zZ89q2LBhSk1NVbNmzTRo0KBK\nM8vNzdWECRPUtWtX/e53v6v0WAAAcH1r28NDt3S15j1YDfxvVNw9i80v/DO8BwvuotoK1vbt2xUR\nEaHx48fr7bffVlRUlB599FHNnDlTR48e1aZNm+R0/nhq22ar/Mcv+/fvV2lpqYqKinT48GHdfPPN\nZc+FhoZq0KBBGjhwoL777jtt3ry5wnVCQ0MVFBSksWPH6sKFC1q+fHnZe5zKm+Gn+aQff8oiSS1a\ntNDXX3+tgoIC1a1bV7t27SorX/v27ZMknTlzRnl5eWrcuLF+/etfKzk5WQ0aNNCiRYsqnO3ChQsa\nOXKkHnnkkcsWMQAAAEny9LJJXubX9fH14H3gQBVVW8EKDw/XlClTtGTJEtntdq1bt04JCQlKT0+X\nr6+vbr75ZmVnZ1dprZKSEj322GM6d+6cxo0bp0aNGpU9N3bsWM2YMUObNm1SXl6exo8fX+E6w4cP\nV3x8vB5++GHl5eVpxIgRZcWpPK1atdLkyZN11113lT3WqFEjPfHEE4qLi5PdbtdNN92kyZMn6513\n3tGZM2f029/+Vt9//72eeeYZeXh4yMPDQ3fccYfOnj2rBg0aVLjXhg0b9O2332rz5s1lJXH27NkK\nDg6uUkYAAAAAqp/N+fPTMrXAzp07tWHDBi1cuNDVo1QqNTVVR44c0eTJky95LiEhQffee6/uvPNO\n4/u+9M4o5Xx/3Pi6AADg+tWwXnONuT/Z1WO4THp6uiIiIlw9hltx50yvi9vSJSQk6Ouvv77k8VWr\nVqlOnTrVOsuoUaN0ww03lJWrpUuXaufOnZccx9kqAAAAoPapdWewUDnOYAEAANM4g+W+Z1tcxZ0z\nrbbbtAMAAACAu6NgAQAAAIAhFCwAAAAAMISCBQAAAACGULAAAAAAwBAKFgAAAAAYQsECAAAAAEOu\niw8avp408Aty9QgAAMDN8P8LoOooWG7mtiYjFN473NVjuJWMjAyFh5OpaeRqDXK1BrmaR6bWIFfA\n9bhE0M0UFha6egS3Q6bWIFdrkKs1yNU8MrUGuQKuR8ECAAAAAEMoWAAAAABgCAULAAAAAAyhYAEA\nAACAIRQsN+Pj4+PqEdwOmVqDXK1BrtYgV/PI1BrkCriezel0Ol09BMxZ/vEMfZd/0tVjAACAWq6x\nX5DG9Ux09Rg1Qnp6uiIiIlw9hltx50z5HCw3813+SZ3OO+7qMQAAAIDrEpcIAgAAAIAhFCwAAAAA\nMISCBQAAAACGULAAAAAAwBAKFgAAAAAYQsECAAAAAEMoWAAAAABgCAULAAAAAAyhYAEAAACAIRQs\nAAAAADCEggUAAAAAhlx3BSs1NVXz5s1z9RiXiIyMVGFhYYXPf/DBBzp16lQ1TgQAAADgSnm6egBU\nzZo1a5SQkKDAwEBXjwIAAFystNgpZ6m1exR7lCo3N9faTSR5e3vL19fX8n2A6nLdFqzk5GS98847\n8vT0VJcuXTRlyhQtWbJEX3zxhQoKCpSYmKhPPvlEb7/9tmw2mwYMGKC4uDhNmzZN3t7eOn78uLKz\nszVnzhzVr19f06dPlyTl5+fryJEj+vTTT8v9xyI1NVXbt29XXl6ecnJy9Pjjj+vee+8tez4zM1Mz\nZsxQSUmJbDab4uPjdfLkSe3fv19Tp07VunXr5O3tXW05AQCAmiXro1KdzXBUw07f6uMlQyzfxW63\na+DAgZowYYLlewHV4bq7RFCSjh49qi1btmjDhg3asGGDjh49qr///e+SpNDQUG3YsEFOp1Pvvvuu\n1q1bp3Xr1mnbtm06cuSIJKlZs2Z65ZVXFBsbq40bNyo4OFgpKSl65ZVX1KBBAy1atKjSn8QUFBTo\n1VdfVXJysubMmaOSkpKy51544QXFxsZq7dq1mjFjhqZPn67evXurbdu2SkpKolwBAHCdq55yVX0c\nDofS0tJcPQZgzHV5Bmv//v3q3bu3vLy8JEldunTRoUOHJEkhISGSpIMHDyorK0sjR46UJOXm5urY\nsWOSpLZt20qSgoKC9O9//1uSVFpaqkmTJmnQoEG6++67K93/jjvukN1uV5MmTVS/fn2dPXu27Lmv\nv/5ad9xxR9k+J0+eNPRVAwAAd9Ao3K6z+xyS09WTmPHTGSzAXVyXBatt27bau3evSkpK5OHhoc8+\n+0yDBw/WgQMHZLf/eFIvNDRUYWFhevnll2Wz2bR69Wq1bt1aW7dulc1mu2g9p9Op6dOnq1OnTho8\nePBl99+3b58k6cyZM8rLy1Pjxo3LnmvVqpU+//xz9e3bV/v371eTJk0kSTabTU6nm/xLCgAArlqz\nX3ko8E675e/BauJ3o57ss8jaTcR7sOB+rsuCdfPNN6tz58568MEH5XA4FBERoX79+unAgQNlx9x6\n662688479eCDD6qoqEjt27ev8AYTW7du1fvvv69Tp07pH//4hyTpmWeeUVhYWLnHnzlzRr/97W/1\n/fff65lnnpGHh0fZc0899ZT++Mc/Kjk5WSUlJUpMTJQkderUSU899ZSSk5PVoEEDU1EAAIBayMPL\nJnlZu4eXr4cCAgKs3QRwQzYnp0WqVWpqqo4cOaLJkydbsv5z743W6bzjlqwNAACuH039myv+3ldc\nPUaNkJ6eroiICFeP4VbcOdPr8gxWdUhISNDXX399yeP33XefC6YBAAAAUB0oWBZJSEhw9QgAAAAA\nqtl1eZt2AAAAALACBQsAAAAADKFgAQAAAIAhFCwAAAAAMISCBQAAAACGULAAAAAAwBAKFgAAAAAY\nQsECAAAAAEP4oGE309gvyNUjAAAAN8D/KYCrQ8FyM70aPKjwnuGuHsOtZGRkKDycTE0jV2uQqzXI\n1TwytQa5Aq7HJYJuprCw0NUjuB0ytQa5WoNcrUGu5pGpNcgVcD0KFgAAAAAYQsECAAAAAEMoWAAA\nAABgCAULAAAAAAyhYLkZHx8fV4/gdsjUGuRqDXK1BrmaR6YA3BW3aXcz689v0alta1w9hvs56eoB\n3BS5WoNcrUGu5pFplQTWbarEu6a4egwAVUTBcjOnCk7reP4pV48BAAAAXJe4RBAAAAAADKFgAQAA\nAIAhFCwAAAAAMISCBQAAAACGULAAAAAAwBAKFgAAAAAYQsECAAAAAEMoWAAAAABgCAULAAAAAAyh\nYAEAAACAIRQsAAAAADCEggUAAAAAhni6egArHTp0SHPnztUPP/yggoIC3X333fr222/VrVs3DR06\ntOy41atXKycnR5MmTbrsmpMmTdLw4cPVrVu3cp+PjIzUli1b9N133+nAgQOKjIyscK3w8HB16tRJ\nklRcXCyHw6H58+crODhYkZGRuvHGG2W321VaWqqCggLNmjVLt99++xWmAAAArOAsckilTsv3KbWV\nKDc3t0rH5ufnV/nY8nh7e8vX1/eqXw/AjQvW+fPn9eSTT2rJkiVq2bKlSktL9Yc//EG33Xab0tLS\nLipYf/vb3/TnP//Z6P47duzQkSNHKi1YAQEBSklJKfvzhg0b9Oqrr+pPf/qTJCk5OVk+Pj6SpH/+\n859aunSpVq5caXROAABw5Ur+b44ce/OrZa9jOqEhi4ZUy152u10DBw7UhAkTqmU/wB25bcHavn27\nunXrppYtW0qSPDw8lJSUJC8vL73zzjs6fvy4mjdvrr1796pJkyZq0aJFhWutXbtWmzdvVtOmTfXd\nd99J+vGM0zPPPKOjR4/K4XBo4sSJZWe1SktL9dJLL+nChQvq1KmT6tWrp6VLl0qSLly4oKSkJIWE\nhFyyT1ZWlurXr1/uDJU9BwAAqld1lavq5nA4lJaWRsECroHbFqzs7GwFBwdf9Jifn58kaejQoXrz\nzTc1btw4paamavjw4RWu8/3332vNmjV66623ZLPZNGTIjz9B2rx5sxo2bKjZs2crJydHDz/8sN55\n5x1JP5a5MWPG6MiRI+rbt6/Wrl2ruXPnKjAwUCtWrNDWrVs1btw45ebmKjY2Vnl5eTp37pz69+9/\n0T9oo0aNUmFhobKzs9WrVy9NnTrVdEwAAOAq2Nv7yfFlvmT9FYLV6qczWACuntsWrGbNmumrr766\n6LFvv/1WJ0+eVFRUlEaOHKlRo0Zp165dio+Pr3CdI0eOKCwsTN7e3pKk9u3bS5IOHjyo9PR07d27\nV5JUUlKinJycctcIDAxUYmKi6tatq1OnTqlz586S/vcSwdLSUk2bNk1eXl5lJVD630sEFyxYoMzM\nTDVu3PjqAwEAAMZ49m4o510B1fIerBvr3qAX736mSsfu2bNHHTp0uOq9eA8WcO3ctmD16dNHK1eu\n1IMPPqibbrpJxcXFmjNnju666y7dcccdatWqlZYtW6Z77rlHnp4VxxAcHKzDhw/rwoUL8vLy0v79\n+zVo0CCFhoYqKChIY8eO1YULF7R8+XIFBASUvc5ut8vhcEiS4uPjtW3bNvn7+2vq1KlyOi/+x9jD\nw0OzZs1SVFSUunTpot69e1/0/MSJExUXF6d169bpoYceMhcSAAC4ajbv6rkZs0ddz4v+j1EZPz+/\nKh8LwBpuW7D8/f01Z84cxcfHy+l0Kj8/X3369NGIESMkSdHR0Xrssce0devWStdp1KiR/vCHP2j4\n8OFq1KhR2U91hg8frvj4eD388MPKy8vTiBEjZLf/7z+0rVu31vLly9WuXTtFRUUpOjpa9evXV5Mm\nTZSdnX3JPnXq1FFiYqKmTp2qrl27XvSc3W5XYmKiHnroIfXr10+BgYHXGg8AAAAAC9icvzydglrt\n0W1P6Xj+KVePAQAADGnuF6iX+71QpWPT09MVERFh8UTXH3I1z50zddszWFdq+/btWr169SWPx8XF\n6Z577qn+gQAAAADUOhSs/69v377q27evq8cAAAAAUItVz7szAQAAAOA6QMECAAAAAEMoWAAAAABg\nCAULAAAAAAyhYAEAAACAIRQsAAAAADCE27S7mcC6TV09AgAAMIjv7UDtQsFyMw/Wv0/hd4W7egy3\nkpGRofBwMjWNXK1BrtYgV/PIFIC74hJBN1NYWOjqEdwOmVqDXK1BrtYgV/PIFIC7omABAAAAgCEU\nLAAAAAAwhIIFAAAAAIZQsAAAAADAEAoWAAAAABhCwXIzPj4+rh7B7ZCpNcjVGuRqDXI1j0wBuCs+\nB8vNbMj9Qqc++Lurx3A/J8jUEuRqDXK1BrmaR6ZVEli3gZ7rEevqMQBUEQXLzZwqOKfjed+5egwA\nAADgusQlggAAAABgCAULAAAAAAyhYAEAAACAIRQsAAAAADCEggUAAAAAhlCwAAAAAMAQChYAAAAA\nGELBAgAAAABDKFgAAAAAYAgFCwAAAAAMoWABAAAAgCEULAAAAAAwxNPVA2RmZmrQoEFq165d2WPd\nunXT+PHjq7zGxo0bNWTIEHl5eVkxYrlOnTql/v37a86cObrvvvskSTt37tTEiRMVFhYmp9OpkpIS\nxcXFacCAAZKkEydOaM6cOTp79qwuXLigdu3aafr06fL29i53j3PnzmnKlCnKy8tTgwYN9Nxzz6lx\n48bV9jUCAIBr4ywqlUod17RGqUeRcnNzq3Rsfn5+pcd6e3vL19f3muYBUDmXFyxJCgsLU0pKylW/\nfuXKlRo8eLDBiS4vNTVVcXFxWrduXVnBkqTu3btr4cKFkn78Ry42NlYhISFq3bq1fv/73yshIUEd\nOnSQJD333HNavHixJk+eXO4eK1euVEREhMaOHatPPvlECxYsUGJiovVfHAAAuGbF/zgsx5cnrnmd\no5KGLHr32geSZLfbNXDgQE2YMMHIegAuVWMvEZw/f76GDx+umJgYbdmyRZK0a9cuxcXFKS4uTtHR\n0frmm2+0efNmnT59WpMmTdLOnTs1adKksjV69OghSZo2bZrGjh2r4cOHKzc3t9y1165dq2HDhikm\nJkZJSUmVzuZ0OpWWlqZHHnlExcXFOnjwYLnH+fn5KSYmRlu3blV6erqCgoLKypUkTZkyRY8//niF\n+xw+fFi/+tWvJEmdO3dWenp6FZIDAAA1gYlyZZrD4VBaWpqrxwDcWo0oWIcPH1ZsbGzZrzfffFOZ\nmZnasGGD1qxZoxUrVuj8+fM6dOiQ5s6dqzVr1igyMlJbt27VsGHD1LRp07KzRhXp3r27NmzYoN27\nd5e7dmpqqmbMmKGNGzcqODhYJSUlFa716aefqnXr1mrUqJEeeOABrV27tsJjGzdurJycHGVnZys4\nOPii53x8fCo9Td+2bVt9+OGHkqQPP/xQFy5cqPRrBAAANYf99hslm6unuJjdbldUVJSrxwDcWo28\nRHDVqlXat2+fYmNjJUklJSXKyspSYGCgEhMTVbduXZ06dUqdO3eudF2n01n2+5CQEEnSwYMHy137\n+eefV3JysubNm6eOHTte9Npf2rRpkzIzMzV69GgVFxfrwIEDFV7ml5WVpaCgIDVr1kzvv//+Rc/l\n5ORo9+7d6tOnT7mvHTNmjBITEzVy5Ej16tVLQUFBlX69AACg5vC6O0zOO0Ou+T1YN/o30sK7H63S\nsXv27Lnoaplf4j1YgPVqRMH6pdDQUHXr1k2zZs2Sw+HQsmXL1KJFC40cOVLbtm2Tv7+/pk6dWlaC\nbDabHA6HfHx8dPr0aUnS8ePHL3qTp81mq3TtF198Uc8++6x8fHw0evRoffHFF+ratesls509e1Z7\n9uzRtm3b5OHhIUmKj4/X3/72N7Vp0+aiY/Py8rR582YtWrRILVu2VGZmpvbu3av27dvL6XRq6dKl\n8vHxqbBgff7554qKilL37t313nvvXbZQAgCAmsXm7SHJ45rW8PD1VkBAQJWO9fPzq/KxAKxRIwtW\nZGSkdu3apREjRqigoED9+vWTv7+/oqKiFB0drfr166tJkybKzs6WJHXp0kVjxoxRcnKy6tWrp2HD\nhqlVq1Zq0aJFlddu06aNhg4dqoYNGyowMLDCn/6kpaWpf//+ZeVKkqKjo/XUU08pISFBO3bsUGxs\nrOx2u0pLS/XEE08oNDRUkrRo0SLNnDlTP/zwgwoKCtSxY0dNnDixwhxCQkI0depUSdINN9yg2bNn\nX3WmAAAAAKxnc1Z2LRxqncc+WKLjed+5egwAAGBIc//GWnXPE1U6Nj09XRERERZPdP0hV/PcOdMa\neQarJti+fbtWr159yeNxcXG65557jO41fvz4Sz6zwt/fX8uXLze6DwAAAABrUbAq0LdvX/Xt27da\n9lq6dGm17AMAAADAWjXiNu0AAAAA4A4oWAAAAABgCAULAAAAAAyhYAEAAACAIRQsAAAAADCEggUA\nAAAAhnCbdjcTWLeBq0cAAAAG8b0dqF0oWG5meEAnhfcId/UYbiUjI0Ph4WRqGrlag1ytQa7mkSkA\nd8Ulgm6msLDQ1SO4HTK1Brlag1ytQa7mkSkAd0XBAgAAAABDKFgAAAAAYAgFCwAAAAAMoWABAAAA\ngCEULAAAAAAwhILlZnx8fFw9gtshU2uQqzXI1Rrkah6ZAnBXfA6Wm9l47pAWvf+5q8dwP1lkagly\ntQa5WoNczTOQaVDdAM3q+X8MDAMAZlCw3MzJglxl5Z1z9RgAAADAdYlLBAEAAADAEAoWAAAAABhC\nwQIAAAAAQyhYAAAAAGAIBQsAAAAADKFgAQAAAIAhFCwAAAAAMISCBQAAAACGULAAAAAAwBAKFgAA\nAAAYQsECAAAAAEM8XT1AbXPo0CHNnTtXP/zwgwoKCnT33XfriSeeUE5OjpKSkpSVlaXS0lLdeOON\nmjZtmpo2bSqHw6GkpCQdPHhQdrtdXl5emjFjhoKDgxUbG6sffvhBvr6+ZXuMHj1avXv3dt0XCQCA\nhZxFJZLDYWStUo9C5ebmGlmrqry9vS/6vg0AP0fBugLnz5/Xk08+qSVLlqhly5YqLS3VH/7wB61f\nv15vv/22Ro0apX79+kmSPvnkE/3ud7/T5s2b9fHHHys7O1uvvvqqJGnbtm2aPXu2li9fLklKSkpS\nq1atXPZ1AQBQXYo/+lKlX/7X2HpHJQ1ZvMnYelVht9s1cOBATZgwoVr3BVA7cIngFdi+fbu6deum\nli1bSpI8PDyUlJSk8PBw1atXr6xcSdJdd92lm266SZ999pmCgoKUkZGhd999V2fPnlXfvn21aNGi\nSvfauXOnHn30UY0bN04DBw4sK2MAANRmJsuVqzgcDqWlpbl6DAA1FGewrkB2draCg4MveszPz0+Z\nmZmXPC5JwcHBysrKUvfu3TVr1ixt2rRJzz33nIKCgjRt2jR17dpVkjR16tSLLjX4qXxlZWXpzTff\nVFFRkXr16qVx48ZZ+NUBAGA9j9tbqjTjv5LT1ZNcvZ/OYAFAeShYV6BZs2b66quvLnrs22+/VZMm\nTXT8+PFLjj969KjuuusuHThwQCEhIVqwYIGcTqf+9a9/aeLEifrXv/4lqeJLBFu3bi1PT095enqq\nTp061nxRAABUI69f3S7P7m2NvQcryC9AC3sPN7JWVfEeLACVoWBdgT59+mjlypV68MEHddNNN6m4\nuFhz5szRXXfdpTNnzujDDz9UZGSkJOmjjz7S0aNH1bVrV61Zs0YHDhzQ7Nmz5eHhoVtuuUW+vr6y\n2WyV7ne55wEAqI1s3ub+++Hh66OAgABj6wHAtaJgXQF/f3/NmTNH8fHxcjqdys/PV58+fTRixAj9\n+te/1uzZs7Vy5UpJUlBQkF566SV5eHgoNjZWSUlJGjx4sPz9/WW32/XCCy+UrfvLSwTvu+8+bnoB\nAAAA1EI2p9NZi6+Cxi899v5qZeWdc/UYAABUi2b+DbSq/0hXj1FjpKenKyIiwtVjuB1yNc+dM+Uu\nggAAAABgCAULAAAAAAyhYAEAAACAIRQsAAAAADCEggUAAAAAhlCwAAAAAMAQChYAAAAAGELBAgAA\nAABDKFgAAAAAYIinqweAWUF1A1w9AgAA1YbvewBqGgqWm4lpcIvCe4a7egy3kpGRofBwMjWNXK1B\nrtYgV/PIFIC74hJBN1NYWOjqEdwOmVqDXK1BrtYgV/PIFIC7omABAAAAgCEULAAAAAAwhIIFAAAA\nAIZQsAAAAADAEAoWAAAAABhCwXIzPj4+rh7B7ZCpNcjVGuRqDXI1j0wBuCs+B8vNbDz3rRa995Wr\nx3A/x8nUEuRqDXK1BrmaR6YK8qunWT3vc/UYAAyiYLmZk/nfKyvvvKvHAAAAAK5LXCIIAAAAAIZQ\nsAAAAADAEAoWAAAAABhCwQIAAAAAQyhYAAAAAGAIBQsAAAAADKFgAQAAAIAhFCwAAAAAMISCBQAA\nAACGULAAAAAAwBAKFgAAAAAY4rKClZqaqnnz5l3y+KRJk1RUVFTh63r06HFN+yYmJiorK+uyx50+\nfVoJCQmSpMjISBUWFlZp/WnTpumjjz66lhH1wQcf6NSpU9e0BgAAqF7O4mI5LxRe0a/SHy4oNzf3\nqn798MMPrv6SAZTD09UD/NLChQstXX/GjBlVOq5p06ZlBau6rVmzRgkJCQoMDHTJ/gAA4MoUf/S5\nSjMOXfHrjkoasuS1q9rTbrdr4MCBmjBhwlW9HoA1LCtYqamp+utf/yqHw6EJEybozjvvvOSYPXv2\naNSoUTp79qwefPBBxcTEKDIyUlu2bNHJkyc1bdo0eXp6qnnz5jp+/LhSUlJUVFSk//mf/1FWVpYa\nNGigxYsXy8vLq9wZFi5cqB07dsjhcOj+++/XyJEjFRsbq4SEBL377rs6evSocnJylJubqxEjRuj9\n99/XN998o6SkJDVp0kRPPvmkNm3aVLbewYMHNWfOHDkcDp0/f17x8fHq3Lmz+vTpo9DQUIWGhkqS\n1q1bp1deeUWlpaVKTEzUzTffrJSUFL399tuy2WwaMGCA4uLiyl3v/Pnz2r9/v6ZOnarVq1dr8uTJ\nysvL04ULFzRlyhR169bNmr8wAABw1a6mXF0rh8OhtLQ0ChZQw1h6iWD9+vW1fv36csuVJHl6euqV\nV17R0qVL9dprF//05oUXXtDYsWOVkpKizp07lz1eUFCgSZMmaf369crLy9P+/fsr3P+NN97QvHnz\ntHbtWtWpU+eSSfHVfwAAIABJREFU5+vUqaNXXnlF/fv31z/+8Q+tWLFCY8aM0TvvvFPueocPHy4r\nPo888ohSU1MlSSdOnNC8efPKzo517txZr732mh577DHNnTtXhw8f1rvvvqt169Zp3bp12rZtm44c\nOVLuer1791bbtm2VlJSkEydO6MyZM1qxYoXmz5+vCxcuVB44AABwCY/wWySbrVr3tNvtioqKqtY9\nAVyepZcIhoSEVPr8bbfdJpvNpqZNm15SHr7++mt16tRJkhQREaG33npLkhQQEKAWLVpIkpo0aVLp\n9ccLFizQggULdObMGfXq1avc/SWpXr16CgsLK1u/ovdb3XDDDVq2bJnq1Kmj/Px8+fv7S5IaNmyo\nhg0blh3XpUsXSVKnTp30wgsv6ODBg8rKytLIkSMlSbm5uTp27FiF6/3klltu0UMPPaQnn3xSJSUl\nio2NrfBrBQAAruP1qy7yvLODVOq4otcF+dXTwj5XV5K8vb3l6+t7Va8FYB1LC5bdXvkJMlslP+lp\n3bq1vvjiC919993as2dPlV7zc0VFRdq6dasWLFggp9Op+++/X/fff3+V9y9PYmKi5s2bp1atWmnx\n4sU6fvy4pEu/zr1796pz5876/PPPdcsttyg0NFRhYWF6+eWXZbPZtHr1arVu3VqPP/54uevZbDY5\nnU795z//UX5+vl566SVlZ2dr+PDh6tOnzxXNDAAAqofNy0sq/10LFfLwraOAgABrBgLgEjXuJhc/\nmTx5sqZPn67k5GTVq1dPnp5XNqq3t7cCAgIUFRWlgIAA9ejRQ82aNbummQYNGqTf//73aty4sYKC\ngpSTk1PucXv27FFcXJxsNptmz56t5s2b684779SDDz6ooqIitW/fXoGBgRWu16lTJz311FNavny5\ndu3apTfeeENeXl5cYw0AAADUcDan0+l09RDlefPNN9WhQwfdfPPN2rx5s/7973/r+eefd/VYNd5j\n721SVt55V48BAACqoJl/fa26N9rYeunp6YqIiDC2Hn5Erua5c6aXPS10/PhxxcfH6/jx43r99dc1\nefJkzZ49u+x9UJeTkJCgr7/++pLHV61aVe6NJ35y4403atKkSfL19ZXdbtfs2bPLPW7v3r2aO3fu\nJY/fd999GjFiRJVmBAAAAAATLluw/vSnP2n06NGaP3++mjZtqt/85jeaOnWq1q5dW6UNrvazpO64\n446yu/RVpn379kpJSbmqPQAAAADApMvepj0nJ0c9e/aU0+mUzWZTdHS08vLyqmM2AAAAAKhVLluw\n6tSpo5MnT5bdce/zzz+Xt7e35YMBAAAAQG1z2UsEn376af3ud7/TsWPHFBUVpdzcXC1atKg6ZgMA\nAACAWuWyBeu7777TX/7yF/33v/9VaWmpQkNDOYMFAAAAAOW47CWCc+fOlZeXl2655RbdeuutlCsA\nAAAAqMBlz2AFBwfr6aefVocOHS66rfrgwYMtHQwAAAAAapvLFqyGDRtKkvbs2XPR4xQsAAAAALjY\nZQvW888/Xx1zwJAgv3quHgEAAFQR37cB93PZghUZGVl2i/af2759uyUD4drENAhWeM9wV4/hVjIy\nMhQeTqamkas1yNUa5GoemQJwV5ctWCkpKWW/Lykp0QcffKCioiJLh8LVKywsdPUIbodMrUGu1iBX\na5CreWQKwF1d9i6CzZs3L/t1880369FHH9W2bduqYzYAAAAAqFUuewbrs88+K/u90+nUoUOH+KkT\nAAAAAJTjsgVr8eLFZb+32Wxq2LCh5syZY+lQAAAAAFAbXbZg/fGPf1Tr1q0vemz37t2WDQQAAAAA\ntVWFBSs9PV0Oh0Px8fFKTEyU0+mU9OONLhISEvTee+9V25CoOh8fH1eP4HbI1Brkag1ytQa5mkem\nANxVhQXrk08+0a5du5Sdna1Fixb97ws8PRUTE1Mtw+HKbcrJ1uKtb7p6DPeTecTVE7gncrUGuVqD\nXM2zINMgP3/N7BVpfF0AqKoKC9YTTzwhSXrjjTc0ePDgahsI1+Zkfp6y8r539RgAAADAdemy78Hq\n2LGjnnvuORUUFMjpdMrhcCgzM1Nr166tjvkAAAAAoNa47OdgPfnkk6pfv77279+vtm3bKisrS7fc\nckt1zAYAAAAAtcplz2AVFxdrwoQJKikp0W233abo6Gg98MAD1TEbAAAAANQqlz2D5evrq6KiIrVs\n2VL79u1TnTp1qmMuAAAAAKh1LluwBg0apLFjx6p37956/fXX9eijjyowMLA6ZgMAAACAWuWylwg+\n/PDDGjx4sPz9/ZWSkqIvv/xSPXr0qI7ZAAAAAKBWuewZrKKiIr3++ut66qmn5O/vr//85z/y9Lxs\nLwMAAACA685lC9bMmTNVUFCgr776Sh4eHjp27JimT59eHbMBAAAAQK1y2YK1b98+Pfnkk/L09JSv\nr6+SkpJ04MCB6pgNAAAAAGqVyxYsm82moqIi2Ww2SVJOTk7Z7wEAAAAA/6vCgvXuu+9KkuLi4vTI\nI4/o9OnTSkxM1JAhQxQXF1dtAwIAAABAbVHh3SoWLlyo/v3767XXXtO8efO0Y8cOORwOrVy5Um3a\ntKnOGQEAAACgVqiwYHXp0kW33367nE6nfvOb38jpdJY9Z7PZtH//fmNDZGZmatCgQWrXrl3ZY926\nddP48eOrvMbGjRs1ZMgQeXl5GZurMnv37tWLL74op9Mph8Ohu+++W6NGjdLOnTs1ceJEhYWFyel0\nqqSkRHFxcRowYMBl11y9erXOnDmjyZMnS5Lee+89vfTSS7LZbIqJidGwYcOs/rIAAKg2zuJiqbTU\n6JqlHp7Kzc01uuYveXt7y9fX19I9ANReFRas559/Xs8//7zGjRun5cuXWz5IWFiYUlJSrvr1K1eu\n1ODBgw1OVLmZM2cqKSlJrVq1UnFxsYYPH67u3btLkrp3766FCxdKkvLz8xUbG6uQkBC1bdu23LUu\nXLig+Ph47d27V/3795cklZaWav78+frrX/+qunXrasCAAerbt68aNWpUPV8gAAAWKvrnpyrNMPfD\n2p/8V9KQpS8ZX/fn7Ha7Bg4cqAkTJli6D4Da6bI3uaiOclWR+fPna/jw4YqJidGWLVskSbt27VJc\nXJzi4uIUHR2tb775Rps3b9bp06c1adIk7dy5U5MmTSpb46cPRZ42bZrGjh2r4cOHKzc3t9y1165d\nq2HDhikmJkZJSUmVztasWTOtXbtWGRkZstvtWr9+vW677bZLjvPz81NMTIy2bt1a4VqFhYUaPHiw\nxo4dW/aYh4eH3n33XdWrV0/nzp0rWwsAAHdgRbmqLg6HQ2lpaa4eA0ANddmCVV0OHz6s2NjYsl9v\nvvmmMjMztWHDBq1Zs0YrVqzQ+fPndejQIc2dO1dr1qxRZGSktm7dqmHDhqlp06ZlZ40q0r17d23Y\nsEG7d+8ud+3U1FTNmDFDGzduVHBwsEpKSipca/bs2WrcuLESEhJ01113KSkpSUVFReUe27hxY+Xk\n5FS4VkBAgHr27HnJ456ennr//fcVFRWlLl268AHPAAC34RHeVqqldyW22+2Kiopy9RgAaqga8z/2\nX14iuGrVKu3bt0+xsbGSpJKSEmVlZSkwMFCJiYmqW7euTp06pc6dO1e67s/fOxYSEiJJOnjwYLlr\nP//880pOTta8efPUsWPHi177c4WFhdq3b58ef/xxPf7448rJydH06dO1ceNGtW7d+pLjs7KyFBQU\ndGWB/H/9+/dXv379NG3aNL3xxht64IEHrmodAABqEu9ed8rZvYvx92AF+flrQeSvja75S7wHC0Bl\nakzB+qXQ0FB169ZNs2bNksPh0LJly9SiRQuNHDlS27Ztk7+/v6ZOnVpWgmw2mxwOh3x8fHT69GlJ\n0vHjxy96o+tPn99V0dovvviinn32Wfn4+Gj06NH64osv1LVr10tms9lsmjJlil5++WW1bt1aDRs2\nVPPmzeXt7X3JsXl5edq8ebMWLVp0RV9/Xl6exo4dq+Tk5LJ/yO32GnPCEQCAa2bz8pIM35zKw9dX\nAQEBRtcEgCtRYwtWZGSkdu3apREjRqigoED9+vWTv7+/oqKiFB0drfr166tJkybKzs6W9ONdD8eM\nGaPk5GTVq1dPw4YNU6tWrdSiRYsqr92mTRsNHTpUDRs2VGBgoDp06FDubN7e3nrxxRf1pz/9SaWl\npbLZbLr99tv1wAMPKD09XTt27FBsbKzsdrtKS0v1xBNPKDQ09Iq+fn9/fw0cOFAPPfSQPD091aZN\nGw0aNOjKgwQAAABQbWzOiq6DQ600Zuubysr73tVjAADgEs386+mlX1+/P5BMT09XRESEq8dwO+Rq\nnjtnWmPPYNUE27dv1+rVqy95PC4uTvfcc88VrVVUVKTRo0df8nhISIhmzpx5tSMCAAAAqEEoWJXo\n27ev+vbta2Qtb2/va/qcLwAAAAA1H3dNAAAAAABDKFgAAAAAYAgFCwAAAAAMoWABAAAAgCEULAAA\nAAAwhIIFAAAAAIZQsAAAAADAED4Hy80E+fm7egQAAFyG74MAXI2C5WaiG96g8F6Rrh7DrWRkZCg8\nPNzVY7gdcrUGuVqDXM0jUwDuiksE3UxhYaGrR3A7ZGoNcrUGuVqDXM0jUwDuioIFAAAAAIZQsAAA\nAADAEAoWAAAAABhCwQIAAAAAQyhYbsbHx8fVI7gdMrUGuVqDXK1BruaRKQB3xW3a3cymnFwt2fqB\nq8dwP5knXD2BeyJXa5CrNcjVvGvINNCvrmb26mFwGAAwg4LlZk7lFygrL8/VYwAAAADXJS4RBAAA\nAABDKFgAAAAAYAgFCwAAAAAMoWABAAAAgCEULAAAAAAwhIIFAAAAAIZQsAAAAADAEAoWAAAAABhC\nwQIAAAAAQyhYAAAAAGAIBQsAAAAADKFgAQAAAIAhnq4eAAAAXD+cxUVSaek1r1Pq4aHc3FwDE5XP\n29tbvr6+lq0PwH1RsGqIb775Rk8//bQ8PT3l4eGhF154Qa+//ro+++wzOZ1OjRw5Uvfdd5+rxwQA\n4KoV/fMfKsn40sha30gasnSRkbXKY7fbNXDgQE2YMMGyPQC4Jy4RrCE++eQTtWvXTq+++qrGjh2r\n999/X5mZmdqwYYPWrFmjFStW6Pz5864eEwCAq2aqXFUHh8OhtLQ0V48BoBbiDFYNMXToUK1atUqP\nPvqo6tWrp1tvvVX79u1TbGysJKmkpERZWVmqX7++iycFAODqeIbfrpJ9GZLT6epRLuunM1gAcKUo\nWDXE9u3bFRERofHjx+vtt9/WggUL1KNHD82aNUsOh0PLli1TixYtXD0mAABXzbvX3fLqfqeR92AF\n+flrfuTdBqYqH+/BAnC1KFg1RHh4uKZMmaIlS5bIbrdr8eLFeuuttzRixAgVFBSoX79+8vf3d/WY\nAABcE5uXt+R17et4+PoqICDg2hcCAMMoWDXETTfdpI0bN170WHh4uIumAQAAAHA1uMkFAAAAABhC\nwQIAAAAAQyhYAAAAAGAIBQsAAAAADKFgAQAAAIAhFCwAAAAAMISCBQAAAACGULAAAAAAwBAKFgAA\nAAAY4unqAWBWoF9dV48AAIDl+H4HoKaiYLmZ6IYBCu/Vw9VjuJWMjAyFh4e7egy3Q67WIFdrkKt5\nZArAXXGJoJspLCx09Qhuh0ytQa7WIFdrkKt5ZArAXVGwAAAAAMAQChYAAAAAGELBAgAAAABDKFgA\nAAAAYAgFCwAAAAAMoWC5GR8fH1eP4HbI1Brkag1ytQa5mkemANwVn4PlZv6Sc0F/3vpPV4/hfjLJ\n1BLkag1ytQa5mlfFTAP9fJXQq4vFwwCAGRQsN3Mq/wdl5RW4egwAAADgusQlggAAAABgCAULAAAA\nAAyhYAEAAACAIRQsAAAAADCEggUAAAAAhlCwAAAAAMAQChYAAAAAGELBAgAAAABDKFgAAAAAYAgF\nCwAAAAAMoWABAAAAgCEULAAAAAAwxLO6NsrMzNSgQYPUrl27sse6deum8ePHV3mNjRs3asiQIfLy\n8rJixHKdOnVK/fv315w5c3TfffdJknbu3KmJEycqLCxMTqdTJSUliouL04ABAyRJJ06c0Jw5c3T2\n7FlduHBB7dq10/Tp0+Xt7V3pXh988IG2bt2q+fPnS5J2796txMREeXh4qGfPnleUFQAA1c1ZXCSV\nlhpft9RDys3NNb6uJHl7e8vX19eStQFcn6qtYElSWFiYUlJSrvr1K1eu1ODBgw1OdHmpqamKi4vT\nunXrygqWJHXv3l0LFy6UJOXn5ys2NlYhISFq3bq1fv/73yshIUEdOnSQJD333HNavHixJk+eXOE+\nzz33nD7++GO1bdu27LFnnnlGS5YsUXBwsMaMGaN9+/ZdVFABAKgpCv/5gYozvrBk7a8lDVlqydKy\n2+0aOHCgJkyYYM0GAK47Lr9EcP78+Ro+fLhiYmK0ZcsWSdKuXbsUFxenuLg4RUdH65tvvtHmzZt1\n+vRpTZo0STt37tSkSZPK1ujRo4ckadq0aRo7dqyGDx+u3Nzcctdeu3athg0bppiYGCUlJVU6m9Pp\nVFpamh555BEVFxfr4MGD5R7n5+enmJgYbd26Venp6QoKCiorV5I0ZcoUPf7445Xu1blzZyUkJJT9\nOS8vT0VFRbrppptks9nUs2dPffrpp5WuAQCAq1hVrqzmcDiUlpbm6jEAuJFqLViHDx9WbGxs2a83\n33xTmZmZ2rBhg9asWaMVK1bo/PnzOnTokObOnas1a9YoMjJSW7du1bBhw9S0adOys0YV6d69uzZs\n2KDdu3eXu3ZqaqpmzJihjRs3Kjg4WCUlJRWu9emnn6p169Zq1KiRHnjgAa1du7bCYxs3bqycnBxl\nZ2crODj4oud8fHwue/nBgAEDZLPZyv6cl5cnf3//sj/7+fnp+++/r3QNAABcxSu8k/Sz72O1hd1u\nV1RUlKvHAOBGXHqJ4KpVq7Rv3z7FxsZKkkpKSpSVlaXAwEAlJiaqbt26OnXqlDp37lzpuk6ns+z3\nISEhkqSDBw+Wu/bzzz+v5ORkzZs3Tx07drzotb+0adMmZWZmavTo0SouLtaBAwcqvMwvKytLQUFB\natasmd5///2LnsvJydHu3bvVp0+fSr+On/P391d+fn7Zn/Pz81W/fv0qvx4AgOrk0+seeXe/25L3\nYAX5+WpuZHfj60q8BwuAedVasH4pNDRU3bp106xZs+RwOLRs2TK1aNFCI0eO1LZt2+Tv76+pU6eW\nlSCbzSaHwyEfHx+dPn1aknT8+PGL3vj601mgitZ+8cUX9eyzz8rHx0ejR4/WF198oa5du14y29mz\nZ7Vnzx5t27ZNHh4ekqT4+Hj97W9/U5s2bS46Ni8vT5s3b9aiRYvUsmVLZWZmau/evWrfvr2cTqeW\nLl0qHx+fKy5YXl5eOnbsmIKDg/Xxxx9zkwsAQI1m8/KWLLgPlYdvXQUEBJhfGAAs4NKCFRkZqV27\ndmnEiBEqKChQv3795O/vr6ioKEVHR6t+/fpq0qSJsrOzJUldunTRmDFjlJycrHr16mnYsGFq1aqV\nWrRoUeW127Rpo6FDh6phw4YKDAy86L1SP5eWlqb+/fuXlStJio6O1lNPPaWEhATt2LFDsbGxstvt\nKi0t1RNPPKHQ0FBJ0qJFizRz5kz98MMPKigoUMeOHTVx4sQrzufZZ5/V5MmTVVpaqp49e1Y4KwAA\nAICaweas7Bo51Drjtv5TWXkFrh4DAABjmvnX1fJf93L1GLVCenq6IiIiXD2G2yFX89w5U5eewaoJ\ntm/frtWrV1/yeFxcnO655x6je40fP/6Sz/Hw9/fX8uXLje4DAAAAwDWu+4LVt29f9e3bt1r2WrrU\nog/xAAAAAFAjuPxzsAAAAADAXVCwAAAAAMAQChYAAAAAGELBAgAAAABDKFgAAAAAYAgFCwAAAAAM\nue5v0+5uAv18XT0CAABG8b0NQG1CwXIzQxvWUXivLq4ew61kZGQoPDzc1WO4HXK1Brlag1zNI1MA\n7opLBN1MYWGhq0dwO2RqDXK1Brlag1zNI1MA7oqCBQAAAACGULAAAAAAwBAKFgAAAAAYQsECAAAA\nAEMoWAAAAABgCAXLzfj4+Lh6BLdDptYgV2uQqzXI1TwyBeCu+BwsN5N6zq7l7/3b1WO4n+Nkagly\ntQa5WoNczbvKTAP96uhPPW8zPAwAmEHBcjOn8i/oRN4FV48BAAAAXJe4RBAAAAAADKFgAQAAAIAh\nFCwAAAAAMISCBQAAAACGULAAAAAAwBAKFgAAAAAYQsECAAAAAEMoWAAAAABgCAULAAAAAAyhYAEA\nAACAIRQsAAAAADDE09UDAACA64+zuFDO0tKrem2pR6lyc3OvaX9vb2/5+vpe0xoAUB4KVhXs3LlT\nEydOVFhYmCQpPz9fLVq00KRJk/TAAw+oXbt2kqTCwkLVrVtXixYtUkBAwFXtdfr0af35z39WQkKC\nqfEBAKhRfvjobRVl7JLkvKrXfy9pyJJrm8Fut2vgwIGaMGHCtS0EAL/AJYJV1L17d6WkpCglJUWp\nqany8vLShx9+qLCwsLLHN23apNtvv11/+ctfrnqfpk2bUq4AAG6tKGOnrrZcmeJwOJSWlubSGQC4\nJ85gXYWioiJlZ2ere/fuFz3udDp14sQJ3XTTTRW+dsmSJTp69KhycnKUm5urEf+PvbsPi6rO/z/+\nmhkYQEC8wRRTSjS3lKzVUlPS1bTaitVYNXWF/Go3thqp6XpbmplK2lqraZqa38xMTco2uzH199Xc\nVnMpM9ws7/J+xRvEQBluZn5/tLFrgoF+hgOH5+O6vC7nzDmf8563xxlenM8507ev1q5dq/379ysl\nJUWRkZEaPny4VqxYofj4eLVu3VrffvutHA6H5syZo/DwcH+/PAAA/Mod20Z5Oz+XfNaFrJ/OYAGA\naQSsUtqyZYsSExN16tQpOZ1O9erVS7fddpumTp2qxMREnTlzRh6PR/Hx8br//vsvOVZwcLAWLlyo\n+fPna+PGjXrllVe0atUqrVmzRg8++GDRejk5Obr33nv11FNP6cknn9SmTZt07733+vulAgDgVyEd\n7lPwbV0v+xqseqFBSunU4opq4BosAP5CwCqltm3baubMmcrMzNSAAQPUoEEDSSqaIpibm6tBgwap\ndu3aCgi4dFubNWsmSQoPDy+6risiIkIej6fEdaOioop9HgCAysgRGCRH4OVt6woJvuxrnQHA37gG\nq4xq1qyp6dOna/z48Tpx4kTR8uDgYM2YMUNz5szRrl27LjmGw+Eo9f7Ksi4AAAAAaxGwLkOTJk2U\nmJio11577YLlkZGR+tOf/qSnn35aXq/XouoAAAAAWMXh81l4hSmMG/zxFzqWnWt1GQAA+E1UWLBe\nvqul1WVUSGlpaWrVqpXVZdgOfTXPzj3lGiw/GTJkyEVfghgWFqa5c+daVBEAAAAAfyNg+cns2bOt\nLgEAAABAOeMaLAAAAAAwhIAFAAAAAIYQsAAAAADAEAIWAAAAABhCwAIAAAAAQwhYAAAAAGAIt2m3\nmbqhwVaXAACAX/FZB6AiI2DZTEINr2Lj+HZ7k9LT0xUbG2t1GbZDX/2DvvoHfTWPngKwK6YI2ozH\n47G6BNuhp/5BX/2DvvoHfTWPngKwKwIWAAAAABhCwAIAAAAAQwhYAAAAAGAIAQsAAAAADCFgAQAA\nAIAhBCybCQoKsroE26Gn/kFf/YO++gd9BQCUFt+DZTOrz0To1Y/3Wl2GzYRIR+ipefTVP+irf1Tc\nvl4V6ta4uIZWlwEA+DcCls1k5OTpWHa+1WUAAAAAVRJTBAEAAADAEAIWAAAAABhCwAIAAAAAQwhY\nAAAAAGAIAQsAAAAADCFgAQAAAIAhBCwAAAAAMISABQAAAACGELAAAAAAwBACFgAAAAAYEmB1AZdr\n9+7dmj59us6fP69z586pY8eOevzxx5WZmamUlBQdPXpUhYWFioqK0ujRo1WnTh2lpqZqzJgxWrFi\nhW666SZJUn5+vuLi4tSvXz89/vjjio2N1a9//WtJUkFBgRo3bqyJEyfqvffe0759+zRixIgL6ujc\nubOioqLkdP4nq44aNUpZWVlKSUnRihUrFBwcrOPHj+uhhx7SggULtGLFCkVGRiokJESrVq2Sx+PR\nnj171Lx5c0lSQkKCFi1apFWrVsntdkuSpk6dqsDAwIv2DwAAAKDiqJQB6+zZsxo+fLhmzZqla6+9\nVoWFhXriiSe0bNkyvf/++xowYIC6dOkiSfrss8/06KOPauXKlZKkmJgYvf/++0UB69NPP1V4eHjR\n2BEREVqyZEnR46FDh2rjxo2XrGfRokUKCgq6aHlcXJymTZumcePGadiwYRo9erTq1q1b9Hz37t3V\nvXt3HT58WMOHD79gv9u2bdOcOXM0dOhQffHFF0pLS9OyZcsuo1sAgIrEl58rX2GBsfEKXIHKysoy\nNt4vcbvdCgkJKbf9AUBlUykD1vr169WmTRtde+21kiSXy6WUlBTt3btXGzduLApXktSuXTtFR0dr\n27ZtkqQOHTpo8+bN8nq9cjqdWrNmje69995i95Ofn69z586pWrVql/XhNWzYMPXt21d//OMf1a5d\nO7Vv377U244dO1YJCQnq2rWrJk+erOnTpyswMLDMNQAAKo7sTcvlSf9Uks/YmJmSEmYZG+4XOZ1O\nxcfHKzk5ufx2CgCVSKW8BisjI0MNGza8YFloaKgOHz580XJJatiwoY4ePSpJCgwM1M0336zPP/9c\n2dnZys7OVr169YrWzcrKUmJiohITEzVw4EC1bt1at9122yXrGTBgQNE2Dz74YNHywMBA9erVS599\n9pkSEhLK9BrDwsI0efJkPfjgg+rZs6caN25cpu0BABWPJ32TTIYrK3i9Xq1evdrqMgCgwqqUZ7Dq\n16+vf/7znxcsO3TokCIjI3XkyJGL1j9w4IDatWunY8eOSZLuu+8+rVmzRseOHVPXrl2Vn59ftO7P\npwiWRkkU7kGKAAAgAElEQVRTBI8cOaIFCxZo5MiRGjlypF5//XW5XK5Sj9u6dWtVr169zOEMAFAx\nBcV2kGfnp5Kv8oasn85gAQCKVykDVqdOnTRv3jz16dNH0dHRys/P17Rp09SuXTudPHlSGzZsUOfO\nnSVJmzZt0oEDB9S6deui37i1adNGU6ZMUUZGhl544QX99a9/NV5jXl6ehg4dqrFjx6pjx45KT0/X\n7Nmz9cQTTxjfFwCgcgjr8IBCb+tm9BqsuqGBmtLpWmPj/RKuwQKAS6uUASssLEzTpk3T+PHj5fP5\nlJOTo06dOqlv3766++67NWXKFM2bN0+SVK9ePc2fP/+CM0dOp1Pt27fXsWPHFBYWVur9vvvuu/rs\ns8+KHv90pmvAgAEX3EUwKSlJW7ZsUatWrdSxY0dJ0sSJE5WQkKC2bdte0WsHAFRujsBgOQxeUhsQ\nEqiIiAhzAwIArojD56vE8xRwkSc+3qtj2fm/vCIAwBaiwgL10l2V7zrdtLQ0tWrVyuoybIe++gd9\nNc/OPa2UN7kAAAAAgIqIgAUAAAAAhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYAgBCwAA\nAAAMIWABAAAAgCEELAAAAAAwhIAFAAAAAIYEWF0AzLoq1G11CQCAcsT7PgBULAQsm+lWI0uxcbFW\nl2Er6enpio2lp6bRV/+gr/5BXwEApcUUQZvxeDxWl2A79NQ/6Kt/0Ff/oK8AgNIiYAEAAACAIQQs\nAAAAADCEgAUAAAAAhhCwAAAAAMAQApbNBAUFWV2C7dBT/6Cv/kFf/YO+AgBKi9u028wXWVHa8Mlx\nq8uwmTracIyemkdf/YO++gd9NaVGtQAlta9tdRkA4DcELJs5c65Ap7ILrS4DAAAAqJKYIggAAAAA\nhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYAgBCwAAAAAMIWABAAAAgCEELAAAAAAwhIAF\nAAAAAIYQsAAAAADAEAIWAAAAABhCwAIAAAAAQwKsLuAnhw8f1u9+9zs1b968aFmbNm00ZMiQUo+x\nfPlyJSQkKDAw0B8lXmTHjh168cUX5fP55PV61bFjRw0YMEBbt27V0KFD1aRJE/l8PhUUFCgpKUn3\n3HPPL465bds2jRgxQhs3btSJEyc0fPjwoue++eYbPfnkk+rTp48/XxYAAJdUmJcrb2H+ZW2b53Ip\nKytYOTk5ysrKuqwx3G63QkJCLmtbAPC3ChOwJKlJkyZasmTJZW8/b948de/e3WBFlzZp0iSlpKSo\ncePGys/PV+/evdW2bVtJUtu2bTVz5kxJUk5OjhITE9WoUSPdcMMNJY537NgxLVq0SAUFBZKkOnXq\nFPXjyy+/1MyZM9WrVy8/vyoAAEq2d+P/6tjX6yX5LnuMD1+6shqcTqfi4+OVnJx8ZQMBgB9U+CmC\nL7zwgnr37q0HHnhAH374oSTp888/V1JSkpKSktSrVy/t379fK1eu1IkTJzRs2DBt3bpVw4YNKxqj\nffv2kqTRo0dr0KBB6t27t7Kysoode+nSperZs6ceeOABpaSkXLK2+vXra+nSpUpPT5fT6dSyZcvU\nrFmzi9YLDQ3VAw88oI8++qjEsTwejyZMmKCJEyde9JzP59Ozzz6riRMnyuVy/WLPAADwl2Nfr9OV\nhCsTvF6vVq9ebWkNAFCSChWw9uzZo8TExKI/7733ng4fPqy33npLr7/+ul555RWdPXtWu3fv1vTp\n0/X666+rc+fO+uijj9SzZ0/VqVOn6KxRSdq2bau33npL27dvL3bs1NRUjRs3TsuXL1fDhg2LziYV\nZ8qUKapdu7YmTpyodu3aKSUlRXl5ecWuW7t2bWVmZpY41qRJkzRgwADVrVv3ouc2bNig6667TjEx\nMZd8bQAA+FvUjV0kh8PSGpxOp7p162ZpDQBQkgo9RfDVV1/Vzp07lZiYKEkqKCjQ0aNHVbduXT33\n3HOqVq2ajh8/rpYtW15yXJ/vP79pa9SokSTpu+++K3bsqVOnatGiRZoxY4ZuvvnmC7b9bx6PRzt3\n7tTgwYM1ePBgZWZmauzYsVq+fLmaNm160fpHjx5VvXr1ih3r+PHj+sc//qGDBw/q5ZdfVlZWloYN\nG1YUFt977z0lJSVd8jUCAFAeGnd8UNfe9sBlX4NVK8ylhzvW0VdffaWbbrrpssbgGiwAFVmFClg/\nFxMTozZt2ujZZ5+V1+vVnDlz1KBBA/Xv31/r1q1TWFiYRo0aVRSCHA6HvF6vgoKCdOLECUnSkSNH\nLriI1vHv37qVNPaLL76oZ555RkFBQRo4cKC+/PJLtW7d+qLaHA6HRo4cqQULFqhp06aqWbOmrr76\narnd7ovWzc7O1sqVK/XSS8VPOq9bt64+/vjjosft27e/4Ezczp07fzFEAgBQXlzuYLkUfFnbukNc\nioiIUGhoqCIiIgxXBgDWq9ABq3Pnzvr888/Vt29fnTt3Tl26dFFYWJi6deumXr16qXr16oqMjFRG\nRoYk6ZZbbtEjjzyiRYsWKTw8XD179lTjxo3VoEGDUo/9q1/9Sj169FDNmjVVt27dEn+75na79eKL\nL+rpp59WYWGhHA6HbrzxRv3+979XWlqatmzZosTERDmdThUWFurxxx+/rCl+p0+fVmhoaFEwBAAA\nAFBxOXwlzYFDpfSXT47rVHah1WUAAFCs2mEuJXetq7S0NLVq1crqcmyHvvoHfTXPzj2t0GewKoL1\n69dr8eLFFy1PSkpS165dyzRWXl6eBg4ceNHyRo0aadKkSZdbIgAAAIAKgoD1C+644w7dcccdRsZy\nu91X9D1fAAAAACq2CnWbdgAAAACozAhYAAAAAGAIAQsAAAAADCFgAQAAAIAhBCwAAAAAMISABQAA\nAACGELAAAAAAwBC+B8tmalTjnxQAUHHxOQXA7niXs5mWEccU2z7W6jJsJT09XbGx9NQ0+uof9NU/\n6CsAoLSYImgzHo/H6hJsh576B331D/rqH/QVAFBaBCwAAAAAMISABQAAAACGELAAAAAAwBACFgAA\nAAAYQsCymaCgIKtLsB166h/01T/oq3/QVwBAaXGbdps5dqaBdq89bXUZNlNfu4/SU/Poq3/QV/+o\nWH0Nq+ZU17gaVpcBACgGActmss95dTa70OoyAAAAgCqJKYIAAAAAYAgBCwAAAAAMIWABAAAAgCEE\nLAAAAAAwhIAFAAAAAIYQsAAAAADAEAIWAAAAABhCwAIAAAAAQwhYAAAAAGAIAQsAAAAADCFgAQAA\nAIAhAVYXYGfz58/X66+/rvXr1ysoKEizZs3S+++/r6uuuqponZEjR2rjxo0XLW/Xrp0ee+wxK8oG\nAAAAcJkIWH7017/+Vffcc4/WrFmjhIQESVL//v3Vp0+fC9bbuHFjscsBAJVbfl6uCr35xscNdLmU\nleUyPu7Pud1uhYSE+H0/AGAnBCw/2bp1q6Kjo9W7d2+NHDmyKGCVxfr167Vu3TpNnTpVktS9e3ct\nXLhQtWvXNl0uAMCwrZsW6duvP5Hk88v4C//il2Ev4HQ6FR8fr+TkZP/vDABsgoDlJytXrlTPnj0V\nExMjt9utr776SpK0ePFiffDBB5Kkpk2b6qmnnrpouSQNGjRIv/nNbzR9+nSdO3dOe/bsUXR0NOEK\nACqJb79ea3UJV8zr9Wr16tUELAAoAwKWH2RlZWnTpk06ffq0lixZouzsbL3xxhuKjo4ucSpgScvv\nuusurV27Vtu3b1fPnj3Lo3wAgAG/uvFOfZf+iXw+/5zBKg8/ncECAJQeAcsP3nvvPf3+97/XqFGj\nJEnnz5/XHXfcobCwMEVGRpZprB49emjChAnKzMzU008/7Y9yAQB+0KbDALVs29cv12CFh7p0729q\nGB/357gGCwDKjoDlBytXrtTzzz9f9DgkJER33nmnVq5cqXHjxhW7zc+nCDZq1EiTJk1Sw4YNJUl3\n3HGHnE7uqg8AlUmgO1iBCjY+bkiISxEREcbHBQBcOYevMs9dwEXeWXtaZ7MLrS4DAOBH1cNcuv/O\nWlaXcUXS0tLUqlUrq8uwHfrqH/TVPDv3lFMiAAAAAGAIAQsAAAAADCFgAQAAAIAhBCwAAAAAMISA\nBQAAAACGELAAAAAAwBACFgAAAAAYQsACAAAAAEMIWAAAAABgSIDVBcCssGpkZgCwO97rAaDiImDZ\nTFSNw4qNi7W6DFtJT09XbCw9NY2++gd99Q/6CgAoLX4FZjMej8fqEmyHnvoHffUP+uof9BUAUFoE\nLAAAAAAwhIAFAAAAAIYQsAAAAADAEAIWAAAAABhCwAIAAAAAQwhYNhMUFGR1CbZDT/2DvvoHffUP\n+goAKC2+B8tmzp9qqI1rTltdhs3U18YD9NQ8+uof9NU/Kmdfq4W5dGvHCKvLAIAqhYBlM+eyC3Uu\n22t1GQAAAECVxBRBAAAAADCEgAUAAAAAhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYAgB\nCwAAAAAMIWABAAAAgCEELAAAAAAwhIAFAAAAAIYQsAAAAADAEAIWAAAAABgSYHUB/rZ161a99dZb\nmjlzZtGyGTNmKCYmRpMnT1bz5s0lSR6PR9WqVdNLL72kiIgIv9WzadMmffDBB5o2bZqGDBmi2bNn\n+21fAIDKLS8/V4WF+Zc/gMuprCyXkVrcbrdCQkKMjAUAdmb7gHUpTZo00ZIlS4oev/DCC3r77bc1\ncODActk/4QoAUJJ1mxdp+z/XSvJd2UBzjZQjp9Op+Ph4JScnmxkQAGyqSges/+bz+XTs2DFFR0eX\nuM6sWbN04MABZWZmKisrS3379tXatWu1f/9+paSk6Oabb9aSJUv0/vvvy+Fw6J577lFSUpL27t2r\nsWPHKiQkRCEhIUVnyNq3b6+//e1v+vzzz4vCVm5urlJSUhQYGKgnn3xS9erV06FDh3TjjTfqmWee\nKZdeAACst/2fH1tdwgW8Xq9Wr15NwAKAX1AlAtaWLVuUmJhY9PjQoUNKTk7Wnj17lJiYqDNnzsjj\n8Sg+Pl7333//JccKDg7WwoULNX/+fG3cuFGvvPKKVq1apTVr1igsLEwffPCB3nzzTTkcDvXv319x\ncXF66aWXlJycrPbt22v+/Pnat2/fBWPu3r1b06dPV926dfXKK6/oo48+Unx8vL7//nstXLhQISEh\n6tKli06cOKE6der4pUcAgIrl5mZ36atv1srnu8IzWIb8dAYLAHBpVSJgtW3b9qJrsKT/TBHMzc3V\noEGDVLt2bQUEXLolzZo1kySFh4erSZMmkqSIiAh5PB599913Onr0qPr37y9JysrK0sGDB7V79261\naNFCktSyZcuLAlbdunX13HPPqVq1ajp+/LhatmwpSYqOjlZYWJgkqU6dOvJ4PFfYCQBAZdElboA6\ntOl7RddghYQ61a5rDSP1cA0WAJROlQhYvyQ4OFgzZsxQ9+7d1bJlS11//fUlrutwOEp8LiYmRk2a\nNNGCBQvkcDi0ePFiNW3aVDExMfryyy/VoUMHpaenX7Td+PHjtW7dOoWFhWnUqFFFv6281L4AAPbn\nDgyWAoMve/tqIU6/3rgJAHAxAta/RUZG6k9/+pOefvppvfXWW3I6y34H++uvv1633Xab+vTpo7y8\nPLVo0UJ169bVhAkTNGzYMC1cuFC1atVSUFDQBdt169ZNvXr1UvXq1RUZGamMjAxTLwsAAABAOXL4\nKsrkbhixcc1pncv2Wl0GAKACqBbmVMd7a1ldRrHS0tLUqlUrq8uwHfrqH/TVPDv3lDNYxRgyZIiy\nsrIuWBYWFqa5cw3d6xYAAACALRGwisH3UwEAAAC4HGW/0AgAAAAAUCwCFgAAAAAYQsACAAAAAEMI\nWAAAAABgCAELAAAAAAwhYAEAAACAIdym3WaqhbmsLgEAUEHwmQAA5Y+AZTMhtQ/p1o6xVpdhK+np\n6YqNpaem0Vf/oK/+QV8BAKXFFEGb8Xg8VpdgO/TUP+irf9BX/6CvAIDSImABAAAAgCEELAAAAAAw\nhIAFAAAAAIYQsAAAAADAEAIWAAAAABhCwLKZoKAgq0uwHXrqH/TVP+grAADW4nuwbMZ1tIG2f3fK\n6jJsJoqe+gV99Q/79TUozKUb7qxhdRkAAJQKActmPNmFyj1baHUZAAAAQJXEFEEAAAAAMISABQAA\nAACGELAAAAAAwBACFgAAAAAYQsACAAAAAEMIWAAAAABgCAELAAAAAAwhYAEAAACAIQQsAAAAADCE\ngAUAAAAAhhCwAAAAAMCQAKsLwI8mT56sL774QqGhoZKkOXPmKD8/XyNGjFBubq6uuuoqTZ06VSEh\nIRZXCgAl8+TnqtCbb3TMwlyXsrL883Hldrt5XwUAGEXAqiB27typBQsWqFatWkXLJk+erPvuu08J\nCQmaP3++li9frv79+1tXJABcwnufv6bPv/1EPvnMD77Q/JCS5HQ6FR8fr+TkZP/sAABQ5TBF0I9S\nU1P1xBNP6NFHH9Vvf/tbpaamKjExUc8995z69++vHj166MiRI/J6vTpw4ICefvpp9e7dW2+//bYk\nKS0tTbfffrskqUOHDvrss8+sfDkAcElbv13rn3DlR16vV6tXr7a6DACAjRCw/Cw7O1vz5s3T3Llz\nNX/+fElSixYttHjxYrVv315r1qzRuXPn1K9fP02fPl0LFizQm2++qV27dik7O1vh4eGSpNDQUP3w\nww9WvhQAuKQ2v7pTDofD6jLKxOl0qlu3blaXAQCwEaYI+tn1118vSYqKilJeXp4kqVmzZpKkevXq\n6eTJkwoJCVFSUlLRdQBt27bVrl27FBYWppycHAUHBysnJ0fVq1e35kUAQCn8rvX/6K5f9zF+DVZQ\nuEux99Y0OuZPuAYLAGAaAcvPSvPb3O+//17Dhg3TO++8I6/Xqy+++EL333+/WrZsqY0bNyohIUGb\nNm1Sq1atyqFiALh8QYHBkoKNjhkc7FJERITRMQEA8BcCVgXQuHFjxcfHq1evXgoMDFS3bt103XXX\n6bHHHtOoUaO0YsUK1axZUy+88ILVpQIAAAC4BAKWHyUkJBT9PSgoSBs2bLjg+T59+hT9/eGHH9bD\nDz98wfORkZFauNBPt84CAAAAYBw3uQAAAAAAQwhYAAAAAGAIAQsAAAAADCFgAQAAAIAhBCwAAAAA\nMISABQAAAACGELAAAAAAwBACFgAAAAAYQsACAAAAAEMCrC4AZgWFuawuAQCM4n0NAFCZELBsprD+\nYd0cG2t1GbaSnp6uWHpqHH31D/oKAIC1mCJoMx6Px+oSbIee+gd99Q/6CgCAtQhYAAAAAGAIAQsA\nAAAADCFgAQAAAIAhBCwAAAAAMISABQAAAACGELBsJigoyOoSbIee+gd99Q/6CgCAtfgeLJupse9q\n7d9+0uoybCVU9eipH9BX/zDV18DqLjX4XU0DFQEAULUQsGwm/2yh8rMKrS4DAAAAqJKYIggAAAAA\nhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYAgBCwAAAAAMIWABAAAAgCEELAAAAAAwhIAF\nAAAAAIYQsAAAAADAkACrC7DCtm3bFB4eruuvv97qUop0795d4eHhkqQGDRpo6tSp2r59u5577jm5\nXC7FxcVpyJAhFlcJAAAA4FKqZMBatWqV7rnnngoTsDwejyRpyZIlFyyfMGGCZs2apYYNG+qRRx7R\nzp071bx5cytKBFCJ5RbkqqAwv0zbBOa6lJUVWOZ9ud1uhYSElHk7AADswtKAlZqaqvXr1ys7O1uZ\nmZkaPHiwatasqZkzZ8rlcqlhw4aaNGmS/vrXv2rVqlXyer1KTk7W4cOHtWzZMnm9Xt1xxx16/PHH\n9eGHH2rx4sVyOp1q1aqVRowYoVmzZunw4cM6deqUjh49qjFjxqhmzZr69NNPtXPnTjVp0kQbNmzQ\n2rVrVVBQoPDwcM2aNUter1d/+tOflJGRoaioKG3btk2bN2/Wt99+q8mTJ0uSatSooSlTphSddfq5\n0aNHy+1268iRI8rIyNC0adPUvHlz3XnnnWrZsqX279+v2rVra9asWdq1a5fOnz+vAQMGqKCgQMOH\nD1eTJk2Ul5en6OhoSVJcXJz+/ve/E7AAlMlb21/Tpn3r5JOv7BsvK/smTqdT8fHxSk5OLvvGAADY\ngOXXYJ07d06vvfaaFi1apGnTpmnMmDGaPXu23njjDdWtW1fvvPOOJKl69epatmyZmjZtqldffVVv\nvvmmUlNT9cMPP+jo0aOaNWuWFi9erGXLlun48eP629/+JunH36YuWLBA48aN0+LFixUbG6vbb79d\nI0eOVL169XTmzBktXrxYb775pgoKCvT1119r+fLlatCggd566y0NGTJEp06dkiQ99dRTmjBhgpYs\nWaIOHTpowYIFl3xt9evX18KFC5WYmKjly5dLkg4dOqQnnnhCy5cv1+nTp/X1118rODhYAwcO1MKF\nC/XMM89oxIgRys7OVlhYWNFYoaGh+uGHH/zxTwDAxjbu++TywtVl8nq9Wr16dbntDwCAisbyKYK3\n3nqrnE6nIiMjFRISogMHDmjo0KGSpNzcXLVv317R0dFq1KiRpB8DynXXXafg4GBJ0tixY7Vjxw6d\nPn1ajzzyiCQpJydHhw4dkiTdcMMNkqR69eopLy/vgn07nU4FBgZq+PDhqlatmv71r3+poKBAe/fu\nVYcOHSRJjRs3Vq1atSRJe/fu1TPPPCNJys/PL6qpJP+97y+++EKSVLNmTUVFRUmSoqKi5PF41KxZ\nM11zzTVyOBxq1KiRatSoocLCQuXk5BSNlZOTo+rVq5e5vwCqto4xXS//DNZl+OkMFgAAVZXlAWvn\nzp2SpJMnT8rj8Sg6Olpz5sxReHi41q9fr2rVqunYsWNyOn882RYdHa19+/YpLy9PbrdbycnJGjVq\nlKKiorRo0SIFBgYqNTVVN9xwg9atWyeHw3HRPh0Oh3w+n3bt2qV169Zp5cqVOn/+vBISEuTz+dS0\naVN9+eWX6tKliw4ePKjMzExJUqNGjZSSkqL69esrLS1NJ06cuORrK2nfP/f222/ru+++08SJE3X8\n+HFlZ2erbt26CgwM1MGDB9WwYUNt3ryZm1wAKLPeN/+Pusf2Kfs1WNVdiu5Zq8z74xosAEBVZ3nA\nOnnypB588EH98MMPmjBhgpxOpx555BH5fD6Fhobq+eef17Fjx4rWr1Wrlh5++GH169dPDodDnTp1\n0tVXX63+/fsrMTFRhYWFuvrqq/Xb3/62xH3edNNNmjFjhv785z8rJCRECQkJcrvdqlOnjjIyMtSj\nRw+NHj1af/jDH1S/fn0FBQVJkiZOnKhRo0apsLBQkvTcc88Z6UGPHj00ZswY9enTRw6HQ1OmTFFA\nQEDRdMHCwkLFxcXppptuMrI/AFVLcECwFBBcpm0Cg12KiIjwU0UAANiXw+fzld/k/J9JTU3Vvn37\nNGLECKtKKNYXX3yhc+fOKS4uTt9//70eeughrVu3zuqySmX/GyeVn1VodRkAKrnACJca9Yu0uowK\nIy0tTa1atbK6DFuhp/5BX/2Dvppn555afgarImrYsKGGDx+u2bNnq6CgQE8//XSx6+Xl5WngwIEX\nLW/UqJEmTZrk7zIBAAAAVDCWBqyEhAQrd1+iOnXqXPSdVMVxu92lWg8AAABA1WD5bdoBAAAAwC4I\nWAAAAABgCAELAAAAAAwhYAEAAACAIQQsAAAAADCEgAUAAAAAhhCwAAAAAMAQAhYAAAAAGGLpFw3D\nvMDqLqtLAGADvJcAAHB5CFg2cybmiGJjY60uw1bS09PpqR/QV/+grwAAWIspgjbj8XisLsF26Kl/\n0Ff/oK8AAFiLgAUAAAAAhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFg2ExQUZHUJtkNP/YO+AgAA\nO+I27TZT/5s6OrHliNVl2Epd1aSnfkBfL+aKCFCtnnWtLgMAAFwBApbNFGYVqDCzwOoyAAAAgCqJ\nKYIAAAAAYAgBCwAAAAAMIWABAAAAgCEELAAAAAAwhIAFAAAAAIYQsAAAAADAEAIWAAAAABhCwAIA\nAAAAQwhYAAAAAGAIAQsAAAAADCFgAQAAAIAhBKwyeuONN4yNNWzYMOXl5RkbDwAAAIC1AqwuoLKZ\nO3eu+vXrZ2SsmTNnGhkHQMWWW5CrfG/BL67n8rjkzsoq09hut1shISGXWxoAADCMgHUJ+/fv15gx\nYxQQECCXy6W2bdsqKytLEydO1Lhx4zRhwgQdOHBAXq9XQ4cOVZs2bXTPPffolltu0e7duxUREaE/\n//nP+uijj7R+/XplZ2crMzNTgwcP1l133aXOnTvrww8/1IQJE+R2u3XkyBFlZGRo2rRpat68uVau\nXKmlS5cqIiJCgYGBuueee5SQkGB1WwCUweJ/vqF1B/+ffPKVboPUso3vdDoVHx+v5OTkshcHAACM\nY4rgJXz22Wdq3ry5XnvtNQ0aNEh33HGHIiIiNHHiRK1cuVI1a9bU0qVLNWfOHE2aNEmSlJubq/j4\neC1btkwxMTFavny5JOncuXN67bXXtGjRIk2bNk0FBRf+Nrt+/fpauHChEhMTtXz5cp0+fVoLFizQ\nsmXLtGjRIp0/f77cXz+AK/fJwQ2lD1eXwev1avXq1X4bHwAAlA0B6xJ69OihmjVr6qGHHtLSpUvl\ncrmKnvvuu++0adMmJSYmKjk5WQUFBcrMzFRAQIBuvfVWSVLLli21f/9+SdKtt94qp9OpyMhIVa9e\nXadPn75gXzfccIMkqV69esrLy9PBgwfVuHFjhYSEyOVy6de//nU5vWoAJnWN7iyHHH4b3+l0qlu3\nbn4bHwAAlA1TBC9h/fr1atWqlYYMGaL3339fCxYskM/342+iY2JiVK9ePQ0aNEi5ubmaO3euIiIi\nVFBQoF27dun6669XWlqamjRpIknauXOnJOnkyZPKzs5W7dq1L9iXw3HhD2DR0dHat2+fcnNz5Xa7\ntQ5nhqQAABeySURBVGPHDsXExJTDqwZgUv9m/dS7aY/SXYNVw6Xa/aLKND7XYAEAULEQsC4hNjZW\nI0eO1KxZs+R0OjVmzBgdPnxYI0aM0JQpUzR+/Hj169dP2dnZ6tu3r5zOH08Ivvrqqzp69Kjq16+v\nYcOG6f3339fJkyf14IMP6ocfftCECRMuOBtWnFq1aunhhx9W3759VaNGDXk8HgUE8M8FVEbBAcEK\nLsV6rqAARURE+L0eAADgP/zEfgnR0dFF11D9ZMmSJUV/f/7554vdbsqUKQoKCrpg2a233qoRI0Zc\nsGzDhg2SpGnTphUt69Chgzp06KCCggJlZGQoNfXHK97/8Ic/KCqqbL/ZBgAAAFC+CFgVVEBAgM6f\nP6/7779fgYGBatGihW655RarywIAAABwCQQsw346K/XfLvfW6sOHD9fw4cOvtCQAAAAA5YS7CAIA\nAACAIQQsAAAAADCEgAUAAAAAhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYAjfg2Uzrgj+\nSYHKiv+/AABUfnya28zRG04oNjbW6jJsJT09nZ76AX0FAAB2xBRBm/F4PFaXYDv01D/oKwAAsCMC\nFgAAAAAYQsACAAAAAEMIWAAAAABgCAELAAAAAAwhYAEAAACAIQQsmwkKCrK6BNuhp/5BXwEAgB3x\nPVg2c/V3ITq57Rury7CVenLRUz+oCn11RbhVM6Gx1WUAAIByRMCymcKsPBWe4fuFAAAAACswRRAA\nAAAADCFgAQAAAIAhBCwAAAAAMISABQAAAACGELAAAAAAwBACFgAAAAAYQsACAAAAAEMIWAAAAABg\nCAELAAAAAAwhYAEAAACAIQQsAAAAADAkwOoCqrrdu3dr+vTpOn/+vM6dO6eOHTvq0KFDatOmjXr0\n6FG03uLFi5WZmalhw4ZZWC0AAACASyFgWejs2bMaPny4Zs2apWuvvVaFhYV64okn1KxZM61evfqC\ngPXOO+/o5ZdftrBaAP8tt8CjfG/BJddxefIVmJVV6jHdbrdCQkKutDQAAGAhApaF1q9frzZt2uja\na6+VJLlcLqWkpCgwMFBr1qzRkSNHdPXVV2vHjh2KjIxUgwYNrC0YgCTpta9Tte7AZ/LJ98srryz9\nuE6nU/Hx8UpOTr784gAAgKW4BstCGRkZatiw4QXLQkND5Xa71aNHD7333nuSpNTUVPXu3duKEgEU\n45MDfytduCojr9er1atXGx8XAACUHwKWherXr69//etfFyw7dOiQtm3bpm7duunDDz+Ux+PR559/\nrk6dOllUJYCf63pNeznkMD6u0+lUt27djI8LAADKD1MELdSpUyfNmzdPffr0UXR0tPLz8zVt2jS1\na9dOt956qxo3bqw5c+aoa9euCgjgnwqoKP7nxgT1ueHeX74GK8KtWn2alnpcrsECAKDy46d2C4WF\nhWnatGkaP368fD6fcnJy1KlTJ/Xt21eS1KtXLz388MP66KOPLK4UwM8FBwQpWEGXXMcVFKSIiIhy\nqggAAFQEBCyLxcbG6vXXXy/2udtuu03p6enlXBEAAACAy8U1WAAAAABgCAELAAAAAAwhYAEAAACA\nIQQsAAAAADCEgAUAAAAAhhCwAAAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYEiA1QXALFeE2+oS\nAPwb/x8BAKh6CFg2c6TpecXGxlpdhq2kp6fTUz+grwAAwI6YImgzHo/H6hJsh576B30FAAB2RMAC\nAAAAAEMIWAAAAABgCAELAAAAAAwhYAEAAACAIQQsAAAAADCEgGUzQUFBVpdgO/TUP+grAACwI74H\ny2au3uPTyS+2WV2GrdST6KkfVIW+uqoHq2b3G60uAwAAlCMCls0Uns1V4ZnzVpcBAAAAVElMEQQA\nAAAAQwhYAAAAAGAIAQsAAAAADCFgAQAAAIAhBCwAAAAAMISABQAAAACGELAAAAAAwBACFgAAAAAY\nQsACAAAAAEMIWAAAAABgCAELAAAAAAwJsLoAuzt8+LCGDx+uFStWlLhO586dFRUVJafzP3l31KhR\nio2NLY8SAQAAABhCwKogFi1apKCgIKvLAHAZcgvylO8tuGi5K9erwKysErdzu90KCQnxZ2kAAKCc\nEbDKSWJiomrWrKmzZ8/q3nvv1bvvviuv16vk5OQStxkyZIiSkpLUunVr7dixQ3PnztXcuXPLsWoA\nv+S1HR9o3f5t8pW0wvKSt3U6nYqPj7/k+wAAAKhcCFjlKD4+Xl27dlVqaqqqV69+QVgaMGBA0RRB\np9Op//3f/1XPnj31zjvvqHXr1nrnnXfUq1cvq0oHUIJP9m+77G29Xq9Wr15NwAIAwEYIWOWoUaNG\nxf5dKn6K4O23367p06frzJkz+sc//qHx48eXS50ASq9ro1u1bv8/5Cv5HFaJfjqDBQAA7IOAVY4c\nDkfR3//7hhYlcTqduvvuuzVx4kR16dJFLpfLn+UBuAz/0+Ie9WnWpfhrsKoHq9YDvy5xW67BAgDA\nfghYFcR/TxGUpKSkJHXt2lW///3v1aVLF3388ccWVgfgUoID3AqW+6LlruAQRUREWFARAACwCgHL\nzxo0aHDRLdoTEhIueLxhw4YSt4+KitLOnTv9UhsAAAAAs/iiYQAAAAAwhIAFAAAAAIYQsAAAAADA\nEAIWAAAAABhCwAIAAAAAQwhYAAAAAGAIAQsAAAAADCFgAQAAAIAhBCwAAAAAMCTA6gJglqt6sNUl\nAPg3/j8CAFD1ELBs5kgTh2Jjb7W6DFtJT09XbGys1WXYDn0FAAB2xBRBm/F4PFaXYDv01D/oKwAA\nsCMCFgAAAAAYQsACAAAAAEMIWAAAAABgCAELAAAAAAwhYAEAAACAIQQsmwkKCrK6BNuhp/5BXwEA\ngB3xPVg202Bfjk5t/39Wl2ErURI99YOK1FdX9Wqq8bs2VpcBAABsgIBlM4Vnz6nwTI7VZQAAAABV\nElMEAQAAAMAQAhYAAAAAGELAAgAAAABDCFgAAAAAYAgBCwAAAAAMIWABAAAAgCEELAAAAAAwhIAF\nAAAAAIYQsAAAAADAEAIWAAAAABhCwAIAAAAAQwKsLqCy2rp1q4YOHaomTZpIknJyctSgQQPNmDFD\nbrf7kttu2rRJH3zwgaZNm6YhQ4Zo9uzZ5VEyAEm5BXnKLyy8YJkr16GArKxi13e73QoJCSmP0gAA\ngA0QsK5A27ZtNXPmzKLHTz75pDZs2KC777671GMQroDy89pXG/TJvq/kK+7JZX8udhun06n4+Hgl\nJyf7tTYAAGAPTBE0JC8vTxkZGYqIiNC4ceM0cOBAJSQk6MUXX5Qk7d27Vw888ID69++vZcuWFW3X\nvn17SVJiYqL27t0rSVq2bJlmzZolj8ejQYMGqV+/furRo4e2bt1a/i8MsJG1JYWrS/B6vVq9erVf\n6gEAAPbDGawrsGXLFiUmJurUqVNyOp3q1auXGjZsqJtvvlk9e/aUx+NRhw4dNHToUL300ktKTk5W\n+/btNX/+fO3bt+8Xxz948KBOnjypxYsX69SpU/r+++/9/6IAG7sz5iZ9sm+HfGWIWT+dwQIAACgN\nAtYV+GmKYGZmpgYMGKAGDRqoRo0a+vrrr7VlyxaFhYUpLy9PkrR79261aNFCktSyZctLBiyf78cf\n/q677jr94Q9/0PDhw1VQUKDExET/vyjAxv7nps7q0zzu4muwIqqpZs+4YrfhGiwAAFAWBCwDatas\nqenTpyspKUl9+/ZVeHi4Jk2apAMHDmjFihXy+XyKiYnRl19+qQ4dOig9Pf2iMdxut06cOKHGjRvr\nn//8p+rWratvv/1WOTk5mj9/vjIyMtS7d2916tTJglcI2EdwgFvBP3vncwVXU0REhDUFAQAAWyFg\nGdKkSRMlJibqm2++0f79+5WWlqaQkBBdc801ysjI0IQJEzRs2DAtXLhQtWrVUlBQ0AXbJyUladKk\nSYqKitJVV10lSbr22mv18ssv691331VgYCAX2QMAAAAVHAHrMrVp00Zt2rS5YNljjz12yW2WLl16\n0bK//e1vkqSOHTuqY8eOFz3/l7/85QqqBAAAAFCeuIsgAAAAABhCwAIAAAAAQwhYAAAAAGAIAQsA\nAAAADCFgAQAAAIAhBCwAAAAAMISABQAAAACGELAAAAAAwBACFgAAAAAYEmB1ATDLVb2a1SUAlQ7/\nbwAAgCkELJs5HBOq2Ng2VpdhK+np6YqNjbW6DNuhrwAAwI6YImgzHo/H6hJsh576B30FAAB2RMAC\nAAAAAEMIWAAAAABgiMPn8/msLgIAAAAA7IAzWAAAAABgCAELAAAAAAwhYAEAAACAIQQsAAAAADCE\ngAUAAAAAhhCwAAAAAMAQAhYAAAAAGBJgdQG4cl6vVxMnTtS3334rt9utyZMn65prrrG6rErhq6++\n0owZM7RkyRIdOHBAo0ePlsPh0HXXXacJEybI6XRq9uzZ+r//+z8FBARo7NixatGiRYnrVnX5+fka\nO3asjhw5ory8PD322GNq0qQJfb1ChYWFGj9+vPbv3y+Xy6WpU6fK5/PRV0NOnTqlhIQELVq0SAEB\nAfTVgO7duys8PFyS1KBBAz3wwAN67rnn5HK5FBcXpyFDhpT42bV9+/aL1oU0b948bdiwQfn5+erT\np49at27NsXqFUlNT9c4770iSPB6PvvnmGy1ZsoRj9Qrl5+dr9OjROnLkiJxOp5599tmq997qQ6X3\n8ccf+0aNGuXz+Xy+L7/80jdo0CCLK6oc5s+f77vvvvt8PXv29Pl8Pt+jjz7q27Jli8/n8/meeuop\n39q1a33p6em+xMREn9fr9R05csSXkJBQ4rrw+d5++23f5MmTfT6fz3f69Glfx44d6asBn3zyiW/0\n6NE+n8/n27Jli2/QoEH01ZC8vDzfH//4R9+dd97p27NnD301IDc319etW7cLlv3ud7/zHThwwOf1\nen0PPfSQLz09vcTPruLWreq2bNnie/TRR32FhYW+7Oxs31/+8heOVcMmTpzoe+uttzhWDfjkk098\nycnJPp/P59u8ebNvyJAhVe54rWRxEMVJS0vT7bffLkm6+eablZ6ebnFFlUN0dLRmzZpV9Hjnzp1q\n3bq1JKlDhw767LPPlJaWpri4ODkcDtWvX1+FhYU6ffp0setCuvvuu/XEE08UPXa5XPTVgC5duujZ\nZ5+VJB09elSRkZH01ZCUlBT17t1bV111lSTeB0zYtWuXzp8/rwEDBigpKUnbtm1TXl6eoqOj5XA4\nFBcXp7///e/FfnZlZ2cXu25Vt3nzZjVt2lSDBw/WoEGD9Jvf/IZj1aCvv/5ae/bs0b333suxakCj\nRo1UWFgor9er7OxsBQQEVLnjlYBlA9nZ2QoLCyt67HK5VFBQYGFFlcNdd92lgID/zJL1+XxyOByS\npNDQUP3www8X9fan5cWtix97ERYWpuzsbCUnJ2vo0KH01ZCAgACNGjVKzz77rO666y76akBqaqpq\n1apV9IOTxPuACcHBwRo4cKAWLlyoZ555RmPGjFFISEjR8yX11eVyldjrqi4zM1Pp6el66aWX9Mwz\nz2jEiBEcqwbNmzdPgwcPLrF/HKtlU61aNR05ckS//e1v9dRTTykxMbHKHa9cg2UDYWFhysnJKXrs\n9XovCA4onf+e35uTk6Pq1atf1NucnByFh4cXuy5+dOzYMQ0ePFh9+/ZVfHy8pk+fXvQcfb0yKSkp\nGjFihHr16iWPx1O0nL5enlWrVsnhcOjvf/+7vvnmG40aNUqnT58uep6+Xp5GjRrpmmuukcPhUKNG\njRQeHq4zZ84UPf9Tr3Jzcy/67Cqu1/RVqlGjhmJiYuR2uxUTE6OgoCD961//KnqeY/XynT17Vvv2\n7VPbtm2VnZ1d7PHHsVo2ixcvVlxcnJ588kkdO3ZMDz74oPLz84uerwrHK2ewbKBly5batGmTJGn7\n9u1q2rSpxRVVTs2aNdPWrVslSZs2bdItt9yili1bavPmzfJ6vTp69Ki8Xq9q1apV7LqQTp48qQED\nBmjkyJHq0aOHJPpqwrvvvqt58+ZJkkJCQuRwOBQbG0tfr9DSpUv1xhtvaMmSJbrhhhuUkpKiDh06\n0Ncr9Pbbb2vatGmSpOPHj+v8+fOqVq2aDh48KJ/Pp82bNxf19eefXWFhYQoMDLxo3aquVatW+vTT\nT+Xz+Yp6etttt3GsGrBt2za1a9dOkko8/jhWy6Z69epFN7mJiIhQQUFBlftZwOHz+XxWF4Er89Pd\nbb777jv5fD5NmTJFjRs3trqsSuHw4cMaPny4VqxYof379+upp55Sfn6+YmJiNHnyZLlcLs2aNUub\nNm2S1+vVmDFjdMstt5S4blU3efJkffjhh4qJiSlaNm7cOE2ePJm+XoFz585pzJgxOnnypAoKCvTw\nww+rcePGHK8GJSYmauLEiXI6nfT1CuXl5WnMmDE6evSoHA6HRowYIafTqSlTpqiwsFBxcXEaNmxY\niZ9d27dvv2hdSM8//7y2bt0qn8+nYcOGqUGDBhyrBixYsEABAQHq37+/JBV7/HGslk1OTo7Gjh2r\nEydOKD8/X0lJSYqNja1SxysBCwAAAAAMYYogAAAAABhCwAIAAAAAQwhYAAAAAGAIAQsAAAAADCFg\nAQAAAIAhBCwAAIrx9ddfa9y4ceWyrx07dlzwpdwAgMorwOoCAACoiG688UbdeOON5bKvPXv26NSp\nU+WyLwCAf/E9WAAAFGPr1q2aPfv/t3MHIVFtcRzHv8M1nYsKgpFioIhpqFAIQjpEoOFKx6xARRQn\nkMRFK3XjQlqkC3Wls1EQpgRzkSEWRCBIUJqCaDGhCKNCojmEZpTiNN55i8cbXijIe296Qvw+q8Pl\nf86552wuf/7nHjcAOTk5zM3NcXBwQEtLC48ePcLn8+FyuXC5XPT19bGxsYHP52NnZ4eqqioaGhqw\nLIvOzk6mp6ex2WyUl5dz9+5dZmZm6O7uxrIskpKSWFxcZG9vjzt37lBXV0dbWxtbW1v4/X4KCwvp\n6OhgdnaW/v5+7HY7Pp+Pixcv0tPTQ3R0NB6Ph8ePH2MYBkVFRbS2tvL582fa29v59OkTNpuN5uZm\nHA7HKe+qiMjvTxUsERGRE4RCIZ48eYLb7ebBgweMj4+zvb1NRUUFLpcLAK/Xy8jICJZlcevWLQoL\nC1lYWGBzc5Px8XECgQB1dXVkZWVhmiZra2tMTk4SHx/P06dPmZ2dpampiefPn5OdnU1vby+BQIDS\n0lI+fPgAwPz8PC9evODcuXNUVlby+vVrzp49y/DwMKOjo5imSUNDA16vl8HBQW7fvs3169fx+/3U\n1NQwNjZGXFzcKe6kiMjvTwmWiIjICa5duwZASkoKly9fxjRNzp8/z9evX8MxZWVlxMbGAlBcXMzb\nt2959+4dN2/exDAMTNPE6XQyPT1NcXEx6enpxMfHH5mrrKyM9+/f4/F4WFlZ4cuXL+zt7QGQmZlJ\ncnIyABkZGezu7rK6ukpRUVF4LI/HA8DU1BQrKyv09vYCEAwG+fjxI9nZ2b9mk0REBFCCJSIicqIz\nZ86E21FRx386DcMIty3LwjAMLMv6KSYUCnF4eAiA3W4/dpyhoSFevnxJZWUlDoeD5eVl/jrNHxMT\nE46z2WyEQiGioqKw2Wzh51tbW5imiWVZPHz4kISEBAD8fj+JiYn/ZNkiIvIv6BZBERGRCJiYmCAQ\nCLC7u8vk5CRXr16loKCAsbExDg8P2d/f59mzZ1y5cuVIX8MwCAaDALx584aqqirKy8s5ODhgaWnp\nSKL2d/n5+bx69Yrv378TDAZpbm7G6/VSUFDA8PAw8OclGk6nk/39/V+zeBERCVMFS0REJAJiYmKo\nqanh27dvNDY2cuHCBdLS0lhbW+PGjRv8+PEDp9NJSUkJMzMzP/W9dOkSbrebnp4e6uvruX//PgMD\nA8TFxZGXl8f6+jqpqanHzpubm0ttbS3V1dVYlkVJSQkOh4OMjAza29txOp0AdHV16f8rEZH/gW4R\nFBER+Y/6+voAuHfv3im/iYiInDYdERQREREREYkQVbBEREREREQiRBUsERERERGRCFGCJSIiIiIi\nEiFKsERERERERCJECZaIiIiIiEiEKMESERERERGJkD8AUxSVHOnRImwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:200].index.tolist()\n",
    "top_fea = display_importances(\"lightgbm\",feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Features_SD_55',\n",
       " 'rr_var_2',\n",
       " 'Features_CP_18',\n",
       " 'Features_SD_64',\n",
       " 'Features_SD_48',\n",
       " 'sample_entropy_1',\n",
       " 'Features_ADC_6',\n",
       " 'sk_RR',\n",
       " 'sample_entropy_2',\n",
       " 'lorenz_plot',\n",
       " 'Features_ADC_9',\n",
       " 'CV_deltaRR',\n",
       " 'r_high_similarbeats',\n",
       " 'RR_min',\n",
       " 'Features_SD_13',\n",
       " 'se',\n",
       " 'COSEn',\n",
       " 'Features_ADC_10',\n",
       " 'Features_SD_47',\n",
       " 'HR_median',\n",
       " 'COMPLEXITY',\n",
       " 'AFEv',\n",
       " 'nn50',\n",
       " 'percentage_nn50',\n",
       " 'stepping',\n",
       " 'IrrEv',\n",
       " 'CV',\n",
       " 'Radius',\n",
       " 'OriginCount',\n",
       " 'MOBILITY']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "[0]\ttrain-mlogloss:1.37383\tval-mlogloss:1.37406\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.538175\tval-mlogloss:0.579846\n",
      "[400]\ttrain-mlogloss:0.409228\tval-mlogloss:0.49185\n",
      "[600]\ttrain-mlogloss:0.360056\tval-mlogloss:0.476196\n",
      "[800]\ttrain-mlogloss:0.328202\tval-mlogloss:0.47345\n",
      "[1000]\ttrain-mlogloss:0.303634\tval-mlogloss:0.474026\n",
      "[1200]\ttrain-mlogloss:0.282347\tval-mlogloss:0.475812\n",
      "Stopping. Best iteration:\n",
      "[826]\ttrain-mlogloss:0.324776\tval-mlogloss:0.473417\n",
      "\n",
      "fold:  1  training\n",
      "[0]\ttrain-mlogloss:1.37372\tval-mlogloss:1.37405\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.53605\tval-mlogloss:0.590715\n",
      "[400]\ttrain-mlogloss:0.408405\tval-mlogloss:0.507597\n",
      "[600]\ttrain-mlogloss:0.358465\tval-mlogloss:0.494796\n",
      "[800]\ttrain-mlogloss:0.326152\tval-mlogloss:0.493704\n",
      "[1000]\ttrain-mlogloss:0.300706\tval-mlogloss:0.496473\n",
      "[1200]\ttrain-mlogloss:0.279485\tval-mlogloss:0.500765\n",
      "Stopping. Best iteration:\n",
      "[721]\ttrain-mlogloss:0.33762\tval-mlogloss:0.493262\n",
      "\n",
      "fold:  2  training\n",
      "[0]\ttrain-mlogloss:1.37375\tval-mlogloss:1.3744\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.5374\tval-mlogloss:0.607051\n",
      "[400]\ttrain-mlogloss:0.410595\tval-mlogloss:0.520471\n",
      "[600]\ttrain-mlogloss:0.360558\tval-mlogloss:0.504106\n",
      "[800]\ttrain-mlogloss:0.329088\tval-mlogloss:0.501449\n",
      "[1000]\ttrain-mlogloss:0.30398\tval-mlogloss:0.501858\n",
      "[1200]\ttrain-mlogloss:0.28208\tval-mlogloss:0.504174\n",
      "Stopping. Best iteration:\n",
      "[887]\ttrain-mlogloss:0.31809\tval-mlogloss:0.501157\n",
      "\n",
      "fold:  3  training\n",
      "[0]\ttrain-mlogloss:1.3737\tval-mlogloss:1.37416\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.536133\tval-mlogloss:0.598582\n",
      "[400]\ttrain-mlogloss:0.408296\tval-mlogloss:0.511704\n",
      "[600]\ttrain-mlogloss:0.358948\tval-mlogloss:0.495392\n",
      "[800]\ttrain-mlogloss:0.326016\tval-mlogloss:0.492799\n",
      "[1000]\ttrain-mlogloss:0.300708\tval-mlogloss:0.494392\n",
      "[1200]\ttrain-mlogloss:0.279069\tval-mlogloss:0.496745\n",
      "Stopping. Best iteration:\n",
      "[773]\ttrain-mlogloss:0.330095\tval-mlogloss:0.492628\n",
      "\n",
      "fold:  4  training\n",
      "[0]\ttrain-mlogloss:1.37375\tval-mlogloss:1.37417\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.537087\tval-mlogloss:0.599278\n",
      "[400]\ttrain-mlogloss:0.409924\tval-mlogloss:0.512584\n",
      "[600]\ttrain-mlogloss:0.360564\tval-mlogloss:0.496827\n",
      "[800]\ttrain-mlogloss:0.328124\tval-mlogloss:0.494472\n",
      "[1000]\ttrain-mlogloss:0.302903\tval-mlogloss:0.496407\n",
      "[1200]\ttrain-mlogloss:0.280883\tval-mlogloss:0.498885\n",
      "Stopping. Best iteration:\n",
      "[777]\ttrain-mlogloss:0.33147\tval-mlogloss:0.494404\n",
      "\n",
      "fold:  5  training\n",
      "[0]\ttrain-mlogloss:1.37372\tval-mlogloss:1.37381\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.539698\tval-mlogloss:0.567573\n",
      "[400]\ttrain-mlogloss:0.412511\tval-mlogloss:0.475104\n",
      "[600]\ttrain-mlogloss:0.363267\tval-mlogloss:0.459553\n",
      "[800]\ttrain-mlogloss:0.331131\tval-mlogloss:0.457366\n",
      "[1000]\ttrain-mlogloss:0.30517\tval-mlogloss:0.457048\n",
      "[1200]\ttrain-mlogloss:0.28302\tval-mlogloss:0.459299\n",
      "Stopping. Best iteration:\n",
      "[873]\ttrain-mlogloss:0.320929\tval-mlogloss:0.456581\n",
      "\n",
      "fold:  6  training\n",
      "[0]\ttrain-mlogloss:1.37415\tval-mlogloss:1.37479\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.534399\tval-mlogloss:0.613395\n",
      "[400]\ttrain-mlogloss:0.408497\tval-mlogloss:0.529965\n",
      "[600]\ttrain-mlogloss:0.36047\tval-mlogloss:0.514652\n",
      "[800]\ttrain-mlogloss:0.328592\tval-mlogloss:0.512715\n",
      "[1000]\ttrain-mlogloss:0.30271\tval-mlogloss:0.515004\n",
      "[1200]\ttrain-mlogloss:0.280306\tval-mlogloss:0.517784\n",
      "Stopping. Best iteration:\n",
      "[767]\ttrain-mlogloss:0.333452\tval-mlogloss:0.512441\n",
      "\n",
      "fold:  7  training\n",
      "[0]\ttrain-mlogloss:1.37422\tval-mlogloss:1.37472\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.536062\tval-mlogloss:0.601744\n",
      "[400]\ttrain-mlogloss:0.409146\tval-mlogloss:0.518575\n",
      "[600]\ttrain-mlogloss:0.359948\tval-mlogloss:0.504359\n",
      "[800]\ttrain-mlogloss:0.327949\tval-mlogloss:0.502302\n",
      "[1000]\ttrain-mlogloss:0.302765\tval-mlogloss:0.503731\n",
      "[1200]\ttrain-mlogloss:0.280401\tval-mlogloss:0.507546\n",
      "Stopping. Best iteration:\n",
      "[828]\ttrain-mlogloss:0.324129\tval-mlogloss:0.502095\n",
      "\n",
      "fold:  8  training\n",
      "[0]\ttrain-mlogloss:1.37418\tval-mlogloss:1.3746\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.536311\tval-mlogloss:0.594245\n",
      "[400]\ttrain-mlogloss:0.408715\tval-mlogloss:0.513047\n",
      "[600]\ttrain-mlogloss:0.358654\tval-mlogloss:0.498092\n",
      "[800]\ttrain-mlogloss:0.326882\tval-mlogloss:0.495829\n",
      "[1000]\ttrain-mlogloss:0.301896\tval-mlogloss:0.497145\n",
      "[1200]\ttrain-mlogloss:0.280941\tval-mlogloss:0.500028\n",
      "Stopping. Best iteration:\n",
      "[746]\ttrain-mlogloss:0.334334\tval-mlogloss:0.495544\n",
      "\n",
      "fold:  9  training\n",
      "[0]\ttrain-mlogloss:1.3738\tval-mlogloss:1.37429\n",
      "Multiple eval metrics have been passed: 'val-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-mlogloss hasn't improved in 500 rounds.\n",
      "[200]\ttrain-mlogloss:0.536528\tval-mlogloss:0.593227\n",
      "[400]\ttrain-mlogloss:0.409261\tval-mlogloss:0.503371\n",
      "[600]\ttrain-mlogloss:0.360725\tval-mlogloss:0.485875\n",
      "[800]\ttrain-mlogloss:0.329217\tval-mlogloss:0.482969\n",
      "[1000]\ttrain-mlogloss:0.304526\tval-mlogloss:0.484435\n",
      "[1200]\ttrain-mlogloss:0.283146\tval-mlogloss:0.487921\n",
      "Stopping. Best iteration:\n",
      "[798]\ttrain-mlogloss:0.32951\tval-mlogloss:0.482933\n",
      "\n",
      "fold f1 score is 0.7342080986319567\n",
      "F1 measure for Normal rhythm: 0.8897\n",
      "F1 measure for AF rhythm: 0.8064\n",
      "F1 measure for Other rhythm: 0.6978\n",
      "F1 measure for Noisy recordings: 0.5429\n",
      "Final F1 measure: 0.7980\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "start_time = time.time()\n",
    "offline=0\n",
    "online=0\n",
    "params={'booster':'gbtree',\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric':'auc',\n",
    "    'gamma':0.1,\n",
    "    'min_child_weight':1.1,\n",
    "    'max_depth':7,\n",
    "    'lambda':10,\n",
    "    'subsample':0.7,\n",
    "    'colsample_bytree':0.7,\n",
    "    'colsample_bylevel':0.7,\n",
    "    'eta': 0.01,\n",
    "    'tree_method':'exact',\n",
    "    'seed':1000,\n",
    "    'nthread':12\n",
    "    }\n",
    "\n",
    "xgb_params2={\n",
    "'booster':'gbtree',\n",
    "'objective': 'multi:softmax',#'binary:logistic',\n",
    "'num_class': 4,\n",
    "'scale_pos_weight': 1/7.5,\n",
    "#7183正样本\n",
    "#55596条总样本\n",
    "#差不多1:7.7这样子\n",
    "'gamma':0.2,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "'max_depth':8, # 构建树的深度，越大越容易过拟合\n",
    "'lambda':10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "'subsample':0.7, # 随机采样训练样本\n",
    "#'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "'min_child_weight':3, \n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "'eta': 0.03, # 如同学习率\n",
    "'seed':1000,\n",
    "'nthread':-1,# cpu 线程数\n",
    "'eval_metric': 'mlogloss',#'auc'\n",
    "}\n",
    "\n",
    "xgb_params3={\n",
    " 'learning_rate' :0.01,\n",
    " 'n_estimators':2000,\n",
    " 'max_depth':6,\n",
    " 'min_child_weight':3,\n",
    " 'gamma':0.2,\n",
    " 'subsample':0.8,\n",
    " 'colsample_bytree':0.8,\n",
    " 'objective':'multi:softprob',#'binary:logistic',multi:softprob,multi:softmax\n",
    " 'num_class': 4,\n",
    " 'nthread':-1,\n",
    " 'reg_alpha':0,\n",
    " 'reg_lambda':1,\n",
    " 'scale_pos_weight':1,\n",
    " 'seed':27,\n",
    " 'booster':'gbtree',\n",
    " #'scale_pos_weight': 1/7.5,\n",
    " #7183正样本\n",
    " #55596条总样本\n",
    " #差不多1:7.7这样子\n",
    " # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    " #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    " #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    " 'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    " 'eval_metric': 'mlogloss',#'auc'\n",
    "}\n",
    "\n",
    "plst = list(xgb_params3.items())\n",
    "num_rounds = 5000 # 迭代次数\n",
    "\n",
    "#offline_test_X=offline_test[feature_list]\n",
    "#online_test_X=online_test[feature_list]\n",
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 10\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data = train_df[feature_name]\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data\n",
    "\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \\\n",
    "        train_label[train_fold], train_label[validate]\n",
    "        \n",
    "        xgb_train = xgb.DMatrix(X_train, label=label_train)\n",
    "        xgb_val = xgb.DMatrix(X_validate,label=label_validate)\n",
    "        \n",
    "        # return 训练和验证的错误率\n",
    "        watchlist = [(xgb_train, 'train'),(xgb_val, 'val')]\n",
    "\n",
    "        # training model \n",
    "        # early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练\n",
    "        model = xgb.train(plst, xgb_train,num_boost_round=2000,evals=watchlist,early_stopping_rounds=500,verbose_eval=200)\n",
    "\n",
    "        k_pred = model.predict(xgb_val, ntree_limit=model.best_iteration)\n",
    "        oof[validate] = np.argmax(k_pred,axis=1)\n",
    "        #fold_importance_df = pd.DataFrame()\n",
    "        #fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "        #fold_importance_df[\"importance\"] = model.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        #fold_importance_df[\"fold\"] = count + 1\n",
    "        #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        count += 1\n",
    "\n",
    "oof = list(map(int, oof))\n",
    "fold_f1_error = f1_score(train_labels.values, oof, average='macro')\n",
    "print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_labels.values))\n",
    "\n",
    "import json\n",
    "import time\n",
    "data = {\n",
    "    'name' : 'xgboost',\n",
    "    'seed mount': en_amount,\n",
    "    'kfold': NFOLDS,\n",
    "    'params':plst,\n",
    "    'revise':\"\",\n",
    "    'F1n' : F1n,\n",
    "    'F1a' : F1a,\n",
    "    'F1o' : F1o,\n",
    "    'F1p' : F1p,\n",
    "    'F1':F1\n",
    "}\n",
    "with open(\"xgb_record.json\",\"a\") as f:\n",
    "    f.write(\" \\n\\n{0}: \\n \".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) ))\n",
    "    json.dump(data,f,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "fold:  0  training\n",
      "fold:  1  training\n",
      "fold:  2  training\n",
      "fold:  3  training\n",
      "fold:  4  training\n",
      "fold:  5  training\n",
      "fold:  6  training\n",
      "fold:  7  training\n",
      "fold:  8  training\n",
      "fold:  9  training\n",
      "F1 measure for Normal rhythm: 0.8800\n",
      "F1 measure for AF rhythm: 0.7699\n",
      "F1 measure for Other rhythm: 0.6566\n",
      "F1 measure for Noisy recordings: 0.4682\n",
      "Final F1 measure: 0.7688\n"
     ]
    }
   ],
   "source": [
    "cv_pred_all = 0\n",
    "en_amount = 1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# print('rfc.score=',rfc.score(features_test[:,feat_rank], 1-labels_test))\n",
    "\n",
    "#Perfmc_analysis(1-labels_test,ypred2)\n",
    "# feat_rank = range(0,38)\n",
    "for seed in range(en_amount):\n",
    "    print(\"************************\")\n",
    "    NFOLDS = 10\n",
    "    train_label = train_labels#train_data['score']\n",
    "    train_data = train_df[feature_name]\n",
    "    \n",
    "    #train_df[feature_name].astype('float64') #feature_name  columns\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n",
    "    kf = kfold.split(train_data_df, train_label)\n",
    "\n",
    "    #train_data_use = train_data.drop(['uid','score','blk_list_flag'], axis=1)\n",
    "    #test_data_use = test_data.drop(['uid','blk_list_flag'], axis=1)\n",
    "    train_data_use = train_data_df\n",
    "    # cv_pred = np.zeros(test_data.shape[0])\n",
    "    valid_best_l2_all = 0\n",
    "    oof = np.zeros(train_data_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('fold: ',i, ' training')\n",
    "        #print(validate)\n",
    "        \n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \\\n",
    "        train_label[train_fold], train_label[validate]\n",
    "        \n",
    "        #print(X_validate)\n",
    "        #break\n",
    "        rfc = RandomForestClassifier(n_estimators=300, max_leaf_nodes=16, n_jobs=-1)\n",
    "        rfc.fit(X_train, label_train)\n",
    "\n",
    "        #bst = lgb.train(lgb_params2, dtrain, num_boost_round=819, valid_sets=dvalid, verbose_eval=200,early_stopping_rounds=500)\n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        #k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "        \n",
    "        \n",
    "        #cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        #k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "\n",
    "        #valid_best_l2_all += bst.best_score['valid_0']['l1']\n",
    "        #k_pred = bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "        ypred2=rfc.predict(X_validate)\n",
    "        #print(ypred2)\n",
    "        oof[validate] =np.array(ypred2)# np.argmax(ypred2,axis=1)\n",
    "        \n",
    "        '''\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = count + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        ''' \n",
    "        count += 1\n",
    "\n",
    "oof = list(map(int, oof))\n",
    "#fold_f1_error = f1_score(train_labels.values, oof, average='macro')\n",
    "#print('fold f1 score is {0}'.format(fold_f1_error))\n",
    "\n",
    "F1n,F1a,F1o,F1p,F1 = cinc_f1_score(np.array(oof),np.array(train_label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30994</td>\n",
       "      <td>0.041869</td>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.19065</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19327</td>\n",
       "      <td>0.68086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34616</td>\n",
       "      <td>10.8630</td>\n",
       "      <td>0.34610</td>\n",
       "      <td>4.5497</td>\n",
       "      <td>-0.12276</td>\n",
       "      <td>0.097953</td>\n",
       "      <td>0.226740</td>\n",
       "      <td>1.9396</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25562</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>0.15432</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19876</td>\n",
       "      <td>0.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39260</td>\n",
       "      <td>8.2842</td>\n",
       "      <td>0.38207</td>\n",
       "      <td>4.7038</td>\n",
       "      <td>-0.12732</td>\n",
       "      <td>0.102770</td>\n",
       "      <td>-0.380300</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.30436</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>0.19647</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.21903</td>\n",
       "      <td>0.71024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51830</td>\n",
       "      <td>9.7364</td>\n",
       "      <td>0.38495</td>\n",
       "      <td>3.9130</td>\n",
       "      <td>-0.13483</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.344830</td>\n",
       "      <td>1.5477</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29224</td>\n",
       "      <td>0.084545</td>\n",
       "      <td>0.016270</td>\n",
       "      <td>0.18474</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.42657</td>\n",
       "      <td>0.70049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51857</td>\n",
       "      <td>10.4310</td>\n",
       "      <td>0.43186</td>\n",
       "      <td>3.8826</td>\n",
       "      <td>-0.27688</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.307340</td>\n",
       "      <td>1.9596</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.28172</td>\n",
       "      <td>0.103240</td>\n",
       "      <td>0.038225</td>\n",
       "      <td>0.20509</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51972</td>\n",
       "      <td>0.81922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51645</td>\n",
       "      <td>4.8322</td>\n",
       "      <td>0.42668</td>\n",
       "      <td>3.7270</td>\n",
       "      <td>-0.37256</td>\n",
       "      <td>0.122560</td>\n",
       "      <td>-0.015275</td>\n",
       "      <td>1.6736</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2        3   4   5   6   7        8        9  ...  \\\n",
       "0  0.30994  0.041869  0.017553  0.19065  26  32   4   1  0.19327  0.68086 ...   \n",
       "1  0.25562  0.093994  0.014658  0.15432   7  21  14   0  0.19876  0.77200 ...   \n",
       "2  0.30436  0.078538  0.017806  0.19647  29  33   0   2  0.21903  0.71024 ...   \n",
       "3  0.29224  0.084545  0.016270  0.18474  33  32   1  -1  0.42657  0.70049 ...   \n",
       "4  0.28172  0.103240  0.038225  0.20509  28  32   0   2  0.51972  0.81922 ...   \n",
       "\n",
       "        29       30       31      32       33        34        35      36  \\\n",
       "0  0.34616  10.8630  0.34610  4.5497 -0.12276  0.097953  0.226740  1.9396   \n",
       "1  0.39260   8.2842  0.38207  4.7038 -0.12732  0.102770 -0.380300  2.8417   \n",
       "2  0.51830   9.7364  0.38495  3.9130 -0.13483  0.102100  0.344830  1.5477   \n",
       "3  0.51857  10.4310  0.43186  3.8826 -0.27688  0.098439  0.307340  1.9596   \n",
       "4  0.51645   4.8322  0.42668  3.7270 -0.37256  0.122560 -0.015275  1.6736   \n",
       "\n",
       "      37  38  \n",
       "0  0.860   0  \n",
       "1  0.836   0  \n",
       "2  0.668   0  \n",
       "3  0.816   0  \n",
       "4  0.780   0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取王春丽的38个特征数据\n",
    "ids = \"04015\"\n",
    "wclfeat_test_path = \"./wclfeature/afdb_test/\"\n",
    "features38_pd = pd.read_csv(wclfeat_test_path+ids+\"_feat.csv\",header=None)\n",
    "#features38_pd.drop([0,39],axis=1,inplace=True)\n",
    "#features38_pd.columns = feature38_name\n",
    "#features38_pd['id']=file_list\n",
    "features38_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>QRS_Width_std</th>\n",
       "      <th>MAD</th>\n",
       "      <th>AFEv</th>\n",
       "      <th>IrrEv</th>\n",
       "      <th>OriginCount</th>\n",
       "      <th>PACEv</th>\n",
       "      <th>R_amp_std</th>\n",
       "      <th>RR_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>r_high_similarbeats</th>\n",
       "      <th>stepping</th>\n",
       "      <th>E</th>\n",
       "      <th>MOBILITY</th>\n",
       "      <th>COMPLEXITY</th>\n",
       "      <th>R_amp_CV</th>\n",
       "      <th>QRS_width_mean</th>\n",
       "      <th>sk_RR</th>\n",
       "      <th>kurt_RR</th>\n",
       "      <th>RR_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.24277</td>\n",
       "      <td>0.150070</td>\n",
       "      <td>0.021606</td>\n",
       "      <td>0.17638</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097188</td>\n",
       "      <td>0.92237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.50290</td>\n",
       "      <td>-0.003566</td>\n",
       "      <td>0.44654</td>\n",
       "      <td>3.9524</td>\n",
       "      <td>-0.90471</td>\n",
       "      <td>0.10513</td>\n",
       "      <td>0.11917</td>\n",
       "      <td>2.5503</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.28062</td>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.020946</td>\n",
       "      <td>0.18304</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.79133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37838</td>\n",
       "      <td>0.55682</td>\n",
       "      <td>6.017500</td>\n",
       "      <td>0.43131</td>\n",
       "      <td>3.9657</td>\n",
       "      <td>-1.07720</td>\n",
       "      <td>0.10616</td>\n",
       "      <td>0.70848</td>\n",
       "      <td>3.2648</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.26198</td>\n",
       "      <td>0.157210</td>\n",
       "      <td>0.020960</td>\n",
       "      <td>0.17341</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150130</td>\n",
       "      <td>0.87153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57143</td>\n",
       "      <td>0.55537</td>\n",
       "      <td>2.309400</td>\n",
       "      <td>0.45824</td>\n",
       "      <td>3.9435</td>\n",
       "      <td>-0.97756</td>\n",
       "      <td>0.10126</td>\n",
       "      <td>0.52247</td>\n",
       "      <td>2.7806</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25921</td>\n",
       "      <td>0.136420</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.17504</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074812</td>\n",
       "      <td>0.78746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52632</td>\n",
       "      <td>0.61563</td>\n",
       "      <td>7.171000</td>\n",
       "      <td>0.46193</td>\n",
       "      <td>3.9358</td>\n",
       "      <td>-0.55962</td>\n",
       "      <td>0.11284</td>\n",
       "      <td>0.16040</td>\n",
       "      <td>1.9246</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.22884</td>\n",
       "      <td>0.078651</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.13785</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092106</td>\n",
       "      <td>0.83931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72222</td>\n",
       "      <td>0.41132</td>\n",
       "      <td>5.226300</td>\n",
       "      <td>0.35730</td>\n",
       "      <td>4.6323</td>\n",
       "      <td>-0.53916</td>\n",
       "      <td>0.10567</td>\n",
       "      <td>0.70778</td>\n",
       "      <td>4.7020</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CV     rmssd  QRS_Width_std      MAD  AFEv  IrrEv  OriginCount  PACEv  \\\n",
       "0  0.24277  0.150070       0.021606  0.17638    30     30            0      0   \n",
       "1  0.28062  0.121190       0.020946  0.18304    34     32            0     -1   \n",
       "2  0.26198  0.157210       0.020960  0.17341    30     30            0      0   \n",
       "3  0.25921  0.136420       0.027653  0.17504    26     30            0      2   \n",
       "4  0.22884  0.078651       0.025178  0.13785    31     31            0      0   \n",
       "\n",
       "   R_amp_std  RR_mean    ...     r_high_similarbeats  stepping         E  \\\n",
       "0   0.097188  0.92237    ...                 0.43750   0.50290 -0.003566   \n",
       "1   0.086614  0.79133    ...                 0.37838   0.55682  6.017500   \n",
       "2   0.150130  0.87153    ...                 0.57143   0.55537  2.309400   \n",
       "3   0.074812  0.78746    ...                 0.52632   0.61563  7.171000   \n",
       "4   0.092106  0.83931    ...                 0.72222   0.41132  5.226300   \n",
       "\n",
       "   MOBILITY  COMPLEXITY  R_amp_CV  QRS_width_mean    sk_RR  kurt_RR  RR_range  \n",
       "0   0.44654      3.9524  -0.90471         0.10513  0.11917   2.5503     0.852  \n",
       "1   0.43131      3.9657  -1.07720         0.10616  0.70848   3.2648     0.960  \n",
       "2   0.45824      3.9435  -0.97756         0.10126  0.52247   2.7806     0.900  \n",
       "3   0.46193      3.9358  -0.55962         0.11284  0.16040   1.9246     0.728  \n",
       "4   0.35730      4.6323  -0.53916         0.10567  0.70778   4.7020     1.028  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wclfeat_test_path = \"./wclfeature/afdb_test/\"\n",
    "features38_pd = pd.read_csv(wclfeat_test_path+data_id+\"_feat.csv\",header=None)\n",
    "features38_pd.drop(38,axis=1,inplace=True)\n",
    "features38_pd.columns = feature38_name\n",
    "#features38_pd['id']=file_list\n",
    "features38_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 38)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features38_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>perdiogram_1</th>\n",
       "      <th>perdiogram_2</th>\n",
       "      <th>perdiogram_3</th>\n",
       "      <th>perdiogram_4</th>\n",
       "      <th>qrs_areas_mean</th>\n",
       "      <th>qrs_areas_max</th>\n",
       "      <th>qrs_areas2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_var_1</th>\n",
       "      <th>rr_var_2</th>\n",
       "      <th>log_rr</th>\n",
       "      <th>log_rr_1_abs</th>\n",
       "      <th>sample_entropy_1</th>\n",
       "      <th>sample_entropy_2</th>\n",
       "      <th>shannon_entropy_1</th>\n",
       "      <th>shannon_entropy_2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>-2.521598</td>\n",
       "      <td>10.938882</td>\n",
       "      <td>-4687.848085</td>\n",
       "      <td>-4763.011963</td>\n",
       "      <td>-6665.024317</td>\n",
       "      <td>-8826.959656</td>\n",
       "      <td>-0.471668</td>\n",
       "      <td>-0.166694</td>\n",
       "      <td>-0.488015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>9.291413</td>\n",
       "      <td>4.451966</td>\n",
       "      <td>3.097515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.825164</td>\n",
       "      <td>4.906891</td>\n",
       "      <td>0.056946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>-2.547818</td>\n",
       "      <td>10.392283</td>\n",
       "      <td>-4648.087630</td>\n",
       "      <td>-4727.636762</td>\n",
       "      <td>-6640.763278</td>\n",
       "      <td>-8710.528278</td>\n",
       "      <td>-0.408759</td>\n",
       "      <td>-0.023979</td>\n",
       "      <td>-0.422774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>10.604623</td>\n",
       "      <td>5.033569</td>\n",
       "      <td>2.512306</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>4.993237</td>\n",
       "      <td>5.114369</td>\n",
       "      <td>0.033498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>-1.909422</td>\n",
       "      <td>8.485781</td>\n",
       "      <td>-4867.277065</td>\n",
       "      <td>-4735.425963</td>\n",
       "      <td>-6597.242374</td>\n",
       "      <td>-8788.492763</td>\n",
       "      <td>-0.379592</td>\n",
       "      <td>0.738954</td>\n",
       "      <td>-0.393093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>9.835129</td>\n",
       "      <td>5.282726</td>\n",
       "      <td>3.033884</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>4.771143</td>\n",
       "      <td>4.983788</td>\n",
       "      <td>0.029564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>-2.823616</td>\n",
       "      <td>11.777004</td>\n",
       "      <td>-4855.653225</td>\n",
       "      <td>-4764.603780</td>\n",
       "      <td>-6615.116961</td>\n",
       "      <td>-8796.311772</td>\n",
       "      <td>-0.470036</td>\n",
       "      <td>0.047883</td>\n",
       "      <td>-0.476584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>10.119332</td>\n",
       "      <td>5.927576</td>\n",
       "      <td>2.954574</td>\n",
       "      <td>2.159484</td>\n",
       "      <td>4.957854</td>\n",
       "      <td>5.087463</td>\n",
       "      <td>0.057326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>-1.600680</td>\n",
       "      <td>6.130430</td>\n",
       "      <td>-4856.808130</td>\n",
       "      <td>-4857.883877</td>\n",
       "      <td>-6757.718602</td>\n",
       "      <td>-8920.292816</td>\n",
       "      <td>-0.390534</td>\n",
       "      <td>0.137030</td>\n",
       "      <td>-0.404499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>10.040674</td>\n",
       "      <td>3.875350</td>\n",
       "      <td>2.863985</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>4.888790</td>\n",
       "      <td>4.983788</td>\n",
       "      <td>0.082815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var      skew   kurtosis  perdiogram_1  perdiogram_2  perdiogram_3  \\\n",
       "0  0.000111 -2.521598  10.938882  -4687.848085  -4763.011963  -6665.024317   \n",
       "1  0.000111 -2.547818  10.392283  -4648.087630  -4727.636762  -6640.763278   \n",
       "2  0.000111 -1.909422   8.485781  -4867.277065  -4735.425963  -6597.242374   \n",
       "3  0.000111 -2.823616  11.777004  -4855.653225  -4764.603780  -6615.116961   \n",
       "4  0.000111 -1.600680   6.130430  -4856.808130  -4857.883877  -6757.718602   \n",
       "\n",
       "   perdiogram_4  qrs_areas_mean  qrs_areas_max  qrs_areas2_mean     ...       \\\n",
       "0  -8826.959656       -0.471668      -0.166694        -0.488015     ...        \n",
       "1  -8710.528278       -0.408759      -0.023979        -0.422774     ...        \n",
       "2  -8788.492763       -0.379592       0.738954        -0.393093     ...        \n",
       "3  -8796.311772       -0.470036       0.047883        -0.476584     ...        \n",
       "4  -8920.292816       -0.390534       0.137030        -0.404499     ...        \n",
       "\n",
       "     rr_var  rr_var_1  rr_var_2     log_rr  log_rr_1_abs  sample_entropy_1  \\\n",
       "0  0.001754  0.005253  0.017313   9.291413      4.451966          3.097515   \n",
       "1  0.001845  0.003850  0.012175  10.604623      5.033569          2.512306   \n",
       "2  0.002438  0.007003  0.024822   9.835129      5.282726          3.033884   \n",
       "3  0.002113  0.006019  0.020254  10.119332      5.927576          2.954574   \n",
       "4  0.001371  0.002940  0.009514  10.040674      3.875350          2.863985   \n",
       "\n",
       "   sample_entropy_2  shannon_entropy_1  shannon_entropy_2  correlation  \n",
       "0          0.000000           4.825164           4.906891     0.056946  \n",
       "1          2.564949           4.993237           5.114369     0.033498  \n",
       "2          2.484907           4.771143           4.983788     0.029564  \n",
       "3          2.159484           4.957854           5.087463     0.057326  \n",
       "4          3.367296           4.888790           4.983788     0.082815  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_id=\"07162\"\n",
    "path = './AFdb_TEST0/'\n",
    "test_features39_pd = pd.read_csv(path+data_id+\"_feat39.csv\")\n",
    "test_features39_pd.dropna(inplace=True)\n",
    "labels = test_features39_pd[\"label\"]\n",
    "ID = test_features39_pd[\"ID\"]\n",
    "test_features39_pd.drop([\"ID\",\"label\"],axis=1,inplace=True)\n",
    "#features39_pd.columns = feature39_name\n",
    "#features38_pd['id']=file_list\n",
    "test_features39_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1227, 39)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features39_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Predict_afdb(object):\n",
    "    def __init__(self, path,data_id,preprocess,feature39_name,feature188_name,select_feature_name):\n",
    "        super(Predict_afdb,self).__init__()\n",
    "        self.feature39_name = feature39_name\n",
    "        self.feature188_name = feature188_name\n",
    "        self.select_feature_name = select_feature_name\n",
    "        self.preprocess = preprocess\n",
    "        self.features39_id = []\n",
    "        self.labels = []\n",
    "        self.path = path\n",
    "        self.data_id = data_id\n",
    "        self.test_data = 0\n",
    "        self.pred_labels = []\n",
    "    def _get_id_labels(self):\n",
    "        with open(os.path.join(self.path,self.data_id+'_features39_id.txt')) as f:\n",
    "            temp = f.read().splitlines()#[-2909:]\n",
    "            self.features39_id = [x.split(\" \")[0] for x in temp]\n",
    "            self.labels = [x.split(\" \")[-1] for x in temp]\n",
    "    def _get_merge_features(self):\n",
    "        self._get_id_labels()\n",
    "        #print(self.features39_id)\n",
    "        \n",
    "        #读取39个特征\n",
    "        ''' \n",
    "        test_features39_pd = pd.read_csv(os.path.join(self.path,self.data_id+'_feat39.csv'))\n",
    "        test_features39_pd.dropna(inplace=True)\n",
    "        self.labels = test_features39_pd[\"label\"].values.tolist()\n",
    "        self.features39_id =  test_features39_pd[\"ID\"].values.tolist()\n",
    "        test_features39_pd.drop([\"ID\",\"label\"],axis=1,inplace=True)\n",
    "        test_features39_pd[\"id\"] = self.features39_id\n",
    "        #features39_pd.columns = feature39_name\n",
    "        #features38_pd['id']=file_list\n",
    "        '''\n",
    "        features39 = np.loadtxt(os.path.join(self.path,self.data_id+'_features39.txt'))#[-2909:]\n",
    "        test_features39_pd = pd.DataFrame(data=features39,columns=self.feature39_name)\n",
    "        test_features39_pd[\"id\"] = self.features39_id\n",
    "        #print(test_features39_pd.shape)\n",
    "        \n",
    "        #读取188个特征\n",
    "        if self.preprocess == False:\n",
    "            features188 = np.loadtxt(os.path.join(os.path.join(self.path,data_id),\"TH902_features_188_test.txt\"))\n",
    "        else:\n",
    "            features188 = np.loadtxt(os.path.join(os.path.join(self.path,\"results\",data_id),\"afdb_188features_lead1.txt\"))\n",
    "        features188_pd = pd.DataFrame(features188,columns=self.feature188_name)\n",
    "        features188_pd['id']=self.features39_id\n",
    "        #print(features188_pd.shape)\n",
    "        \n",
    "        \n",
    "        #读取38个特征\n",
    "        wclfeat_test_path = \"./wclfeature/afdb_test/\"\n",
    "        features38_pd = pd.read_csv(wclfeat_test_path+data_id+\"_feat_id.csv\")#,header=None\n",
    "        #features38_pd.drop(38,axis=1,inplace=True)\n",
    "        #features38_pd.columns = feature38_name+[\"label\"]   \n",
    "        #features38_pd['id']=self.features39_id\n",
    "        #features38_pd.to_csv(wclfeat_test_path+data_id+\"_feat_id.csv\",index=False)\n",
    "        #print(features38_pd.shape)\n",
    "        \n",
    "        test_data_all = pd.merge(test_features39_pd,features188_pd,on='id')\n",
    "        test_data_all = pd.merge(test_data_all,features38_pd,on='id')\n",
    "        self.test_data = test_data_all[self.select_feature_name] #feature39_name feature_name\n",
    "        \n",
    "        self.labels = test_data_all[\"label\"]\n",
    "        #test_data_all.to_csv(\"test.csv\")\n",
    "        #print(test_data_all[[\"id\",\"RR_range\"]])\n",
    "        #print(\"test_data shape: \",self.test_data.shape)\n",
    "    def _predict(self):\n",
    "        self._get_merge_features()\n",
    "        results = []\n",
    "        num_N=0\n",
    "        num_A=0\n",
    "        num_O=0\n",
    "        num_ = 0\n",
    "        \n",
    "        for i in range(self.test_data.shape[0]):\n",
    "            dfeatures = self.test_data.iloc[i].astype('float64')\n",
    "            prediction_prob = bst.predict(dfeatures)\n",
    "            prediction = np.argmax(prediction_prob)\n",
    "            self.pred_labels.append(prediction)\n",
    "\n",
    "            if prediction == 0:\n",
    "                num_N += 1\n",
    "                pred_label = \"N\"\n",
    "                result =self.features39_id[i] + '   N\\n'\n",
    "            elif prediction == 1:\n",
    "                num_A += 1\n",
    "                pred_label = \"AFIB\"\n",
    "                result = self.features39_id[i]+'   A\\n'\n",
    "            elif prediction == 2:\n",
    "                num_O += 1\n",
    "                pred_label = \"O\"\n",
    "                result =self.features39_id[i] + '   O\\n'\n",
    "            elif prediction == 3:\n",
    "                num_ += 1\n",
    "                pred_label = \"~\"\n",
    "                result = self.features39_id[i]+'   ~\\n'\n",
    "\n",
    "            results.append(result)\n",
    "            #pred_labels.append(pred_label)\n",
    "            #print(test_data_all.iloc[i].loc['id'])\n",
    "            #print(\"********* result :************ \", result)\n",
    "        print(\"\\n************************\\n\")\n",
    "        print(\"data_id =  \" ,self.data_id)\n",
    "        print(\"num_N = %d  :\" % num_N)\n",
    "        print(\"num_A = %d  :\" % num_A)\n",
    "        print(\"num_O = %d  :\" % num_O)\n",
    "        print(\"num_  = %d  :\" % num_ )\n",
    "        \n",
    "        return results\n",
    "    def _perf_measure(self,y_actual, y_hat):\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "\n",
    "        for i in range(len(y_hat)): \n",
    "            if y_actual[i]==y_hat[i]==1:\n",
    "                TP += 1\n",
    "            if y_hat[i]==1 and y_actual[i]!=1:\n",
    "                FP += 1\n",
    "            if y_actual[i]!=1 and y_actual[i]!=1:\n",
    "                TN += 1\n",
    "            if y_hat[i]!=1 and y_actual[i]==1:\n",
    "                FN += 1\n",
    "        #TP, FP, TN, FN = perf_measure(train_labels.values,pred_labels)\n",
    "\n",
    "        print(\"TP, FP, TN, FN == \",TP, FP, TN, FN)\n",
    "\n",
    "        SE = TP / (TP + FN+ 0.00001)\n",
    "        print(\"召回率或灵敏度 SE = TP / (TP + FN) == \",SE)\n",
    "\n",
    "        SP = TN / (TN + FP+0.00001)\n",
    "        print(\"特异性 SP = TN / (TN + FP) == \",SP)\n",
    "\n",
    "        PPV = TP / (TP + FP+ 0.00001)\n",
    "        print(\"阳性预测值 PPV = TP / (TP + FP) == \",PPV)\n",
    "        \n",
    "        Recall       = TP / (TP + FN + 0.00001)\n",
    "        Precision    = TP / (TP + FP + 0.00001)\n",
    "        Specificity  = TN / (TN + FP + 0.00001); # 1-FPR\n",
    "        Acc          = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "        print(\"Recall :\",Recall)\n",
    "        print(\"Precision :\",Precision)\n",
    "        print(\"Specificity :\",Specificity)\n",
    "        print(\"Acc :\",Acc)\n",
    "\n",
    "        return TP, FP, TN, FN,SE, SP, PPV, Acc\n",
    "    def display_confusion_matrix(self):\n",
    "        results = self._predict()\n",
    "        # Creates a confusion matrix\n",
    "        map_dict = {\"N\":0,\"AFIB\":1,\"AFL\":1,\"O\":2,\"~\":3,\"J\":2}#AFIB\n",
    "        train_labels = pd.Series(self.labels)#.map(map_dict)\n",
    "        \n",
    "        columns = pd.Series(self.labels).value_counts().index.values\n",
    "        print(\"true_labels : \\n\",train_labels.value_counts())\n",
    "        y_true = train_labels.values\n",
    "        y_pred = self.pred_labels\n",
    "        \n",
    "        cm = confusion_matrix(y_true,y_pred)\n",
    "        if cm.shape == (2,2):\n",
    "            cm_df = pd.DataFrame(cm,\n",
    "                                     index = ['A','O'], \n",
    "                                     columns = ['A','O'])\n",
    "        else:\n",
    "            # Transform to df for easier plotting\n",
    "            try:\n",
    "                cm_df = pd.DataFrame(cm,\n",
    "                                 index = ['N','A','O','~'], \n",
    "                                 columns = ['N','A','O','~'])\n",
    "            except ValueError:\n",
    "                cm_df = pd.DataFrame(cm,\n",
    "                                 index = ['N','A','O'], \n",
    "                                 columns = ['N','A','O'])\n",
    "        ''' \n",
    "        plt.figure(figsize=(16,10))\n",
    "        sns.heatmap(cm_df, annot=True,annot_kws={'size':25,'weight':'bold', 'color':'r'},fmt=\"d\")#,cmap=\"RdBu\"\n",
    "        plt.title('Xgboost \\nAccuracy:{0:.3f}'.format(accuracy_score(y_pred,y_true)))\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "        '''\n",
    "        TP, FP, TN, FN,SE, SP, PPV, Acc = self._perf_measure(y_true,y_pred)\n",
    "        \n",
    "        return self.data_id,self.test_data.shape[0],TP, FP, TN, FN,SE, SP, PPV, Acc#,results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bst = lgb.Booster(model_file='lightgbm_05141_temp.bin')  #lgb.bin  lightgbm_0327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Radius',\n",
       " 'sample_entropy_2',\n",
       " 'Features_SD_13',\n",
       " 'IrrEv',\n",
       " 'HR_median',\n",
       " 'COMPLEXITY',\n",
       " 'RR_min',\n",
       " 'se',\n",
       " 'r_high_similarbeats',\n",
       " 'percentage_nn50',\n",
       " 'Features_SD_64',\n",
       " 'Features_SD_47',\n",
       " 'Features_ADC_9',\n",
       " 'COSEn',\n",
       " 'AFEv',\n",
       " 'CV',\n",
       " 'lorenz_plot',\n",
       " 'Features_ADC_6',\n",
       " 'CV_deltaRR',\n",
       " 'stepping',\n",
       " 'Features_ADC_10',\n",
       " 'Features_SD_48',\n",
       " 'rr_var_2',\n",
       " 'Features_SD_55',\n",
       " 'nn50',\n",
       " 'Features_CP_18',\n",
       " 'sk_RR',\n",
       " 'sample_entropy_1']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_feature_name = feature_name\n",
    "select_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric_mitafdb(tp,fp,tn,fn):\n",
    "    \n",
    "    print(\"TP, FP, TN, FN == \",tp, fp, tn, fn)\n",
    "    SE = tp / (tp + fn+ 0.00001)\n",
    "    print(\"召回率或灵敏度 SE = TP / (TP + FN) == \",SE)\n",
    "\n",
    "    SP = tn / (tn + fp+0.00001)\n",
    "    print(\"特异性 SP = TN / (TN + FP) == \",SP)\n",
    "\n",
    "    PPV = tp / (tp + fp+ 0.00001)\n",
    "    print(\"阳性预测值 PPV = TP / (TP + FP) == \",PPV)\n",
    "    Acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\"ACC Acc = (TP + TN) / (TP + TN + FP + FN) == \",Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************\n",
      "\n",
      "data_id =   04015\n",
      "num_N = 971  :\n",
      "num_A = 47  :\n",
      "num_O = 209  :\n",
      "num_  = 2  :\n",
      "true_labels : \n",
      " 0    1221\n",
      "1       8\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  8 39 1221 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999987500015626\n",
      "特异性 SP = TN / (TN + FP) ==  0.969047611356765\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.17021272974197238\n",
      "Recall : 0.9999987500015626\n",
      "Precision : 0.17021272974197238\n",
      "Specificity : 0.969047611356765\n",
      "Acc : 0.9692429022082019\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04043\n",
      "num_N = 10  :\n",
      "num_A = 291  :\n",
      "num_O = 953  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    978\n",
      "1    276\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  267 24 978 9\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9673912692974179\n",
      "特异性 SP = TN / (TN + FP) ==  0.9760478944506198\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9175257416657822\n",
      "Recall : 0.9673912692974179\n",
      "Precision : 0.9175257416657822\n",
      "Specificity : 0.9760478944506198\n",
      "Acc : 0.9741784037558685\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04048\n",
      "num_N = 1015  :\n",
      "num_A = 68  :\n",
      "num_O = 142  :\n",
      "num_  = 4  :\n",
      "true_labels : \n",
      " 0    1216\n",
      "1      13\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  13 55 1216 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999992307698226\n",
      "特异性 SP = TN / (TN + FP) ==  0.9567269790973487\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.19117644247405258\n",
      "Recall : 0.9999992307698226\n",
      "Precision : 0.19117644247405258\n",
      "Specificity : 0.9567269790973487\n",
      "Acc : 0.9571651090342679\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04126\n",
      "num_N = 413  :\n",
      "num_A = 86  :\n",
      "num_O = 731  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1182\n",
      "1      48\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  48 38 1182 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.99999979166671\n",
      "特异性 SP = TN / (TN + FP) ==  0.96885245107498\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.5581394699837825\n",
      "Recall : 0.99999979166671\n",
      "Precision : 0.5581394699837825\n",
      "Specificity : 0.96885245107498\n",
      "Acc : 0.9700315457413249\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04746\n",
      "num_N = 476  :\n",
      "num_A = 648  :\n",
      "num_O = 104  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    652\n",
      "0    576\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  648 0 576 4\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9938650154315182\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999826388892\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999845679015\n",
      "Recall : 0.9938650154315182\n",
      "Precision : 0.9999999845679015\n",
      "Specificity : 0.9999999826388892\n",
      "Acc : 0.996742671009772\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04908\n",
      "num_N = 299  :\n",
      "num_A = 133  :\n",
      "num_O = 801  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1128\n",
      "1     105\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  104 29 1128 1\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9904760961451337\n",
      "特异性 SP = TN / (TN + FP) ==  0.9749351687559623\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.781954828424449\n",
      "Recall : 0.9904760961451337\n",
      "Precision : 0.781954828424449\n",
      "Specificity : 0.9749351687559623\n",
      "Acc : 0.9762282091917591\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   04936\n",
      "num_N = 223  :\n",
      "num_A = 760  :\n",
      "num_O = 256  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    893\n",
      "0    346\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  721 39 346 172\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.8073908084278745\n",
      "特异性 SP = TN / (TN + FP) ==  0.8987012753584085\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.948684198043629\n",
      "Recall : 0.8073908084278745\n",
      "Precision : 0.948684198043629\n",
      "Specificity : 0.8987012753584085\n",
      "Acc : 0.8348982785602503\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   05091\n",
      "num_N = 1067  :\n",
      "num_A = 6  :\n",
      "num_O = 156  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1225\n",
      "1       4\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  3 3 1225 1\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.7499981250046875\n",
      "特异性 SP = TN / (TN + FP) ==  0.9975569951339007\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.4999991666680556\n",
      "Recall : 0.7499981250046875\n",
      "Precision : 0.4999991666680556\n",
      "Specificity : 0.9975569951339007\n",
      "Acc : 0.9967532467532467\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   05121\n",
      "num_N = 212  :\n",
      "num_A = 749  :\n",
      "num_O = 275  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    778\n",
      "0    458\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  733 16 458 45\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9421593709234014\n",
      "特异性 SP = TN / (TN + FP) ==  0.9662447053534873\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9786381711797307\n",
      "Recall : 0.9421593709234014\n",
      "Precision : 0.9786381711797307\n",
      "Specificity : 0.9662447053534873\n",
      "Acc : 0.9512779552715654\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   05261\n",
      "num_N = 630  :\n",
      "num_A = 21  :\n",
      "num_O = 579  :\n",
      "num_  = 2  :\n",
      "true_labels : \n",
      " 0    1214\n",
      "1      18\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  18 3 1214 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999994444447531\n",
      "特异性 SP = TN / (TN + FP) ==  0.9975349137425233\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.8571424489797862\n",
      "Recall : 0.9999994444447531\n",
      "Precision : 0.8571424489797862\n",
      "Specificity : 0.9975349137425233\n",
      "Acc : 0.9975708502024292\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   06426\n",
      "num_N = 20  :\n",
      "num_A = 1179  :\n",
      "num_O = 33  :\n",
      "num_  = 3  :\n",
      "true_labels : \n",
      " 1    1175\n",
      "0      60\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  1168 11 60 7\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9940425447315528\n",
      "特异性 SP = TN / (TN + FP) ==  0.8450703035112248\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9906700509697197\n",
      "Recall : 0.9940425447315528\n",
      "Precision : 0.9906700509697197\n",
      "Specificity : 0.8450703035112248\n",
      "Acc : 0.985553772070626\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   06453\n",
      "num_N = 693  :\n",
      "num_A = 10  :\n",
      "num_O = 405  :\n",
      "num_  = 3  :\n",
      "true_labels : \n",
      " 0    1098\n",
      "1      13\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  8 2 1098 5\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.6153841420121985\n",
      "特异性 SP = TN / (TN + FP) ==  0.9981818091074381\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.7999992000008\n",
      "Recall : 0.6153841420121985\n",
      "Precision : 0.7999992000008\n",
      "Specificity : 0.9981818091074381\n",
      "Acc : 0.9937106918238994\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   06995\n",
      "num_N = 94  :\n",
      "num_A = 610  :\n",
      "num_O = 525  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    649\n",
      "1    580\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  560 50 649 20\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9655172247324617\n",
      "特异性 SP = TN / (TN + FP) ==  0.9284692284911412\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9180327718355283\n",
      "Recall : 0.9655172247324617\n",
      "Precision : 0.9180327718355283\n",
      "Specificity : 0.9284692284911412\n",
      "Acc : 0.9452697419859265\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07162\n",
      "num_N = 0  :\n",
      "num_A = 1072  :\n",
      "num_O = 155  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    1227\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  1072 0 0 155\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.8736756245014212\n",
      "特异性 SP = TN / (TN + FP) ==  0.0\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999906716419\n",
      "Recall : 0.8736756245014212\n",
      "Precision : 0.9999999906716419\n",
      "Specificity : 0.0\n",
      "Acc : 0.8736756316218419\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07859\n",
      "num_N = 1  :\n",
      "num_A = 1207  :\n",
      "num_O = 18  :\n",
      "num_  = 1  :\n",
      "true_labels : \n",
      " 1    1227\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  1207 0 0 20\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.983700073482477\n",
      "特异性 SP = TN / (TN + FP) ==  0.0\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.999999991714996\n",
      "Recall : 0.983700073482477\n",
      "Precision : 0.999999991714996\n",
      "Specificity : 0.0\n",
      "Acc : 0.9837000814995925\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07879\n",
      "num_N = 384  :\n",
      "num_A = 744  :\n",
      "num_O = 100  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    740\n",
      "0    488\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  740 4 488 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999999864864867\n",
      "特异性 SP = TN / (TN + FP) ==  0.9918698985392298\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9946236425453812\n",
      "Recall : 0.9999999864864867\n",
      "Precision : 0.9946236425453812\n",
      "Specificity : 0.9918698985392298\n",
      "Acc : 0.9967532467532467\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   07910\n",
      "num_N = 722  :\n",
      "num_A = 203  :\n",
      "num_O = 303  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1032\n",
      "1     196\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  195 8 1032 1\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9948979084235761\n",
      "特异性 SP = TN / (TN + FP) ==  0.9923076827662723\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9605910856851682\n",
      "Recall : 0.9948979084235761\n",
      "Precision : 0.9605910856851682\n",
      "Specificity : 0.9923076827662723\n",
      "Acc : 0.9927184466019418\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08215\n",
      "num_N = 145  :\n",
      "num_A = 895  :\n",
      "num_O = 189  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    990\n",
      "0    239\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  895 0 239 95\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9040403949086829\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999581589976\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999888268158\n",
      "Recall : 0.9040403949086829\n",
      "Precision : 0.9999999888268158\n",
      "Specificity : 0.9999999581589976\n",
      "Acc : 0.9227013832384052\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08219\n",
      "num_N = 68  :\n",
      "num_A = 287  :\n",
      "num_O = 888  :\n",
      "num_  = 1  :\n",
      "true_labels : \n",
      " 0    969\n",
      "1    275\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  270 17 969 5\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9818181461157038\n",
      "特异性 SP = TN / (TN + FP) ==  0.9827586107225293\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.940766517743327\n",
      "Recall : 0.9818181461157038\n",
      "Precision : 0.940766517743327\n",
      "Specificity : 0.9827586107225293\n",
      "Acc : 0.9825535289452815\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08378\n",
      "num_N = 553  :\n",
      "num_A = 252  :\n",
      "num_O = 426  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    973\n",
      "1    258\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  252 0 973 6\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9767441481882114\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999897225078\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999603174619\n",
      "Recall : 0.9767441481882114\n",
      "Precision : 0.9999999603174619\n",
      "Specificity : 0.9999999897225078\n",
      "Acc : 0.9951259138911455\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08405\n",
      "num_N = 278  :\n",
      "num_A = 882  :\n",
      "num_O = 69  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 1    887\n",
      "0    342\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  882 0 342 5\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9943630102101126\n",
      "特异性 SP = TN / (TN + FP) ==  0.9999999707602348\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9999999886621317\n",
      "Recall : 0.9943630102101126\n",
      "Precision : 0.9999999886621317\n",
      "Specificity : 0.9999999707602348\n",
      "Acc : 0.9959316517493898\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08434\n",
      "num_N = 957  :\n",
      "num_A = 50  :\n",
      "num_O = 222  :\n",
      "num_  = 0  :\n",
      "true_labels : \n",
      " 0    1180\n",
      "1      49\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  49 1 1180 0\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9999997959184089\n",
      "特异性 SP = TN / (TN + FP) ==  0.9991532514889648\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9799998040000392\n",
      "Recall : 0.9999997959184089\n",
      "Precision : 0.9799998040000392\n",
      "Specificity : 0.9991532514889648\n",
      "Acc : 0.9991869918699187\n",
      "\n",
      "************************\n",
      "\n",
      "data_id =   08455\n",
      "num_N = 297  :\n",
      "num_A = 837  :\n",
      "num_O = 84  :\n",
      "num_  = 11  :\n",
      "true_labels : \n",
      " 1    850\n",
      "0    379\n",
      "Name: label, dtype: int64\n",
      "TP, FP, TN, FN ==  836 1 379 14\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9835294001937718\n",
      "特异性 SP = TN / (TN + FP) ==  0.997368394806095\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9988052449366159\n",
      "Recall : 0.9835294001937718\n",
      "Precision : 0.9988052449366159\n",
      "Specificity : 0.997368394806095\n",
      "Acc : 0.9878048780487805\n",
      "TP, FP, TN, FN ==  10697 340 16953 565\n",
      "召回率或灵敏度 SE = TP / (TP + FN) ==  0.9498312902239111\n",
      "特异性 SP = TN / (TN + FP) ==  0.9803388648699828\n",
      "阳性预测值 PPV = TP / (TP + FP) ==  0.9691945266202823\n",
      "ACC Acc = (TP + TN) / (TP + TN + FP + FN) ==  0.9683067763964279\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=[\"ID\",\"samples\",\"TP\", \"FP\", \"TN\", \"FN\",\"SE\",\"SP\",\"PPV\",\"ACC\"])\n",
    "\n",
    "data_id_lists = ['04015', '04043', '04048', '04126', '04746', '04908', '04936', '05091', '05121', '05261', '06426', '06453', '06995',\n",
    "                 '07162', '07859', '07879', '07910', '08215', '08219', '08378', '08405', '08434', '08455']\n",
    "\n",
    "#data_id_lists = [\"04048\"]\n",
    "path = \"./AFdb_TEST0/\"\n",
    "tp = []\n",
    "fp = []\n",
    "tn = []\n",
    "fn = []\n",
    "for data_id in data_id_lists:\n",
    "    predict_afdb = Predict_afdb(path,data_id,True,feature39_name,feature188_name,select_feature_name)\n",
    "    ID,num,TP, FP, TN, FN,SE, SP, PPV, Acc = predict_afdb.display_confusion_matrix()\n",
    "    \n",
    "    tp.append(TP)\n",
    "    fp.append(FP)\n",
    "    tn.append(TN)\n",
    "    fn.append(FN)\n",
    "        \n",
    "    result.loc[result.shape[0]] = ID,num,TP, FP, TN, FN,SE, SP, PPV, Acc\n",
    "metric_mitafdb(sum(tp),sum(fp),sum(tn),sum(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"lead0_result_0513_5.csv\",index=False)#lead0_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
