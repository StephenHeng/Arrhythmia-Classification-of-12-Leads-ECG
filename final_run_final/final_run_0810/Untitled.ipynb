{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pywt\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import f1_score,hamming_loss\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "path = \"/media/jdcloud/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_y(labels, y, num_class=10):\n",
    "    bin_label = np.zeros((len(y), num_class)).astype('int8')\n",
    "    for i in range(len(y)):\n",
    "        label_nona = labels.loc[y[i]].dropna()\n",
    "        for j in range(1, label_nona.shape[0]):\n",
    "            bin_label[i, int(label_nona[j])] = 1\n",
    "    return bin_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "#train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_attention_maxpooling_10net_fold0.csv\").values)\n",
    "#train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_attention_maxpooling_10net_fold1.csv\").values)\n",
    "#train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_attention_maxpooling_10net_fold2.csv\").values)\n",
    "path = './'\n",
    "\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_4block_10net_fold0.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_4block_10net_fold1.csv\").values)\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_4block_10net_fold2.csv\").values) #1fold f0.822\n",
    "\n",
    "#train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_one_net_fold0.csv\").values)\n",
    "#train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_one_net_fold1.csv\").values)\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_one_net_fold2.csv\").values) # 1fold f0.813\n",
    "\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_1net_fold0.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_1net_fold1.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_1net_fold2.csv\").values)\n",
    "\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_fold0.csv\").values)\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_fold1.csv\").values)\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_fold2.csv\").values) # 3folds f0.817\n",
    "\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"densenet_f0819_10net_fold.csv\").values) # 1fold f0.819\n",
    "\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_sym_addori_fold0.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_sym_addori_fold1.csv\").values)\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_sym_addori_fold2.csv\").values) # 3folds f0.817\n",
    "\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_db6_addori_fold0.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_db6_addori_fold1.csv\").values)\n",
    "train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_db6_addori_fold2.csv\").values)\n",
    "\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_ori_addori_fold0.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_ori_addori_fold1.csv\").values)\n",
    "# train.append(pd.read_csv(path+\"ensemble_csv/\"+\"attention_10net_ori_addori_fold2.csv\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# out = np.hstack(test)#\n",
    "out0 = np.hstack(train[:-1]) #\n",
    "out1 = np.hstack(train[:-2])\n",
    "out2 = np.hstack(train[:-2]+[train[-1]])\n",
    "\n",
    "LR_clf = joblib.load(\"LR_ensemble0810.pkl\")\n",
    "MLkNN8_clf = joblib.load(\"MLkNN8_ensemble.pkl\")\n",
    "MLkNN10_clf = joblib.load(\"MLkNN10_ensemble.pkl\")\n",
    "MLkNN10_db6_clf = joblib.load(\"MLkNN10_ensemble_db6_0810.pkl\")\n",
    "\n",
    "y_pred_LR = LR_clf.predict(out0)\n",
    "y_pred_proba_LR = LR_clf.predict_proba(out0)\n",
    "\n",
    "y_pred_MLkNN8 = MLkNN8_clf.predict(out1).toarray()\n",
    "y_pred_proba_MLkNN8 = MLkNN8_clf.predict_proba(out1).toarray()\n",
    "\n",
    "y_pred_MLkNN10 = MLkNN10_clf.predict(out1).toarray()\n",
    "y_pred_proba_MLkNN10 = MLkNN10_clf.predict_proba(out1).toarray()\n",
    "\n",
    "y_pred_MLkNN10_db6 = MLkNN10_db6_clf.predict(out2).toarray()\n",
    "y_pred_proba_MLkNN10_db6 = MLkNN10_db6_clf.predict_proba(out2).toarray()\n",
    "\n",
    "y_pred_LR[:,2] = y_pred_MLkNN8[:,2]\n",
    "y_pred_proba_LR[:,2] = y_pred_proba_MLkNN8[:,2]\n",
    "\n",
    "y_pred_LR[:,5] = y_pred_MLkNN8[:,5]\n",
    "y_pred_proba_LR[:,5] = y_pred_proba_MLkNN8[:,5]\n",
    "\n",
    "y_pred_LR[:,6] = y_pred_MLkNN8[:,6]\n",
    "y_pred_proba_LR[:,6] = y_pred_proba_MLkNN8[:,6]\n",
    "\n",
    "y_pred_LR[:,9] = y_pred_MLkNN8[:,9]\n",
    "y_pred_proba_LR[:,9] = y_pred_proba_MLkNN8[:,9]\n",
    "\n",
    "\n",
    "y_pred_LR[:,0] = y_pred_MLkNN10[:,0]\n",
    "y_pred_proba_LR[:,0] = y_pred_proba_MLkNN10[:,0]\n",
    "\n",
    "y_pred_LR[:,4] = y_pred_MLkNN10[:,4]\n",
    "y_pred_proba_LR[:,4] = y_pred_proba_MLkNN10[:,4]\n",
    "\n",
    "y_pred_LR[:,8] = y_pred_MLkNN10[:,8]\n",
    "y_pred_proba_LR[:,8] = y_pred_proba_MLkNN10[:,8]\n",
    "\n",
    "y_pred_LR[:,7] = y_pred_MLkNN10_db6[:,7]\n",
    "y_pred_proba_LR[:,7] = y_pred_proba_MLkNN10_db6[:,7]\n",
    "\n",
    "\n",
    "y_pred = y_pred_LR\n",
    "y_pred_proba_train = y_pred_proba_LR\n",
    "\n",
    "# y_pred = clf.predict(x_train)#.toarray()\n",
    "# y_pred_proba_train = clf.predict(x_train)#.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data f1_score  : 0.9488485550878499\n",
      "f1 score of ab 0 is 0.9718297798267139\n",
      "f1 score of ab 1 is 0.9915591932865238\n",
      "f1 score of ab 2 is 0.9668607152468933\n",
      "f1 score of ab 3 is 0.9864456171309433\n",
      "f1 score of ab 4 is 0.9586664545859218\n",
      "f1 score of ab 5 is 0.9790363885692794\n",
      "f1 score of ab 6 is 0.9739862764690532\n",
      "f1 score of ab 7 is 0.9609072469746974\n",
      "f1 score of ab 8 is 0.9571900723380558\n",
      "f1 score of ab 9 is 0.9623326213834353\n",
      " train data hamming_loss  : 0.011122738824936463\n",
      " train data precision recall f1  : (0.9567947376289431, 0.9624831813425028, 0.9556355257506401, None)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"/media/uuser/data/final_codes/final_run_test/REFERENCE.csv\")\n",
    "\n",
    "index = np.arange(6689)\n",
    "y_train = preprocess_y(labels, index)\n",
    "\n",
    "print(\" train data f1_score  :\", f1_score(y_train, y_pred, average='macro'))\n",
    "for i in range(10):\n",
    "    print(\"f1 score of ab {} is {}\".format(i, f1_score(y_train[:, i], y_pred[:, i], average='macro')))\n",
    "    \n",
    "print(\" train data hamming_loss  :\", hamming_loss(y_train, y_pred)) \n",
    "print(\" train data precision recall f1  :\", prf(y_train, y_pred,average=\"samples\"))# 'micro', 'weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " train data f1_score  : 0.9486110583264719\n",
    "f1 score of ab 0 is 0.9701732528678535\n",
    "f1 score of ab 1 is 0.9915591932865238\n",
    "f1 score of ab 2 is 0.9668607152468933\n",
    "f1 score of ab 3 is 0.9864456171309433\n",
    "f1 score of ab 4 is 0.9586664545859218\n",
    "f1 score of ab 5 is 0.9790363885692794\n",
    "f1 score of ab 6 is 0.9739862764690532\n",
    "f1 score of ab 7 is 0.9609072469746974\n",
    "f1 score of ab 8 is 0.9571900723380558\n",
    "f1 score of ab 9 is 0.9623326213834353\n",
    " train data hamming_loss  : 0.011257288084915534\n",
    " train data precision recall f1  : (0.9544775003737479, 0.9612871879204666, 0.9536920364398314, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " train data f1_score  : 0.9481877348787832\n",
    "f1 score of ab 0 is 0.9718297798267139\n",
    "f1 score of ab 1 is 0.9904887607485836\n",
    "f1 score of ab 2 is 0.9668607152468933\n",
    "f1 score of ab 3 is 0.985171184676515\n",
    "f1 score of ab 4 is 0.9586664545859218\n",
    "f1 score of ab 5 is 0.9790363885692794\n",
    "f1 score of ab 6 is 0.9739862764690532\n",
    "f1 score of ab 7 is 0.9596956215380122\n",
    "f1 score of ab 8 is 0.9571900723380558\n",
    "f1 score of ab 9 is 0.9623326213834353\n",
    " train data hamming_loss  : 0.011212438331589176\n",
    " train data precision recall f1  : (0.9557233268550356, 0.961137688742712, 0.9544993319997057, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data f1_score  : 0.9481877348787832\n",
      "f1 score of ab 0 is 0.9718297798267139\n",
      "f1 score of ab 1 is 0.9904887607485836\n",
      "f1 score of ab 2 is 0.9668607152468933\n",
      "f1 score of ab 3 is 0.985171184676515\n",
      "f1 score of ab 4 is 0.9586664545859218\n",
      "f1 score of ab 5 is 0.9790363885692794\n",
      "f1 score of ab 6 is 0.9739862764690532\n",
      "f1 score of ab 7 is 0.9596956215380122\n",
      "f1 score of ab 8 is 0.9571900723380558\n",
      "f1 score of ab 9 is 0.9623326213834353\n",
      " train data hamming_loss  : 0.011212438331589176\n",
      " train data precision recall f1  : (0.9557233268550356, 0.961137688742712, 0.9544993319997057, None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LR_clf = joblib.load(\"LR_ensemble.pkl\")\n",
    "MLkNN_clf = joblib.load(\"MLkNN10_ensemble.pkl\")\n",
    "MLkNN8_clf = joblib.load(\"MLkNN8_ensemble.pkl\")\n",
    "\n",
    "x_train = np.hstack(train[:-2])\n",
    "\n",
    "y_pred_LR = LR_clf.predict(x_train)\n",
    "y_pred_MLkNN = MLkNN_clf.predict(x_train).toarray()\n",
    "y_pred_MLkNN8 = MLkNN8_clf.predict(x_train).toarray()\n",
    "\n",
    "y_pred_MLkNN[:,1] = y_pred_MLkNN8[:,1]\n",
    "y_pred_MLkNN[:,2] = y_pred_MLkNN8[:,2]\n",
    "\n",
    "y_pred_MLkNN[:,3] = y_pred_LR[:,3]\n",
    "\n",
    "y_pred_MLkNN[:,5] = y_pred_MLkNN8[:,5]\n",
    "y_pred_MLkNN[:,6] = y_pred_MLkNN8[:,6]\n",
    "\n",
    "y_pred_MLkNN[:,7] = y_pred_LR[:,7]\n",
    "\n",
    "y_pred_MLkNN[:,9] = y_pred_MLkNN8[:,9]\n",
    "\n",
    "y_pred = y_pred_MLkNN\n",
    "\n",
    "print(\" train data f1_score  :\", f1_score(y_train, y_pred, average='macro'))\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"f1 score of ab {} is {}\".format(i, f1_score(y_train[:, i], y_pred[:, i], average='macro')))\n",
    "    \n",
    "print(\" train data hamming_loss  :\", hamming_loss(y_train, y_pred)) \n",
    "print(\" train data precision recall f1  :\", prf(y_train, y_pred,average=\"samples\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quarter_labels= pd.read_csv(\"/media/uuser/data/final_codes/final_run_semi/reference.csv\")\n",
    "quarter_index = np.arange(6500)\n",
    "quarter_y_train = preprocess_y(quarter_labels, quarter_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data f1_score  : 0.8457811834294056\n",
      "f1 score of ab 0 is 0.9723483730856107\n",
      "f1 score of ab 1 is 0.988758799327768\n",
      "f1 score of ab 2 is 0.9637685198604251\n",
      "f1 score of ab 3 is 0.9630934277708978\n",
      "f1 score of ab 4 is 0.945610650786264\n",
      "f1 score of ab 5 is 0.9746649815411104\n",
      "f1 score of ab 6 is 0.9665417903333571\n",
      "f1 score of ab 7 is 0.9573233412576465\n",
      "f1 score of ab 8 is 0.9559245572013491\n",
      "f1 score of ab 9 is 0.49876619370758796\n",
      " train data hamming_loss  : 0.0132\n",
      " train data precision recall f1  : (0.9482820512820513, 0.9612769230769231, 0.9496664224664224, None)\n"
     ]
    }
   ],
   "source": [
    "quarter_train = []\n",
    "path = \"./\"\n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold2.csv\").values) \n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_f0819_10net_fold.csv\").values) \n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_attention_10net_fold2.csv\").values) \n",
    "\n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_4block_10net_fold0.csv\").values)\n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_4block_10net_fold1.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_4block_10net_fold2.csv\").values)\n",
    "\n",
    "#quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold0.csv\").values)\n",
    "#quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold1.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold2.csv\").values)\n",
    "\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_fold0.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_fold1.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_fold2.csv\").values)\n",
    "\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_f0819_10net_fold.csv\").values)\n",
    "\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_sym_addori_fold2.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_db6_addori_fold2.csv\").values)\n",
    "\n",
    "''' '''\n",
    "# out = np.hstack(test)#\n",
    "out0 = np.hstack(quarter_train[:-1])#\n",
    "out1 = np.hstack(quarter_train[:-2])\n",
    "out2 = np.hstack(quarter_train[:-2]+[quarter_train[-1]])\n",
    "\n",
    "LR_clf = joblib.load(\"LR_ensemble0810.pkl\")\n",
    "MLkNN8_clf = joblib.load(\"MLkNN8_ensemble.pkl\")\n",
    "MLkNN10_clf = joblib.load(\"MLkNN10_ensemble.pkl\")\n",
    "MLkNN10_db6_clf = joblib.load(\"MLkNN10_ensemble_db6_0810.pkl\")\n",
    "\n",
    "y_pred_LR = LR_clf.predict(out0)\n",
    "y_pred_proba_LR = LR_clf.predict_proba(out0)\n",
    "\n",
    "y_pred_MLkNN8 = MLkNN8_clf.predict(out1).toarray()\n",
    "y_pred_proba_MLkNN8 = MLkNN8_clf.predict_proba(out1).toarray()\n",
    "\n",
    "y_pred_MLkNN10 = MLkNN10_clf.predict(out1).toarray()\n",
    "y_pred_proba_MLkNN10 = MLkNN10_clf.predict_proba(out1).toarray()\n",
    "\n",
    "y_pred_MLkNN10_db6 = MLkNN10_db6_clf.predict(out2).toarray()\n",
    "y_pred_proba_MLkNN10_db6 = MLkNN10_db6_clf.predict_proba(out2).toarray()\n",
    "\n",
    "y_pred_LR[:,2] = y_pred_MLkNN8[:,2]\n",
    "# y_pred_proba_LR[:,2] = y_pred_proba_MLkNN8[:,2]\n",
    "\n",
    "y_pred_LR[:,5] = y_pred_MLkNN8[:,5]\n",
    "# y_pred_proba_LR[:,5] = y_pred_proba_MLkNN8[:,5]\n",
    "\n",
    "y_pred_LR[:,6] = y_pred_MLkNN8[:,6]\n",
    "# y_pred_proba_LR[:,6] = y_pred_proba_MLkNN8[:,6]\n",
    "\n",
    "y_pred_LR[:,9] = y_pred_MLkNN8[:,9]\n",
    "# y_pred_proba_LR[:,9] = y_pred_proba_MLkNN8[:,9]\n",
    "\n",
    "y_pred_LR[:,0] = y_pred_MLkNN10[:,0]\n",
    "#y_pred_proba_LR[:,0] = y_pred_proba_MLkNN10[:,0]\n",
    "\n",
    "y_pred_LR[:,4] = y_pred_MLkNN10[:,4]\n",
    "# y_pred_proba_LR[:,4] = y_pred_proba_MLkNN10[:,4]\n",
    "\n",
    "y_pred_LR[:,8] = y_pred_MLkNN10[:,8]\n",
    "# y_pred_proba_LR[:,8] = y_pred_proba_MLkNN10[:,8]\n",
    "\n",
    "y_pred_LR[:,7] = y_pred_MLkNN10_db6[:,7]\n",
    "# y_pred_proba_LR[:,7] = y_pred_proba_MLkNN10_db6[:,7]\n",
    "\n",
    "\n",
    "quarter_y_pred = y_pred_LR\n",
    "# quarter_y_pred_proba = y_pred_proba_LR\n",
    "\n",
    "# quarter_x_train = np.hstack(quarter_train)\n",
    "# quarter_y_pred = clf.predict(quarter_x_train).toarray()\n",
    "\n",
    "print(\" train data f1_score  :\", f1_score(quarter_y_train, quarter_y_pred, average='macro'))\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"f1 score of ab {} is {}\".format(i, f1_score(quarter_y_train[:, i], quarter_y_pred[:, i], average='macro')))\n",
    "    \n",
    "print(\" train data hamming_loss  :\", hamming_loss(quarter_y_train, quarter_y_pred)) \n",
    "print(\" train data precision recall f1  :\", prf(quarter_y_train, quarter_y_pred,average=\"samples\"))# 'micro', 'weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data f1_score  : 0.8443423747565797\n",
      "f1 score of ab 0 is 0.9723483730856107\n",
      "f1 score of ab 1 is 0.9872106784931818\n",
      "f1 score of ab 2 is 0.9637685198604251\n",
      "f1 score of ab 3 is 0.9618120805912989\n",
      "f1 score of ab 4 is 0.945610650786264\n",
      "f1 score of ab 5 is 0.9746649815411104\n",
      "f1 score of ab 6 is 0.9665417903333571\n",
      "f1 score of ab 7 is 0.9525365906375869\n",
      "f1 score of ab 8 is 0.9559245572013491\n",
      "f1 score of ab 9 is 0.49876619370758796\n",
      " train data hamming_loss  : 0.013353846153846154\n",
      " train data precision recall f1  : (0.947, 0.9598410256410257, 0.9483638583638584, None)\n"
     ]
    }
   ],
   "source": [
    "quarter_train = []\n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold2.csv\").values) \n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_f0819_10net_fold.csv\").values) \n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_attention_10net_fold2.csv\").values) \n",
    "path = \"./\"\n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_4block_10net_fold0.csv\").values)\n",
    "# quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_4block_10net_fold1.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_4block_10net_fold2.csv\").values)\n",
    "\n",
    "#quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold0.csv\").values)\n",
    "#quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold1.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_one_net_fold2.csv\").values)\n",
    "\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_fold0.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_fold1.csv\").values)\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"attention_10net_fold2.csv\").values)\n",
    "\n",
    "quarter_train.append(pd.read_csv(path+\"quarter_final/\"+\"densenet_f0819_10net_fold.csv\").values)\n",
    "\n",
    "''' '''\n",
    "# quarter_train_y = thr0*quarter_train[0] + thr1*quarter_train[1] + thr2*quarter_train[2] + \\\n",
    "#                 thr3*quarter_train[3] + thr4*quarter_train[4] + thr5*quarter_train[5]\n",
    "\n",
    "# print(\"best_threshold :\", best_threshold)\n",
    "\n",
    "# quarter_y_pred = np.array([[1 if quarter_train_y[i, j] >= best_threshold[j] else 0 \n",
    "#                             for j in range(quarter_train_y.shape[1])]\n",
    "#           for i in range(len(quarter_train_y))])\n",
    "\n",
    "# Restore\n",
    "LR_clf = joblib.load(\"LR_ensemble.pkl\")\n",
    "MLkNN_clf = joblib.load(\"MLkNN10_ensemble.pkl\")\n",
    "MLkNN8_clf = joblib.load(\"MLkNN8_ensemble.pkl\")\n",
    "\n",
    "quarter_x_train = np.hstack(quarter_train)\n",
    "\n",
    "quarter_y_pred_LR = LR_clf.predict(quarter_x_train)\n",
    "quarter_y_pred_MLkNN = MLkNN_clf.predict(quarter_x_train).toarray()\n",
    "quarter_y_pred_MLkNN8 = MLkNN8_clf.predict(quarter_x_train).toarray()\n",
    "\n",
    "quarter_y_pred_MLkNN[:,1] = quarter_y_pred_MLkNN8[:,1]\n",
    "quarter_y_pred_MLkNN[:,2] = quarter_y_pred_MLkNN8[:,2]\n",
    "\n",
    "quarter_y_pred_MLkNN[:,3] = quarter_y_pred_LR[:,3]\n",
    "\n",
    "quarter_y_pred_MLkNN[:,5] = quarter_y_pred_MLkNN8[:,5]\n",
    "quarter_y_pred_MLkNN[:,6] = quarter_y_pred_MLkNN8[:,6]\n",
    "\n",
    "quarter_y_pred_MLkNN[:,7] = quarter_y_pred_LR[:,7]\n",
    "\n",
    "quarter_y_pred_MLkNN[:,9] = quarter_y_pred_MLkNN8[:,9]\n",
    "\n",
    "quarter_y_pred = quarter_y_pred_MLkNN\n",
    "\n",
    "print(\" train data f1_score  :\", f1_score(quarter_y_train, quarter_y_pred, average='macro'))\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"f1 score of ab {} is {}\".format(i, f1_score(quarter_y_train[:, i], quarter_y_pred[:, i], average='macro')))\n",
    "    \n",
    "print(\" train data hamming_loss  :\", hamming_loss(quarter_y_train, quarter_y_pred)) \n",
    "print(\" train data precision recall f1  :\", prf(quarter_y_train, quarter_y_pred,average=\"samples\"))# 'micro', 'weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " train data f1_score  : 0.8442967714781059\n",
    "f1 score of ab 0 is 0.9708833862292193\n",
    "f1 score of ab 1 is 0.988758799327768\n",
    "f1 score of ab 2 is 0.9629484127901154\n",
    "f1 score of ab 3 is 0.9630934277708978\n",
    "f1 score of ab 4 is 0.9440688933557289\n",
    "f1 score of ab 5 is 0.9746300670156537\n",
    "f1 score of ab 6 is 0.9673782455750232\n",
    "f1 score of ab 7 is 0.9525056267020673\n",
    "f1 score of ab 8 is 0.9555890425606381\n",
    "f1 score of ab 9 is 0.49884348496530456\n",
    " train data hamming_loss  : 0.0134\n",
    " train data precision recall f1  : (0.9458333333333332, 0.9604820512820512, 0.9476832722832723, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " train data f1_score  : 0.8445570284593916\n",
    "f1 score of ab 0 is 0.972730581097661\n",
    "f1 score of ab 1 is 0.988758799327768\n",
    "f1 score of ab 2 is 0.9629484127901154\n",
    "f1 score of ab 3 is 0.9630934277708978\n",
    "f1 score of ab 4 is 0.9440688933557289\n",
    "f1 score of ab 5 is 0.9746300670156537\n",
    "f1 score of ab 6 is 0.9673782455750232\n",
    "f1 score of ab 7 is 0.9525056267020673\n",
    "f1 score of ab 8 is 0.9555890425606381\n",
    "f1 score of ab 9 is 0.49884348496530456\n",
    " train data hamming_loss  : 0.013246153846153847\n",
    " train data precision recall f1  : (0.9482948717948717, 0.9615589743589743, 0.9496832722832723, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877473"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.844557 * 10 - 0.49884 +0.828)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data f1_score  : 0.9381581941739774\n"
     ]
    }
   ],
   "source": [
    "print(\" train data f1_score  :\", f1_score(quarter_y_train[:,:9], quarter_y_pred[:,:9], average='macro'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
