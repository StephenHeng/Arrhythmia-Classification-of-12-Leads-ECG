{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from utils import extract_basic_features\n",
    "\n",
    "#import wfdb\n",
    "import os\n",
    "#import wfdb.processing as wp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "#from utils import find_noise_features, extract_basic_features\n",
    "import shutil\n",
    "import gc\n",
    "import time\n",
    "import random as rn\n",
    "#from lightgbm import LGBMClassifier\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "#from xgboost import XGBClassifier\n",
    "import pywt\n",
    "import warnings\n",
    "import scipy.io as sio\n",
    "\n",
    "#from resnet_ecg.utils import one_hot,get_batches\n",
    "from resnet_ecg.ecg_preprocess import ecg_preprocessing\n",
    "\n",
    "\n",
    "path = '/media/jdcloud/'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet(ecg,wavefunc,lv,m,n):   #\n",
    "    \n",
    "    coeff = pywt.wavedec(ecg,wavefunc,mode='sym',level=lv)   #\n",
    "    #sgn = lambda x: 1 if x > 0 else -1 if x < 0 else 0\n",
    "\n",
    "    for i in range(m,n+1):  \n",
    "        cD = coeff[i]\n",
    "        for j in range(len(cD)):\n",
    "            Tr = np.sqrt(2*np.log(len(cD)))  \n",
    "            if cD[j] >= Tr:\n",
    "                coeff[i][j] = np.sign(cD[j]) - Tr \n",
    "            else:\n",
    "                coeff[i][j] = 0   \n",
    "                \n",
    "    denoised_ecg = pywt.waverec(coeff,wavefunc)\n",
    "    return denoised_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_db6(sig):\n",
    "    \"\"\"\n",
    "    R J, Acharya U R, Min L C. ECG beat classification using PCA, LDA, ICA and discrete\n",
    "     wavelet transform[J].Biomedical Signal Processing and Control, 2013, 8(5): 437-448.\n",
    "\n",
    "    param sig: 1-D numpy Array\n",
    "    return: 1-D numpy Array\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = pywt.wavedec(sig, 'db6', level=9)\n",
    "\n",
    "    coeffs[-1] = np.zeros(len(coeffs[-1]))\n",
    "\n",
    "    coeffs[-2] = np.zeros(len(coeffs[-2]))\n",
    "\n",
    "    coeffs[0] = np.zeros(len(coeffs[0]))\n",
    "\n",
    "    sig_filt = pywt.waverec(coeffs, 'db6')\n",
    "\n",
    "    return sig_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/media/uuser/data/ysecgtest/training_data_pre/\"\n",
    "data = np.load(path + \"TRAIN0001.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.39426738\n",
      "20736\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(data[:,0]):\n",
    "    if v != 0 :\n",
    "        print(v)\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAIN6491',\n",
       " 'TRAIN6492',\n",
       " 'TRAIN6493',\n",
       " 'TRAIN6494',\n",
       " 'TRAIN6495',\n",
       " 'TRAIN6496',\n",
       " 'TRAIN6497',\n",
       " 'TRAIN6498',\n",
       " 'TRAIN6499',\n",
       " 'TRAIN6500']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"/media/uuser/data/final_codes/final_run_semi/reference.csv\")\n",
    "raw_IDs = labels[\"File_name\"].values.tolist()\n",
    "raw_IDs[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File_name    TRAIN5321\n",
       "label1               6\n",
       "label2             NaN\n",
       "label3             NaN\n",
       "label4             NaN\n",
       "label5             NaN\n",
       "label6             NaN\n",
       "label7             NaN\n",
       "label8             NaN\n",
       "Name: 5320, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.iloc[5320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data_seg_back(data_path, split=\"Train\", preprocess=False, fs=500, newFs=256, winSecond=10, winNum=10, n_index=0):\n",
    "    \"\"\" Read data \"\"\"\n",
    "\n",
    "    # Fixed params\n",
    "    # n_index = 0\n",
    "    n_class = 9\n",
    "    winSize = winSecond * fs\n",
    "    new_winSize = winSecond * newFs\n",
    "    # Paths\n",
    "    path_signals = os.path.join(data_path, split)\n",
    "    \n",
    "    labels = pd.read_csv(\"/media/uuser/data/final_codes/final_run_semi/reference.csv\")\n",
    "    raw_IDs = labels[\"File_name\"].values.tolist()\n",
    "\n",
    "    # Read time-series data\n",
    "    channel_files = raw_IDs#os.listdir(path_signals)\n",
    "    # print(channel_files)\n",
    "    channel_files.sort()\n",
    "    n_channels = 12  # len(channel_files)\n",
    "    # posix = len(split) + 5\n",
    "\n",
    "    # Initiate array\n",
    "    list_of_channels = []\n",
    "    \n",
    "    path_signals = \"/media/uuser/data/ysecgtest/training_data_pre/\"\n",
    "    path  = \"/media/uuser/data/ysecgtest/training_data/\"\n",
    "    \n",
    "    i_ch = 0\n",
    "\n",
    "    channel_name = ['V6', 'aVF', 'I', 'V4', 'V2', 'aVL', 'V1', 'II', 'aVR', 'V3', 'III', 'V5']\n",
    "\n",
    "    for i_ch, fil_ch in tqdm(enumerate(channel_files[:])):  # tqdm\n",
    "        \n",
    "        if i_ch % 1000 == 0:\n",
    "            print(i_ch)\n",
    "            \n",
    "        \n",
    "        ecg = np.load(os.path.join(path_signals, fil_ch)+\"_db4.npy\")  \n",
    "        \n",
    "        for i,v in enumerate(ecg[:,0]):\n",
    "            if v != 0 :\n",
    "                ecg_length = 23296 - i\n",
    "                break\n",
    "        ecg = ecg[i:,:]\n",
    "        #print(ecg.shape)\n",
    "        #print(ecg_length)\n",
    "        '''\n",
    "        if ecg_length > fs * winNum * winSecond:\n",
    "            print(\" too long !!!\", ecg_length)\n",
    "            ecg_length = fs * winNum * winSecond\n",
    "        if ecg_length < 4500:\n",
    "            print(\" too short !!!\", ecg_length)\n",
    "            break\n",
    "        ''' \n",
    "        slide_steps = int((ecg_length - new_winSize) / (winNum-1))#int((ecg_length - winSize) / winSecond)\n",
    "\n",
    "        if ecg_length <= 2560:\n",
    "            slide_steps = 0\n",
    "            \n",
    "        X = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        #X_db4 = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        #X_db6 = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        \n",
    "        for ind in range(winNum):\n",
    "            \n",
    "            n_index = ind\n",
    "            \n",
    "            ecg_channels = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            #ecg_channels_db4 = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            #ecg_channels_db6 = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            \n",
    "            for i_n, ch_name in enumerate(channel_name):\n",
    "                #print(ecg[i_n])\n",
    "                if ecg_length <= 2560:\n",
    "                    ecg_channels[:ecg_length, i_n] = ecg[n_index * slide_steps:,i_n].T\n",
    "                else:\n",
    "                    ecg_channels[:, i_n] = ecg[n_index * slide_steps:n_index * slide_steps + new_winSize,i_n].T\n",
    "\n",
    "            X[ind, :, :] = ecg_channels\n",
    "            #X_db4[ind, :, :] = ecg_channels_db4\n",
    "            #X_db6[ind, :, :] = ecg_channels_db6\n",
    "        np.save(path + \"{}_db4.npy\".format(fil_ch),X)\n",
    "        #np.save(\"training_data/{}.npy\".format(fil_ch.strip(\".mat\")),X)\n",
    "        #np.save(\"training_data/{}_db4.npy\".format(fil_ch.strip(\".mat\")),X_db4)\n",
    "        #np.save(\"training_data/{}_db6.npy\".format(fil_ch.strip(\".mat\")),X_db6)\n",
    "                \n",
    "    return \"OK!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1002it [01:05, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2002it [02:10, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3003it [03:15, 17.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4003it [04:14, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [05:14, 16.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [06:19, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6500it [06:51, 15.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK!!!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data_seg_back(data_path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data_seg(data_path, split=\"Train\", preprocess=False, fs=500, newFs=256, winSecond=10, winNum=10, n_index=0):\n",
    "    \"\"\" Read data \"\"\"\n",
    "\n",
    "    # Fixed params\n",
    "    # n_index = 0\n",
    "    n_class = 9\n",
    "    winSize = winSecond * fs\n",
    "    new_winSize = winSecond * newFs\n",
    "    # Paths\n",
    "    path_signals = os.path.join(data_path, split)\n",
    "\n",
    "    # Read labels82975 and one-hot encode\n",
    "    # label_path = os.path.join(data_path, \"reference.txt\")\n",
    "    # labels = pd.read_csv(label_path, sep='\\t',header = None)\n",
    "    # labels = pd.read_csv(\"reference.csv\")\n",
    "\n",
    "    # Read time-series data\n",
    "    channel_files = os.listdir(path_signals)\n",
    "    # print(channel_files)\n",
    "    channel_files.sort()\n",
    "    n_channels = 12  # len(channel_files)\n",
    "    # posix = len(split) + 5\n",
    "\n",
    "    # Initiate array\n",
    "    list_of_channels = []\n",
    "\n",
    "    \n",
    "    i_ch = 0\n",
    "\n",
    "    channel_name = ['V6', 'aVF', 'I', 'V4', 'V2', 'aVL', 'V1', 'II', 'aVR', 'V3', 'III', 'V5']\n",
    "\n",
    "    for i_ch, fil_ch in tqdm(enumerate(channel_files[:])):  # tqdm\n",
    "        \n",
    "        if i_ch % 1000 == 0:\n",
    "            print(i_ch)\n",
    "            \n",
    "        ecg = sio.loadmat(os.path.join(path_signals, fil_ch))\n",
    "        ecg_length = ecg[\"I\"].shape[1]\n",
    "\n",
    "        if ecg_length > fs * winNum * winSecond:\n",
    "            print(\" too long !!!\", ecg_length)\n",
    "            ecg_length = fs * winNum * winSecond\n",
    "        if ecg_length < 4500:\n",
    "            print(\" too short !!!\", ecg_length)\n",
    "            break\n",
    "\n",
    "        slide_steps = int((ecg_length - winSize) / (winNum-1))#int((ecg_length - winSize) / winSecond)\n",
    "\n",
    "        if ecg_length <= 4500:\n",
    "            slide_steps = 0\n",
    "            \n",
    "        X = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        #X_db4 = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        #X_db6 = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        \n",
    "        for ind in range(winNum):\n",
    "            \n",
    "            n_index = ind\n",
    "            \n",
    "            ecg_channels = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            #ecg_channels_db4 = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            #ecg_channels_db6 = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            \n",
    "            for i_n, ch_name in enumerate(channel_name):\n",
    "                ecg_channels[:, i_n] = signal.resample(ecg[ch_name]\n",
    "                                                       [:, n_index * slide_steps:n_index * slide_steps + winSize].T\n",
    "                                                       , new_winSize).T\n",
    "                if preprocess:\n",
    "                    print(\"preprocess\")\n",
    "                    data = ecg_preprocessing(ecg_channels[:, i_n].reshape(1, new_winSize), 'sym8', 8, 3, newFs,\n",
    "                                            removebaseline=False,normalize=False)\n",
    "                    #ecg_channels_db4[:,i_n] = wavelet(ecg_channels[:,i_n],'db4',4,2,4)\n",
    "                    ecg_channels[:, i_n] = data[0]\n",
    "                    \n",
    "                    #ecg_channels_db6[:,i_n] = wavelet_db6(ecg_channels[:,i_n])\n",
    "                    #print(ecg_channels_db6[:, i_n])\n",
    "                else:\n",
    "                    pass\n",
    "                    #ecg_channels[:, i_n] = ecg_channels[:, i_n]\n",
    "                    \n",
    "                \n",
    "            X[ind, :, :] = ecg_channels\n",
    "            #X_db4[ind, :, :] = ecg_channels_db4\n",
    "            #X_db6[ind, :, :] = ecg_channels_db6\n",
    "        np.save(\"training_data/{}_ori.npy\".format(fil_ch.strip(\".mat\")),X)\n",
    "        #np.save(\"training_data/{}.npy\".format(fil_ch.strip(\".mat\")),X)\n",
    "        #np.save(\"training_data/{}_db4.npy\".format(fil_ch.strip(\".mat\")),X_db4)\n",
    "        #np.save(\"training_data/{}_db6.npy\".format(fil_ch.strip(\".mat\")),X_db6)\n",
    "        \n",
    "        ''' \n",
    "        X = np.zeros((winNum, new_winSize, n_channels)).astype('float32') \n",
    "        for ind in range(winNum):\n",
    "            ecg_channels = np.zeros((new_winSize, n_channels)).astype('float32') \n",
    "            for i_n, ch_name in enumerate(channel_name):\n",
    "                ecg_channels[:, i_n] = signal.resample(ecg[ch_name]\n",
    "                                                       [:, n_index * slide_steps:n_index * slide_steps + winSize].T\n",
    "                                                       , new_winSize).T\n",
    "                ecg_channels[:,i_n] = wavelet(ecg_channels[:,i_n],'db4',4,2,4)[0]\n",
    "                \n",
    "            X[ind, :, :] = ecg_channels\n",
    "            \n",
    "        '''\n",
    "        \n",
    "    return \"OK!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 33.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1006it [00:26, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2007it [00:53, 36.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3007it [01:19, 37.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4006it [01:46, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5007it [02:12, 36.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6004it [02:39, 33.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6689it [03:00, 37.09it/s]\n"
     ]
    }
   ],
   "source": [
    "data = read_data_seg(path,preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = os.listdir(\"training_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6500.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2560, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_labels_enhance(data_path, split = \"Train\",preprocess=True):\n",
    "    \"\"\" Read data \"\"\"\n",
    "\n",
    "    # Fixed params\n",
    "    n_class = 2\n",
    "    n_steps = 3000#2560\n",
    "\n",
    "    # Paths\n",
    "    path_signals = os.path.join(data_path, split)\n",
    "\n",
    "    # Read labels and one-hot encode\n",
    "    labels = pd.read_csv(\"reference.csv\")\n",
    "    #2156+224+672+654+180+826+534+504+1953\n",
    "    \n",
    "    # Read time-series data\n",
    "    channel_files = os.listdir(path_signals)\n",
    "    #print(channel_files)\n",
    "    channel_files.sort()\n",
    "    n_channels = 12#len(channel_files)\n",
    "    #posix = len(split) + 5\n",
    "\n",
    "    # Initiate array\n",
    "    list_of_channels = []\n",
    "    X = np.zeros((len(channel_files), n_steps, n_channels))\n",
    "    i_ch = 0\n",
    "    \n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    \n",
    "    channel_name = ['V6', 'aVF', 'I', 'V4', 'V2', 'aVL', 'V1','II', 'aVR', 'V3', 'III', 'V5']\n",
    "    channel_mid_name = ['II','aVR','V2','V5']\n",
    "    channel_post_name = ['III','aVF','V3','V6']\n",
    "    \n",
    "    for i_ch,fil_ch in tqdm(enumerate(channel_files[:1])):\n",
    "        #print(fil_ch)\n",
    "        labels_list = labels.iloc[i_ch].values[:]#.dropna()\n",
    "        #print(labels_list)\n",
    "        ecg = sio.loadmat(os.path.join(path_signals,fil_ch))\n",
    "        \n",
    "        if True:#7 in labels_list[1:] or 4 in labels_list[1:]:\n",
    "            for i_filter in range(3):\n",
    "                data_y.append(list(labels_list))\n",
    "                \n",
    "                ecg_channels = np.zeros((n_steps, n_channels))\n",
    "\n",
    "                for i_n,ch_name in enumerate(channel_name[:]):\n",
    "\n",
    "                    # method 1\n",
    "                    '''  '''\n",
    "                    if ch_name in channel_mid_name:\n",
    "                        mid_ind = int(ecg[ch_name].T.shape[0]/2)\n",
    "                        ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T[mid_ind-2500:mid_ind+2500],n_steps).T \n",
    "                    elif ch_name in channel_post_name:\n",
    "                        ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T[-5000:],n_steps).T\n",
    "                    else:\n",
    "                        ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T[:5000],n_steps).T\n",
    "                    \n",
    "                    #method 2\n",
    "                    #ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T,n_steps).T\n",
    "                    \n",
    "                    #print(ecg_channels[:,i_n].shape)\n",
    "                    if preprocess and i_filter == 0:\n",
    "                        data = ecg_preprocessing(ecg_channels[:,i_n].reshape(1,n_steps),'sym8',8,3,n_steps/10)\n",
    "                        ecg_channels[:,i_n] = data[0]#ecg['data']\n",
    "                    elif i_filter == 1:\n",
    "                        ecg_channels[:,i_n] = wavelet(ecg_channels[:,i_n],'db4',4,2,4)[0]\n",
    "                    elif i_filter == 1:\n",
    "                        ecg_channels[:,i_n] = wavelet_db6(ecg_channels[:,i_n].reshape(1,n_steps))[0]\n",
    "                    else:\n",
    "                        pass\n",
    "                        #ecg_channels[:,i_n] = ecg_channels[:,i_n]\n",
    "                X[i_ch,:,:] = ecg_channels\n",
    "                data_x.append(ecg_channels)\n",
    "        else:\n",
    "                data_y.append(list(labels_list))\n",
    "                ecg_channels = np.zeros((n_steps, n_channels))\n",
    "                for i_n,ch_name in enumerate(channel_name[:]):\n",
    "\n",
    "                    # method 1\n",
    "                    '''\n",
    "                    if ch_name in channel_mid_name:\n",
    "                        mid_ind = int(ecg[ch_name].T.shape[0]/2)\n",
    "                        ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T[mid_ind-2500:mid_ind+2500],2560).T \n",
    "                    elif ch_name in channel_post_name:\n",
    "                        ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T[-5000:],2560).T\n",
    "                    else:\n",
    "                        ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T[:5000],2560).T\n",
    "                    '''\n",
    "                    #method 2\n",
    "                    ecg_channels[:,i_n] = signal.resample(ecg[ch_name].T,n_steps).T\n",
    "\n",
    "                    if preprocess:\n",
    "                        data = ecg_preprocessing(ecg_channels[:,i_n].reshape(1,n_steps),'sym8',8,3,n_steps/10)\n",
    "                        ecg_channels[:,i_n] = data[0]#ecg['data']\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                X[i_ch,:,:] = ecg_channels\n",
    "                data_x.append(ecg_channels)\n",
    "\n",
    "    # Return \n",
    "    return np.array(data_x).astype('float32'),data_y#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
